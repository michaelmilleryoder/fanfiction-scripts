{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate LEA coreference evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harrypotter_459070_entity_clusters.csv\n",
      "teenwolf_1145590_entity_clusters.csv\n",
      "tolkien_5581141_entity_clusters.csv\n",
      "allmarvel_1621415_entity_clusters.csv\n",
      "sherlock_12828381_entity_clusters.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ground-truth annotated entity mentions\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "annotations_dirpath = '/data/fanfiction_ao3/annotated_10fandom/dev/entity_clusters'\n",
    "\n",
    "gold_entities = {} # fic_id: {cluster_name: {(chapter_id, paragraph_id, token_id_start, token_id_end), ...}}\n",
    "\n",
    "for fname in os.listdir(annotations_dirpath):\n",
    "    print(fname)\n",
    "    \n",
    "    fic_id = int(fname.split('_')[1])\n",
    "    gold_entities[fic_id] = {}\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(annotations_dirpath, fname))\n",
    "    for colname in df.columns:\n",
    "        gold_entities[fic_id][colname] = set()\n",
    "        for mention in df[colname].dropna():\n",
    "            parts = mention.split('.')\n",
    "            chapter_id = int(parts[0])\n",
    "            paragraph_id = int(parts[1])\n",
    "            if '-' in parts[2]:\n",
    "                token_id_start = int(parts[2].split('-')[0])\n",
    "                token_id_end = int(parts[2].split('-')[-1])\n",
    "            else:\n",
    "                token_id_start = int(parts[2])\n",
    "                token_id_end = int(parts[2])\n",
    "                \n",
    "            gold_entities[fic_id][colname].add((chapter_id, paragraph_id, token_id_start, token_id_end))\n",
    "\n",
    "len(gold_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entity_mentions(text):\n",
    "    \"\"\" Return token start and endpoints of entity mentions embedded in text. \"\"\"\n",
    "    \n",
    "    token_count = 1\n",
    "    entities = {} # cluster_name: {(token_id_start, token_id_end), ...}\n",
    "    \n",
    "    tokens = text.split(' ')\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.startswith('($_'): # entity cluster name\n",
    "            if not token in entities:\n",
    "                entities[token] = set()\n",
    "                \n",
    "            mention = tokens[i-1]\n",
    "            mention_len = len(mention.split('_'))\n",
    "            token_id_start = token_count - 1\n",
    "            token_id_end = (token_count - 1) + (mention_len - 1)\n",
    "            \n",
    "            token_count += mention_len - 1 # for the underscore-connected mentions\n",
    "                \n",
    "            entities[token].add((token_id_start, token_id_end))\n",
    "            \n",
    "        else:\n",
    "            # Advance token count\n",
    "            token_count += 1\n",
    "            \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allmarvel_1621415.coref.csv\n",
      "harrypotter_459070.coref.csv\n",
      "sherlock_12828381.coref.csv\n",
      "teenwolf_1145590.coref.csv\n",
      "tolkien_5581141.coref.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load entity cluster predictions\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "predictions_dirpath = '/data/fanfiction_ao3/annotated_10fandom/dev/pipeline_output/char_coref_stories'\n",
    "\n",
    "predicted_entities = {} # fic_id: {cluster_name: {(chapter_id, paragraph_id, token_id_start, token_id_end), ...}}\n",
    "\n",
    "csv_output = [fname for fname in sorted(os.listdir(predictions_dirpath)) if fname.endswith('.csv')]\n",
    "\n",
    "for fname in csv_output:\n",
    "    \n",
    "    print(fname)\n",
    "    df = pd.read_csv(os.path.join(predictions_dirpath, fname))\n",
    "    for row in list(df.itertuples()):\n",
    "        fic_id = row.fic_id\n",
    "        chapter_id = row.chapter_id\n",
    "        para_id = row.para_id\n",
    "        entities = extract_entity_mentions(row.text_tokenized)\n",
    "#         print(entities)\n",
    "#         print(row.text_tokenized)\n",
    "        \n",
    "        if not fic_id in predicted_entities:\n",
    "            predicted_entities[fic_id] = {}\n",
    "        \n",
    "        for cluster_name in entities:\n",
    "            if not cluster_name in predicted_entities[fic_id]:\n",
    "                predicted_entities[fic_id][cluster_name] = set()\n",
    "            \n",
    "            for mention in entities[cluster_name]:\n",
    "                token_id_start = mention[0]\n",
    "                token_id_end = mention[1]\n",
    "                predicted_entities[fic_id][cluster_name].add((chapter_id, para_id, token_id_start, token_id_end))\n",
    "                \n",
    "len(predicted_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def links(entity_mentions):\n",
    "    \"\"\" Returns all the links in an entity between mentions \"\"\"\n",
    "    \n",
    "    if len(entity_mentions) == 1: # self-link\n",
    "        links = {list(entity_mentions)[0], list(entity_mentions)[0]}\n",
    "\n",
    "    else:\n",
    "        links = set(itertools.combinations(entity_mentions, 2))\n",
    "        \n",
    "    return links\n",
    "\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def lea_recall(predicted_entities, gold_entities):\n",
    "    \n",
    "    fic_recalls = {}\n",
    "    \n",
    "    for fic_id in gold_entities:\n",
    "        \n",
    "        cluster_resolutions = {}\n",
    "        cluster_sizes = {}\n",
    "        \n",
    "        for gold_cluster, gold_mentions in gold_entities[fic_id].items():\n",
    "            gold_links = links(gold_mentions)\n",
    "            \n",
    "            cluster_resolution = 0\n",
    "            \n",
    "            for predicted_cluster, predicted_mentions in predicted_entities[fic_id].items():\n",
    "                predicted_links = links(predicted_mentions)\n",
    "                \n",
    "                cluster_resolution += len(predicted_links.intersection(gold_links))\n",
    "                \n",
    "            cluster_resolution = cluster_resolution/len(gold_links)\n",
    "            cluster_resolutions[gold_cluster] = cluster_resolution\n",
    "            cluster_sizes[gold_cluster] = len(gold_mentions)\n",
    "            \n",
    "        # take importance (size) of clusters into account\n",
    "#         print(cluster_resolutions)\n",
    "        fic_recalls[fic_id] = sum([cluster_sizes[c] * cluster_resolutions[c] for c in gold_entities[fic_id]])/sum(cluster_sizes.values())\n",
    "        \n",
    "    # Total recall as mean across fics\n",
    "#     print(fic_recalls)\n",
    "    total_recall = np.mean(list(fic_recalls.values()))\n",
    "    return total_recall, fic_recalls\n",
    "\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def lea_precision(predicted_entities, gold_entities):\n",
    "    \n",
    "    fic_precisions = {}\n",
    "    \n",
    "    for fic_id in gold_entities:\n",
    "        \n",
    "        cluster_resolutions = {}\n",
    "        cluster_sizes = {}\n",
    "        \n",
    "        for predicted_cluster, predicted_mentions in predicted_entities[fic_id].items():\n",
    "            predicted_links = links(predicted_mentions)\n",
    "            \n",
    "            cluster_resolution = 0\n",
    "            \n",
    "            for gold_cluster, gold_mentions in gold_entities[fic_id].items():\n",
    "                gold_links = links(gold_mentions)\n",
    "                cluster_resolution += len(predicted_links.intersection(gold_links))\n",
    "            \n",
    "            cluster_resolution = cluster_resolution/len(predicted_links)\n",
    "            cluster_resolutions[predicted_cluster] = cluster_resolution\n",
    "            cluster_sizes[predicted_cluster] = len(predicted_mentions)\n",
    "            \n",
    "        # take importance (size) of clusters into account\n",
    "#         print(cluster_resolutions)\n",
    "        fic_precisions[fic_id] = sum([cluster_sizes[c] * cluster_resolutions[c] for c in predicted_entities[fic_id]])/sum(cluster_sizes.values())\n",
    "        \n",
    "    # Total precision as mean across fics\n",
    "#     print(fic_precisions)\n",
    "    total_precision = np.mean(list(fic_precisions.values()))\n",
    "    return total_precision, fic_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(precision, recall):\n",
    "    return 2 * (precision * recall)/(precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  28.39%\n",
      "Recall:  13.44%\n",
      "F-score:  18.24%\n"
     ]
    }
   ],
   "source": [
    "recall, fic_recalls = lea_recall(predicted_entities, gold_entities)\n",
    "precision, fic_precisions = lea_precision(predicted_entities, gold_entities)\n",
    "f1 = f_score(precision, recall)\n",
    "\n",
    "print(f\"Precision: {precision: .2%}\")\n",
    "print(f\"Recall: {recall: .2%}\")\n",
    "print(f\"F-score: {f1: .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{459070: 0.20664608688802236,\n",
       " 1145590: 0.44628475692709196,\n",
       " 5581141: 0.5345563442755866,\n",
       " 1621415: 0.08021746118261987,\n",
       " 12828381: 0.1519804183355585}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fic_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{459070: 0.02770425922695492,\n",
       " 1145590: 0.24624357045549267,\n",
       " 5581141: 0.269897197854156,\n",
       " 1621415: 0.024993739043325823,\n",
       " 12828381: 0.10310111184268897}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fic_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Test calculation with toy examples\n",
    "\n",
    "import itertools\n",
    "\n",
    "# set(itertools.combinations({(1,3), (1,4), (2,2), (3,5)}, 2))\n",
    "test_gold = {1: {'A': {(1,1,1,1), (1,1,2,2), (1,1,3,3)},\n",
    "                'B': {(1,1,4,4), (1,1,5,5), (1,1,6,6)}\n",
    "                }}\n",
    "\n",
    "test_predicted = {1: {'A': {(1,1,1,1), (1,1,2,2), (1,1,3,3), (1,1,6,6)},\n",
    "                'B': {(1,1,4,4), (1,1,5,5)}\n",
    "                }}\n",
    "\n",
    "print(lea_recall(test_predicted, test_gold))\n",
    "print(lea_precision(test_predicted, test_gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create personal coref annotation interface (token id subscripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_subscript(text):\n",
    "    numbered_tokens = [el for el in enumerate(text.split())]\n",
    "    subscripted = [f'{tok}<sub>{tok_num+1}</sub>' for tok_num, tok in numbered_tokens]\n",
    "    return ' '.join(subscripted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "annotation_dirpath = '/data/fanfiction_ao3/annotated_10fandom/dev'\n",
    "csv_dirpath = os.path.join(annotation_dirpath, 'fics')\n",
    "subscripts_dirpath = os.path.join(annotation_dirpath, 'subscripted')\n",
    "fnames = os.listdir(csv_dirpath)\n",
    "\n",
    "fandoms = [\n",
    "#     'allmarvel',\n",
    "#     'harrypotter',\n",
    "#     'sherlock',\n",
    "#     'teenwolf',\n",
    "    'tolkien'\n",
    "]\n",
    "\n",
    "for fandom in fandoms:\n",
    "    for fname in fnames:\n",
    "        if fname.endswith('.csv') and fname.startswith(fandom):\n",
    "            data = pd.read_csv(os.path.join(csv_dirpath, fname))\n",
    "            data['annotation_text'] = data['text_tokenized'].map(add_token_subscript)\n",
    "            data.loc[:, ['chapter_id', 'para_id', 'annotation_text']].to_html(os.path.join(subscripts_dirpath, f'{fname[:-4]}_subscripts.html'), escape=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data for preliminary annotation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['teenwolf', 'harrypotter', 'sherlock', 'tolkien']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "all_fandoms = [\n",
    "#     'allmarvel',\n",
    "    'supernatural',\n",
    "    'harrypotter',\n",
    "    'dcu',\n",
    "    'sherlock',\n",
    "    'teenwolf',\n",
    "    'starwars',\n",
    "    'drwho',\n",
    "    'tolkien',\n",
    "    'dragonage',\n",
    "]\n",
    "\n",
    "random.sample(all_fandoms, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sherlock: 12828381.csv\n",
      "teenwolf: 1145590.csv\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import random\n",
    "\n",
    "old_seeds = [9, 12, 1234, 99, 120]\n",
    "current_seed = 120\n",
    "random.seed(current_seed)\n",
    "\n",
    "dataset = 'complete_en_1k-50k'\n",
    "fandoms = [\n",
    "#     'allmarvel',\n",
    "#     'supernatural',\n",
    "#     'harrypotter',\n",
    "#     'dcu',\n",
    "    'sherlock',\n",
    "    'teenwolf',\n",
    "#     'starwars',\n",
    "#     'drwho',\n",
    "#     'tolkien',\n",
    "#     'dragonage',\n",
    "]\n",
    "\n",
    "for fandom in fandoms:\n",
    "\n",
    "    fic_dirpath = f'/data/fanfiction_ao3/{fandom}/{dataset}/fics'\n",
    "    annotation_dirpath = f'/data/fanfiction_ao3/annotated_10fandom/dev/fics/'\n",
    "    fnames = os.listdir(fic_dirpath)\n",
    "    selected = random.sample(fnames, 1)[0]\n",
    "    print(f'{fandom}: {selected}')\n",
    "    shutil.copy(os.path.join(fic_dirpath, selected), os.path.join(annotation_dirpath, f'{fandom}_{selected}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
