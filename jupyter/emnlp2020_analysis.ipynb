{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship prediction experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run logistic regression to predict romantic relationships, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400\n",
      "Index(['fic_id', 'pairing', 'pairing_embedding_unigrams_assertions_local_5',\n",
      "       'pairing_embedding_unigrams_assertions_local_10',\n",
      "       'pairing_embedding_unigrams_assertions_local_25',\n",
      "       'pairing_embedding_unigrams_assertions_local_50', 'relationship',\n",
      "       'selected_relationships', 'is_romantic', 'is_canon', 'is_mm',\n",
      "       'shape_10', 'pairing_embedding_embs_adapted_10',\n",
      "       'pairing_embedding_unigrams_quotes', 'dist_canon_combined',\n",
      "       'subtraction_canon_combined', 'dist_canon_bg', 'subtraction_canon_bg',\n",
      "       'dist_canon_aligned', 'subtraction_canon_aligned',\n",
      "       'pairing_embedding_embs_background_quotes',\n",
      "       'pairing_embedding_embs_combined_quotes',\n",
      "       'pairing_embedding_canon_embs_aligned',\n",
      "       'pairing_embedding_embs_aligned', 'pairing_embedding_embs_combined',\n",
      "       'pairing_embedding_canon_embs_combined',\n",
      "       'pairing_embedding_embs_background',\n",
      "       'pairing_embedding_canon_embs_background', 'dist_canon_background',\n",
      "       'subtraction_canon_background'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_pickle('/usr2/mamille2/fanfiction-project/data/features/relationship_prediction_assertion_sample5400.pkl')\n",
    "print(len(data))\n",
    "print(data.columns)\n",
    "\n",
    "pairings = data['pairing'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4866\n",
      "0.9011111111111111\n",
      "534\n",
      "Index(['fic_id', 'pairing', 'pairing_embedding_unigrams_assertions_local_5',\n",
      "       'pairing_embedding_unigrams_assertions_local_10',\n",
      "       'pairing_embedding_unigrams_assertions_local_25',\n",
      "       'pairing_embedding_unigrams_assertions_local_50', 'relationship',\n",
      "       'selected_relationships', 'is_romantic', 'is_canon', 'is_mm',\n",
      "       'shape_10', 'pairing_embedding_embs_adapted_10',\n",
      "       'pairing_embedding_unigrams_quotes', 'dist_canon_combined',\n",
      "       'subtraction_canon_combined', 'dist_canon_bg', 'subtraction_canon_bg',\n",
      "       'dist_canon_aligned', 'subtraction_canon_aligned',\n",
      "       'pairing_embedding_embs_background_quotes',\n",
      "       'pairing_embedding_embs_combined_quotes',\n",
      "       'pairing_embedding_canon_embs_aligned',\n",
      "       'pairing_embedding_embs_aligned', 'pairing_embedding_embs_combined',\n",
      "       'pairing_embedding_canon_embs_combined',\n",
      "       'pairing_embedding_embs_background',\n",
      "       'pairing_embedding_canon_embs_background', 'dist_canon_background',\n",
      "       'subtraction_canon_background'],\n",
      "      dtype='object')\n",
      "0.26921496095356295\n",
      "0.561241265926864\n",
      "0.3335388409371261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, test = train_test_split(data, test_size=0.1, random_state=9)\n",
    "train_ids, test_ids = train_test_split(data['fic_id'].unique(), test_size=0.1, random_state=11)\n",
    "# train_ids, test_ids = train_test_split(data['fic_id'].unique(), test_size=0.1, random_state=9)\n",
    "\n",
    "train = data[data['fic_id'].isin(train_ids)]\n",
    "test = data[data['fic_id'].isin(test_ids)]\n",
    "print(len(train))\n",
    "print(len(train)/ len(data))\n",
    "print(len(test))\n",
    "print(train.columns)\n",
    "print(sum(train['is_romantic']/len(train)))\n",
    "print(sum(train['is_canon']/len(train)))\n",
    "print(sum(train['is_mm']/len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tis_romantic: 0.795880149812734\n",
      "all\tis_canon: 0.6910112359550562\n",
      "all\tis_mm: 0.900749063670412\n",
      "\n",
      "all\tis_romantic: 0.7788072417465388\n",
      "all\tis_canon: 0.6852502662406815\n",
      "all\tis_mm: 0.8882321618743344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "X_train, y_train = {}, {}\n",
    "X_test, y_test = {}, {}\n",
    "\n",
    "add_features = True\n",
    "\n",
    "# for feature_set in ['unigrams', 'embs']:\n",
    "# for feature_set in ['unigrams_assertions_local_10', 'embs_adapted_10', 'embs_background_10']:\n",
    "# for feature_set in ['unigrams_quotes', 'unigrams_assertions_local_10']:\n",
    "# for feature_set in pairing_char_embs_fpath:\n",
    "# for feature_set in ['embs_combined', 'dist_canon_combined']:\n",
    "# for feature_set in ['embs_combined', 'subtraction_canon_combined']:\n",
    "# for feature_set in ['embs_background', 'dist_canon_background']:\n",
    "# for feature_set in ['embs_background', 'subtraction_canon_background']:\n",
    "# for feature_set in ['embs_combined', 'dist_canon_aligned']:\n",
    "# for feature_set in ['embs_combined', 'subtraction_canon_aligned']:\n",
    "# for feature_set in ['embs_combined', 'pairing_embedding_embs_combined_quotes']:\n",
    "# for feature_set in ['embs_background', 'embs_background_quotes', 'subtraction_canon_background']:\n",
    "for feature_set in ['embs_combined', 'embs_combined_quotes', 'subtraction_canon_combined']: # best results\n",
    "# for feature_set in ['embs_combined', 'embs_combined_quotes', 'dist_canon_combined']:\n",
    "# for feature_set in ['embs_combined', 'embs_combined_quotes']:\n",
    "# for feature_set in ['embs_combined']:\n",
    "# for feature_set in ['embs_combined', 'embs_combined_quotes', 'subtraction_canon_aligned']:\n",
    "# for feature_set in ['embs_combined', 'embs_combined_quotes', 'dist_canon_aligned']:\n",
    "\n",
    "    if feature_set.startswith('embs'):\n",
    "        X_train[feature_set] = np.vstack(train[f'pairing_embedding_{feature_set}'].tolist())\n",
    "        X_test[feature_set] = np.vstack(test[f'pairing_embedding_{feature_set}'].tolist())\n",
    "        \n",
    "    elif 'canon' in feature_set:\n",
    "        X_train[feature_set] = np.vstack(train[feature_set].tolist())\n",
    "        X_test[feature_set] = np.vstack(test[feature_set].tolist())\n",
    "        \n",
    "    elif feature_set.startswith('unigrams'):\n",
    "        X_train[feature_set] = scipy.sparse.vstack(train[f'pairing_embedding_{feature_set}'].tolist())\n",
    "        X_test[feature_set] = scipy.sparse.vstack(test[f'pairing_embedding_{feature_set}'].tolist())\n",
    "        \n",
    "    elif feature_set == 'unigrams+embs':\n",
    "        unigram_features = scipy.sparse.vstack(train[f'pairing_embedding_unigrams'].tolist())\n",
    "        emb_features = np.array(train[f'pairing_embedding_embs'].tolist())\n",
    "        X_train[feature_set] = scipy.sparse.hstack([unigram_features, emb_features])\n",
    "        \n",
    "        unigram_features = scipy.sparse.vstack(test[f'pairing_embedding_unigrams'].tolist())\n",
    "        emb_features = np.array(test[f'pairing_embedding_embs'].tolist())\n",
    "        X_test[feature_set] = scipy.sparse.hstack([unigram_features, emb_features])\n",
    "        \n",
    "    if add_features:\n",
    "        if 'unigrams' in ' '.join(feature_set):\n",
    "            X_train['all'] = scipy.sparse.hstack(list(X_train.values()))\n",
    "            X_test['all'] = scipy.sparse.hstack(list(X_test.values()))\n",
    "        \n",
    "        else:\n",
    "            X_train['all'] = np.hstack(list(X_train.values()))\n",
    "            X_test['all'] = np.hstack(list(X_test.values()))\n",
    "        \n",
    "y_train['is_romantic'] = train['is_romantic']\n",
    "y_train['is_canon'] = train['is_canon']\n",
    "y_train['is_mm'] = train['is_mm']\n",
    "\n",
    "y_test['is_romantic'] = test['is_romantic']\n",
    "y_test['is_canon'] = test['is_canon']\n",
    "y_test['is_mm'] = test['is_mm']\n",
    "\n",
    "X_train.keys()\n",
    "\n",
    "# Per-instance score\n",
    "results = {}\n",
    "clf = {}\n",
    "\n",
    "# for feature_set in ['unigrams_assertions_local_10']:\n",
    "# for feature_set in ['embs_adapted_10']:\n",
    "# for feature_set in ['embs_aligned_10']:\n",
    "# for feature_set in ['embs_background_10']:\n",
    "# for feature_set in ['unigrams_assertions_local_10', 'embs_adapted_10', 'embs_background_10']:\n",
    "# for feature_set in ['unigrams_quotes']:\n",
    "# for feature_set in ['all']:\n",
    "# for feature_set in pairing_char_embs_fpath:\n",
    "for feature_set in ['all']:\n",
    "    results[f'{feature_set}_lr'] = {}\n",
    "    clf[f'{feature_set}_lr'] = {}\n",
    "    for key in y_test:\n",
    "\n",
    "        clf[f'{feature_set}_lr'][key] = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "        clf[f'{feature_set}_lr'][key].fit(X_train[feature_set], y_train[key])\n",
    "        results[f'{feature_set}_lr'][key] = clf[f'{feature_set}_lr'][key].score(X_test[feature_set], y_test[key])\n",
    "        print(f'{feature_set}\\t{key}: {results[f\"{feature_set}_lr\"][key]}')\n",
    "        \n",
    "    print()\n",
    "\n",
    "# Group instance IDs\n",
    "test_groups = test.reset_index().groupby('fic_id').groups\n",
    "len(test_groups)\n",
    "\n",
    "# Per-fic score\n",
    "perfic_results = {}\n",
    "predictions = {}\n",
    "\n",
    "# for feature_set in ['unigrams_assertions_local_10']:\n",
    "# for feature_set in ['embs_adapted_10']:\n",
    "# for feature_set in ['embs_background_10']:\n",
    "# for feature_set in ['unigrams_assertions_local_10', 'embs_adapted_10', 'embs_background_10']:\n",
    "# for feature_set in ['unigrams_quotes']:\n",
    "for feature_set in ['all']:\n",
    "# for feature_set in pairing_char_embs_fpath:\n",
    "    perfic_results[f'{feature_set}_lr'] = {}\n",
    "    for key in y_test:\n",
    "\n",
    "        predictions[key] = clf[f'{feature_set}_lr'][key].predict(X_test[feature_set])\n",
    "        \n",
    "        avg_acc = []\n",
    "        for fic_id, indices in test_groups.items():\n",
    "            avg_acc.append(np.mean([predictions[key][i]==y_test[key].tolist()[i] for i in indices]))\n",
    "        \n",
    "        perfic_results[f'{feature_set}_lr'][key] = np.mean(avg_acc)\n",
    "        print(f'{feature_set}\\t{key}: {perfic_results[f\"{feature_set}_lr\"][key]}')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tis_romantic: 0.8211190053285967\n",
      "all\tis_canon: 0.7396092362344583\n",
      "all\tis_mm: 0.9221432800473652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group instance IDs\n",
    "train_groups = train.reset_index().groupby('fic_id').groups\n",
    "len(train_groups)\n",
    "\n",
    "# Per-fic score\n",
    "train_perfic_results = {}\n",
    "train_predictions = {}\n",
    "\n",
    "# for feature_set in ['unigrams_assertions_local_10']:\n",
    "# for feature_set in ['embs_adapted_10']:\n",
    "# for feature_set in ['embs_background_10']:\n",
    "# for feature_set in ['unigrams_assertions_local_10', 'embs_adapted_10', 'embs_background_10']:\n",
    "# for feature_set in ['unigrams_quotes']:\n",
    "for feature_set in ['all']:\n",
    "# for feature_set in pairing_char_embs_fpath:\n",
    "    train_perfic_results[f'{feature_set}_lr'] = {}\n",
    "    for key in y_train:\n",
    "\n",
    "        train_predictions[key] = clf[f'{feature_set}_lr'][key].predict(X_train[feature_set])\n",
    "        \n",
    "        train_avg_acc = []\n",
    "        for fic_id, indices in train_groups.items():\n",
    "            train_avg_acc.append(np.mean([train_predictions[key][i]==y_train[key].tolist()[i] for i in indices]))\n",
    "        \n",
    "        train_perfic_results[f'{feature_set}_lr'][key] = np.mean(train_avg_acc)\n",
    "        print(f'{feature_set}\\t{key}: {train_perfic_results[f\"{feature_set}_lr\"][key]}')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join training predictions with fic info, save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4866, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['all'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4866"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_predictions['is_canon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4866"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fic_id', 'pairing', 'pairing_embedding_unigrams_assertions_local_5',\n",
       "       'pairing_embedding_unigrams_assertions_local_10',\n",
       "       'pairing_embedding_unigrams_assertions_local_25',\n",
       "       'pairing_embedding_unigrams_assertions_local_50', 'relationship',\n",
       "       'selected_relationships', 'is_romantic', 'is_canon', 'is_mm',\n",
       "       'shape_10', 'pairing_embedding_embs_adapted_10',\n",
       "       'pairing_embedding_unigrams_quotes', 'dist_canon_combined',\n",
       "       'subtraction_canon_combined', 'dist_canon_bg', 'subtraction_canon_bg',\n",
       "       'dist_canon_aligned', 'subtraction_canon_aligned',\n",
       "       'pairing_embedding_embs_background_quotes',\n",
       "       'pairing_embedding_embs_combined_quotes',\n",
       "       'pairing_embedding_canon_embs_aligned',\n",
       "       'pairing_embedding_embs_aligned', 'pairing_embedding_embs_combined',\n",
       "       'pairing_embedding_canon_embs_combined',\n",
       "       'pairing_embedding_embs_background',\n",
       "       'pairing_embedding_canon_embs_background', 'dist_canon_background',\n",
       "       'subtraction_canon_background'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/mamille2/anaconda/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train.loc[:,'best_pred_canon'] = train_predictions['is_canon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out\n",
    "train.to_pickle('/usr2/mamille2/fanfiction-project/output/emnlp2020_predictions/relationship_prediction_sample5400_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look into correct, incorrect predictions on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true negatives: 1432\n",
      "Number of true positives: 2207\n",
      "Number of false positives: 703\n",
      "Number of false negatives: 524\n"
     ]
    }
   ],
   "source": [
    "true_negatives = train[(train['best_pred_canon']==False) & (train['is_canon']==False)]\n",
    "true_positives = train[(train['best_pred_canon']==True) & (train['is_canon']==True)]\n",
    "false_positives = train[(train['best_pred_canon']==True) & (train['is_canon']==False)]\n",
    "false_negatives = train[(train['best_pred_canon']==False) & (train['is_canon']==True)]\n",
    "\n",
    "print(f'Number of true negatives: {len(true_negatives)}')\n",
    "print(f'Number of true positives: {len(true_positives)}')\n",
    "print(f'Number of false positives: {len(false_positives)}')\n",
    "print(f'Number of false negatives: {len(false_negatives)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
