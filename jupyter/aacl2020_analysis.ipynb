{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship prediction experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run logistic regression to predict romantic relationships, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400\n",
      "Index(['fic_id', 'pairing', 'pairing_embedding_unigrams_assertions_local_5',\n",
      "       'pairing_embedding_unigrams_assertions_local_10',\n",
      "       'pairing_embedding_unigrams_assertions_local_25',\n",
      "       'pairing_embedding_unigrams_assertions_local_50', 'relationship',\n",
      "       'selected_relationships', 'is_romantic', 'is_canon', 'is_mm',\n",
      "       'shape_10', 'pairing_embedding_embs_adapted_10',\n",
      "       'pairing_embedding_unigrams_quotes', 'dist_canon_combined',\n",
      "       'subtraction_canon_combined', 'dist_canon_bg', 'subtraction_canon_bg',\n",
      "       'dist_canon_aligned', 'subtraction_canon_aligned',\n",
      "       'pairing_embedding_embs_background_quotes',\n",
      "       'pairing_embedding_embs_combined_quotes',\n",
      "       'pairing_embedding_canon_embs_aligned',\n",
      "       'pairing_embedding_embs_aligned', 'pairing_embedding_embs_combined',\n",
      "       'pairing_embedding_canon_embs_combined',\n",
      "       'pairing_embedding_embs_background',\n",
      "       'pairing_embedding_canon_embs_background', 'dist_canon_background',\n",
      "       'subtraction_canon_background'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_pickle('/usr2/mamille2/fanfiction-project/data/features/relationship_prediction_assertion_sample5400.pkl')\n",
    "print(len(data))\n",
    "print(data.columns)\n",
    "\n",
    "pairings = data['pairing'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4866\n",
      "0.9011111111111111\n",
      "534\n",
      "Index(['fic_id', 'pairing', 'pairing_embedding_unigrams_assertions_local_5',\n",
      "       'pairing_embedding_unigrams_assertions_local_10',\n",
      "       'pairing_embedding_unigrams_assertions_local_25',\n",
      "       'pairing_embedding_unigrams_assertions_local_50', 'relationship',\n",
      "       'selected_relationships', 'is_romantic', 'is_canon', 'is_mm',\n",
      "       'shape_10', 'pairing_embedding_embs_adapted_10',\n",
      "       'pairing_embedding_unigrams_quotes', 'dist_canon_combined',\n",
      "       'subtraction_canon_combined', 'dist_canon_bg', 'subtraction_canon_bg',\n",
      "       'dist_canon_aligned', 'subtraction_canon_aligned',\n",
      "       'pairing_embedding_embs_background_quotes',\n",
      "       'pairing_embedding_embs_combined_quotes',\n",
      "       'pairing_embedding_canon_embs_aligned',\n",
      "       'pairing_embedding_embs_aligned', 'pairing_embedding_embs_combined',\n",
      "       'pairing_embedding_canon_embs_combined',\n",
      "       'pairing_embedding_embs_background',\n",
      "       'pairing_embedding_canon_embs_background', 'dist_canon_background',\n",
      "       'subtraction_canon_background'],\n",
      "      dtype='object')\n",
      "0.26921496095356295\n",
      "0.561241265926864\n",
      "0.3335388409371261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, test = train_test_split(data, test_size=0.1, random_state=9)\n",
    "train_ids, test_ids = train_test_split(data['fic_id'].unique(), test_size=0.1, random_state=11)\n",
    "# train_ids, test_ids = train_test_split(data['fic_id'].unique(), test_size=0.1, random_state=9)\n",
    "\n",
    "train = data[data['fic_id'].isin(train_ids)]\n",
    "test = data[data['fic_id'].isin(test_ids)]\n",
    "print(len(train))\n",
    "print(len(train)/ len(data))\n",
    "print(len(test))\n",
    "print(train.columns)\n",
    "print(sum(train['is_romantic']/len(train)))\n",
    "print(sum(train['is_canon']/len(train)))\n",
    "print(sum(train['is_mm']/len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tis_romantic: 0.795880149812734\n",
      "all\tis_canon: 0.6910112359550562\n",
      "all\tis_mm: 0.900749063670412\n",
      "\n",
      "all\tis_romantic: 0.7788072417465388\n",
      "all\tis_canon: 0.6852502662406815\n",
      "all\tis_mm: 0.8882321618743344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "X_train, y_train = {}, {}\n",
    "X_test, y_test = {}, {}\n",
    "\n",
    "add_features = True\n",
    "\n",
    "# for feature_set in ['unigrams', 'embs']:\n",
    "# for feature_set in ['unigrams_assertions_local_10', 'embs_adapted_10', 'embs_background_10']:\n",
    "# for feature_set in ['unigrams_quotes', 'unigrams_assertions_local_10']:\n",
    "# for feature_set in pairing_char_embs_fpath:\n",
    "# for feature_set in ['embs_combined', 'dist_canon_combined']:\n",
    "# for feature_set in ['embs_combined', 'subtraction_canon_combined']:\n",
    "# for feature_set in ['embs_background', 'dist_canon_background']:\n",
    "# for feature_set in ['embs_background', 'subtraction_canon_background']:\n",
    "# for feature_set in ['embs_combined', 'dist_canon_aligned']:\n",
    "# for feature_set in ['embs_combined', 'subtraction_canon_aligned']:\n",
    "# for feature_set in ['embs_combined', 'pairing_embedding_embs_combined_quotes']:\n",
    "# for feature_set in ['embs_background', 'embs_background_quotes', 'subtraction_canon_background']:\n",
    "for feature_set in ['embs_combined', 'embs_combined_quotes', 'subtraction_canon_combined']: # best results\n",
    "# for feature_set in ['embs_combined', 'embs_combined_quotes', 'dist_canon_combined']:\n",
    "# for feature_set in ['embs_combined', 'embs_combined_quotes']:\n",
    "# for feature_set in ['embs_combined']:\n",
    "# for feature_set in ['embs_combined', 'embs_combined_quotes', 'subtraction_canon_aligned']:\n",
    "# for feature_set in ['embs_combined', 'embs_combined_quotes', 'dist_canon_aligned']:\n",
    "\n",
    "    if feature_set.startswith('embs'):\n",
    "        X_train[feature_set] = np.vstack(train[f'pairing_embedding_{feature_set}'].tolist())\n",
    "        X_test[feature_set] = np.vstack(test[f'pairing_embedding_{feature_set}'].tolist())\n",
    "        \n",
    "    elif 'canon' in feature_set:\n",
    "        X_train[feature_set] = np.vstack(train[feature_set].tolist())\n",
    "        X_test[feature_set] = np.vstack(test[feature_set].tolist())\n",
    "        \n",
    "    elif feature_set.startswith('unigrams'):\n",
    "        X_train[feature_set] = scipy.sparse.vstack(train[f'pairing_embedding_{feature_set}'].tolist())\n",
    "        X_test[feature_set] = scipy.sparse.vstack(test[f'pairing_embedding_{feature_set}'].tolist())\n",
    "        \n",
    "    elif feature_set == 'unigrams+embs':\n",
    "        unigram_features = scipy.sparse.vstack(train[f'pairing_embedding_unigrams'].tolist())\n",
    "        emb_features = np.array(train[f'pairing_embedding_embs'].tolist())\n",
    "        X_train[feature_set] = scipy.sparse.hstack([unigram_features, emb_features])\n",
    "        \n",
    "        unigram_features = scipy.sparse.vstack(test[f'pairing_embedding_unigrams'].tolist())\n",
    "        emb_features = np.array(test[f'pairing_embedding_embs'].tolist())\n",
    "        X_test[feature_set] = scipy.sparse.hstack([unigram_features, emb_features])\n",
    "        \n",
    "    if add_features:\n",
    "        if 'unigrams' in ' '.join(feature_set):\n",
    "            X_train['all'] = scipy.sparse.hstack(list(X_train.values()))\n",
    "            X_test['all'] = scipy.sparse.hstack(list(X_test.values()))\n",
    "        \n",
    "        else:\n",
    "            X_train['all'] = np.hstack(list(X_train.values()))\n",
    "            X_test['all'] = np.hstack(list(X_test.values()))\n",
    "        \n",
    "y_train['is_romantic'] = train['is_romantic']\n",
    "y_train['is_canon'] = train['is_canon']\n",
    "y_train['is_mm'] = train['is_mm']\n",
    "\n",
    "y_test['is_romantic'] = test['is_romantic']\n",
    "y_test['is_canon'] = test['is_canon']\n",
    "y_test['is_mm'] = test['is_mm']\n",
    "\n",
    "X_train.keys()\n",
    "\n",
    "# Per-instance score\n",
    "results = {}\n",
    "clf = {}\n",
    "\n",
    "# for feature_set in ['unigrams_assertions_local_10']:\n",
    "# for feature_set in ['embs_adapted_10']:\n",
    "# for feature_set in ['embs_aligned_10']:\n",
    "# for feature_set in ['embs_background_10']:\n",
    "# for feature_set in ['unigrams_assertions_local_10', 'embs_adapted_10', 'embs_background_10']:\n",
    "# for feature_set in ['unigrams_quotes']:\n",
    "# for feature_set in ['all']:\n",
    "# for feature_set in pairing_char_embs_fpath:\n",
    "for feature_set in ['all']:\n",
    "    results[f'{feature_set}_lr'] = {}\n",
    "    clf[f'{feature_set}_lr'] = {}\n",
    "    for key in y_test:\n",
    "\n",
    "        clf[f'{feature_set}_lr'][key] = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "        clf[f'{feature_set}_lr'][key].fit(X_train[feature_set], y_train[key])\n",
    "        results[f'{feature_set}_lr'][key] = clf[f'{feature_set}_lr'][key].score(X_test[feature_set], y_test[key])\n",
    "        print(f'{feature_set}\\t{key}: {results[f\"{feature_set}_lr\"][key]}')\n",
    "        \n",
    "    print()\n",
    "\n",
    "# Group instance IDs\n",
    "test_groups = test.reset_index().groupby('fic_id').groups\n",
    "len(test_groups)\n",
    "\n",
    "# Per-fic score\n",
    "perfic_results = {}\n",
    "predictions = {}\n",
    "\n",
    "# for feature_set in ['unigrams_assertions_local_10']:\n",
    "# for feature_set in ['embs_adapted_10']:\n",
    "# for feature_set in ['embs_background_10']:\n",
    "# for feature_set in ['unigrams_assertions_local_10', 'embs_adapted_10', 'embs_background_10']:\n",
    "# for feature_set in ['unigrams_quotes']:\n",
    "for feature_set in ['all']:\n",
    "# for feature_set in pairing_char_embs_fpath:\n",
    "    perfic_results[f'{feature_set}_lr'] = {}\n",
    "    for key in y_test:\n",
    "\n",
    "        predictions[key] = clf[f'{feature_set}_lr'][key].predict(X_test[feature_set])\n",
    "        \n",
    "        avg_acc = []\n",
    "        for fic_id, indices in test_groups.items():\n",
    "            avg_acc.append(np.mean([predictions[key][i]==y_test[key].tolist()[i] for i in indices]))\n",
    "        \n",
    "        perfic_results[f'{feature_set}_lr'][key] = np.mean(avg_acc)\n",
    "        print(f'{feature_set}\\t{key}: {perfic_results[f\"{feature_set}_lr\"][key]}')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tis_romantic: 0.8211190053285967\n",
      "all\tis_canon: 0.7396092362344583\n",
      "all\tis_mm: 0.9221432800473652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group instance IDs\n",
    "train_groups = train.reset_index().groupby('fic_id').groups\n",
    "len(train_groups)\n",
    "\n",
    "# Per-fic score\n",
    "train_perfic_results = {}\n",
    "train_predictions = {}\n",
    "\n",
    "# for feature_set in ['unigrams_assertions_local_10']:\n",
    "# for feature_set in ['embs_adapted_10']:\n",
    "# for feature_set in ['embs_background_10']:\n",
    "# for feature_set in ['unigrams_assertions_local_10', 'embs_adapted_10', 'embs_background_10']:\n",
    "# for feature_set in ['unigrams_quotes']:\n",
    "for feature_set in ['all']:\n",
    "# for feature_set in pairing_char_embs_fpath:\n",
    "    train_perfic_results[f'{feature_set}_lr'] = {}\n",
    "    for key in y_train:\n",
    "\n",
    "        train_predictions[key] = clf[f'{feature_set}_lr'][key].predict(X_train[feature_set])\n",
    "        \n",
    "        train_avg_acc = []\n",
    "        for fic_id, indices in train_groups.items():\n",
    "            train_avg_acc.append(np.mean([train_predictions[key][i]==y_train[key].tolist()[i] for i in indices]))\n",
    "        \n",
    "        train_perfic_results[f'{feature_set}_lr'][key] = np.mean(train_avg_acc)\n",
    "        print(f'{feature_set}\\t{key}: {train_perfic_results[f\"{feature_set}_lr\"][key]}')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join training predictions with fic info, save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4866, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['all'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4866"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_predictions['is_canon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4866"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fic_id', 'pairing', 'pairing_embedding_unigrams_assertions_local_5',\n",
       "       'pairing_embedding_unigrams_assertions_local_10',\n",
       "       'pairing_embedding_unigrams_assertions_local_25',\n",
       "       'pairing_embedding_unigrams_assertions_local_50', 'relationship',\n",
       "       'selected_relationships', 'is_romantic', 'is_canon', 'is_mm',\n",
       "       'shape_10', 'pairing_embedding_embs_adapted_10',\n",
       "       'pairing_embedding_unigrams_quotes', 'dist_canon_combined',\n",
       "       'subtraction_canon_combined', 'dist_canon_bg', 'subtraction_canon_bg',\n",
       "       'dist_canon_aligned', 'subtraction_canon_aligned',\n",
       "       'pairing_embedding_embs_background_quotes',\n",
       "       'pairing_embedding_embs_combined_quotes',\n",
       "       'pairing_embedding_canon_embs_aligned',\n",
       "       'pairing_embedding_embs_aligned', 'pairing_embedding_embs_combined',\n",
       "       'pairing_embedding_canon_embs_combined',\n",
       "       'pairing_embedding_embs_background',\n",
       "       'pairing_embedding_canon_embs_background', 'dist_canon_background',\n",
       "       'subtraction_canon_background'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/mamille2/anaconda/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train.loc[:,'best_pred_canon'] = train_predictions['is_canon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out\n",
    "train.to_pickle('/usr2/mamille2/fanfiction-project/output/emnlp2020_predictions/relationship_prediction_sample5400_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look into correct, incorrect predictions on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4866, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training set predictions\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_pickle('/usr2/mamille2/fanfiction-project/output/emnlp2020_predictions/relationship_prediction_sample5400_train.pkl')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true negatives: 1432\n",
      "Number of true positives: 2207\n",
      "Number of false positives: 703\n",
      "Number of false negatives: 524\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "true_negatives = train[(train['best_pred_canon']==False) & (train['is_canon']==False)]\n",
    "true_positives = train[(train['best_pred_canon']==True) & (train['is_canon']==True)]\n",
    "false_positives = train[(train['best_pred_canon']==True) & (train['is_canon']==False)]\n",
    "false_negatives = train[(train['best_pred_canon']==False) & (train['is_canon']==True)]\n",
    "\n",
    "print(f'Number of true negatives: {len(true_negatives)}')\n",
    "print(f'Number of true positives: {len(true_positives)}')\n",
    "print(f'Number of false positives: {len(false_positives)}')\n",
    "print(f'Number of false negatives: {len(false_negatives)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fic_id', 'pairing', 'pairing_embedding_unigrams_assertions_local_5',\n",
       "       'pairing_embedding_unigrams_assertions_local_10',\n",
       "       'pairing_embedding_unigrams_assertions_local_25',\n",
       "       'pairing_embedding_unigrams_assertions_local_50', 'relationship',\n",
       "       'selected_relationships', 'is_romantic', 'is_canon', 'is_mm',\n",
       "       'shape_10', 'pairing_embedding_embs_adapted_10',\n",
       "       'pairing_embedding_unigrams_quotes', 'dist_canon_combined',\n",
       "       'subtraction_canon_combined', 'dist_canon_bg', 'subtraction_canon_bg',\n",
       "       'dist_canon_aligned', 'subtraction_canon_aligned',\n",
       "       'pairing_embedding_embs_background_quotes',\n",
       "       'pairing_embedding_embs_combined_quotes',\n",
       "       'pairing_embedding_canon_embs_aligned',\n",
       "       'pairing_embedding_embs_aligned', 'pairing_embedding_embs_combined',\n",
       "       'pairing_embedding_canon_embs_combined',\n",
       "       'pairing_embedding_embs_background',\n",
       "       'pairing_embedding_canon_embs_background', 'dist_canon_background',\n",
       "       'subtraction_canon_background', 'best_pred_canon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fic_id</th>\n",
       "      <th>pairing</th>\n",
       "      <th>best_pred_canon</th>\n",
       "      <th>is_canon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>10901745</td>\n",
       "      <td>(draco, harry)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>15682923</td>\n",
       "      <td>(ginny, harry)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>239144</td>\n",
       "      <td>(draco, harry)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>12199506</td>\n",
       "      <td>(draco, hermione)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>13098939</td>\n",
       "      <td>(hermione, ron)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fic_id            pairing  best_pred_canon  is_canon\n",
       "1895  10901745     (draco, harry)            False     False\n",
       "4861  15682923     (ginny, harry)            False     False\n",
       "2235    239144     (draco, harry)            False     False\n",
       "2866  12199506  (draco, hermione)            False     False\n",
       "217   13098939    (hermione, ron)            False     False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s = false_positives.sample(5, random_state=15)\n",
    "# s = false_negatives.sample(5, random_state=15)\n",
    "# s = true_positives.sample(5, random_state=15)\n",
    "s = true_negatives.sample(5, random_state=15)\n",
    "s.loc[:, ['fic_id', 'pairing', 'best_pred_canon', 'is_canon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13098939\n",
      "('hermione', 'ron')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 118: expected 4 fields, saw 2407\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"It's probably going to be another hour at least,\" he thought to himself as he let his head hit the wall behind him and rubbed at his temples. He was pretty sure Draco was going to be fine, but he wasn't an expert at wizard law. That was Hermione's field and even though she tried to reassure him, he could see the worry on her face that something could possibly go horrible wrong. She sat inside with Ron and during breaks they would join Harry and catch him up quickly &amp; quietly before rushing back inside before the doors were locked again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ron and Hermione stood waiting for them at the bottom trying to clear away the press that had been screaming questions and flashing pictures. Not like either of the young men noticed. They looked into each other's eyes before rushing back inside the ministry's courthouse and finding the nearest floo asking to go to Hogwarts. As the green flames faded the other contributing factors of the golden trio rushed along into the fireplace following the others.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>It was almost time for breakfast and if he missed it, Hermione would have his head on a pike. Not before having the entire school search for him first, of course. He checked the time again, then peeped into Draco's room to see he was still fast asleep. If Harry were in his position he would want to rest. Draco hadn't had proper rest in more than 3 months. Harry decided he would let him sleep. He rushed to the door quietly and left, headed towards the dinning hall. Once he entered he noticed Hermione and Ron sitting in their usual places at the Gryffindor table and breathed a sigh of relief before joining them and piling his plate with almost as much food as Ron started with.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Harry smiled that lopsided grin then turned back to Ron and Hermione and what seemed to be the rest of the Gryffindor table.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>\"I'll go get Ron and Hermione. Take them to our room to wait. Love you,\" Harry said before heading to Gryffindor Tower to look for his friends.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Harry impatiently gave the portrait the password before scrambling quickly through the hole it left. Ron and Hermione sat at the fireplace having an in depth discussion about...him?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>\"-good for each other, Ronald,\" said Hermione smiling.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>\"Yeah, but you have to admit it's a little weird not having Malfoy take jabs at us, 'Mione,\" Ron responded still focused on his game of wizarding chess with Seamus as Hermione thumbed through a book Harry had seen her finish time and time again. He walked up seemingly unnoticed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>\"Checkmate,\" Ron said as his remaining pieces began to do a small dance. He stood up, parting Seamus on the shoulder and making his way over to the door. \"C'mon 'Mione we're wasting time. He's more jittery than you during finals week.\" Harry looked up surprised that anyone had noticed. Hermione marked her place and closed her book again, standing up.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text\n",
       "3                                                                                                                                               \"It's probably going to be another hour at least,\" he thought to himself as he let his head hit the wall behind him and rubbed at his temples. He was pretty sure Draco was going to be fine, but he wasn't an expert at wizard law. That was Hermione's field and even though she tried to reassure him, he could see the worry on her face that something could possibly go horrible wrong. She sat inside with Ron and during breaks they would join Harry and catch him up quickly & quietly before rushing back inside before the doors were locked again.\n",
       "9                                                                                                                                                                                                                                      Ron and Hermione stood waiting for them at the bottom trying to clear away the press that had been screaming questions and flashing pictures. Not like either of the young men noticed. They looked into each other's eyes before rushing back inside the ministry's courthouse and finding the nearest floo asking to go to Hogwarts. As the green flames faded the other contributing factors of the golden trio rushed along into the fireplace following the others.\n",
       "39  It was almost time for breakfast and if he missed it, Hermione would have his head on a pike. Not before having the entire school search for him first, of course. He checked the time again, then peeped into Draco's room to see he was still fast asleep. If Harry were in his position he would want to rest. Draco hadn't had proper rest in more than 3 months. Harry decided he would let him sleep. He rushed to the door quietly and left, headed towards the dinning hall. Once he entered he noticed Hermione and Ron sitting in their usual places at the Gryffindor table and breathed a sigh of relief before joining them and piling his plate with almost as much food as Ron started with.\n",
       "51                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Harry smiled that lopsided grin then turned back to Ron and Hermione and what seemed to be the rest of the Gryffindor table.\n",
       "78                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \"I'll go get Ron and Hermione. Take them to our room to wait. Love you,\" Harry said before heading to Gryffindor Tower to look for his friends.\n",
       "81                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Harry impatiently gave the portrait the password before scrambling quickly through the hole it left. Ron and Hermione sat at the fireplace having an in depth discussion about...him?\n",
       "82                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \"-good for each other, Ronald,\" said Hermione smiling.\n",
       "83                                                                                                                                                                                                                                                                                                                                                                                                                      \"Yeah, but you have to admit it's a little weird not having Malfoy take jabs at us, 'Mione,\" Ron responded still focused on his game of wizarding chess with Seamus as Hermione thumbed through a book Harry had seen her finish time and time again. He walked up seemingly unnoticed.\n",
       "89                                                                                                                                                                                                                                                                                                                                             \"Checkmate,\" Ron said as his remaining pieces began to do a small dance. He stood up, parting Seamus on the shoulder and making his way over to the door. \"C'mon 'Mione we're wasting time. He's more jittery than you during finals week.\" Harry looked up surprised that anyone had noticed. Hermione marked her place and closed her book again, standing up."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join with story texts, find 10-word context windows around characters\n",
    "import os\n",
    "import csv\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "fic_idx = 4\n",
    "fic_id = s['fic_id'].tolist()[fic_idx]\n",
    "print(fic_id)\n",
    "pairing = s['pairing'].tolist()[fic_idx]\n",
    "print(pairing)\n",
    "\n",
    "story_dirpath = '/usr2/mamille2/fanfiction-project/data/ao3/harrypotter/emnlp_dataset_6k/fics'\n",
    "fic_fpath = os.path.join(story_dirpath, f'{fic_id}.csv')\n",
    "fic = pd.read_csv(fic_fpath, error_bad_lines=False)\n",
    "\n",
    "def pairing_in_text(text):\n",
    "    return (pairing[0] in text.lower()) and (pairing[1] in text.lower())\n",
    "\n",
    "pairing_present = fic.loc[fic['text'].map(pairing_in_text), ['text']]\n",
    "pairing_present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label distributions across character pairings\n",
    "Are there any non-romantic Harry/Draco fics, for example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pairing            is_canon\n",
       "(draco, harry)     False       587\n",
       "                   True        224\n",
       "(draco, hermione)  False       263\n",
       "                   True        548\n",
       "(ginny, harry)     False       600\n",
       "                   True        217\n",
       "(harry, hermione)  False        31\n",
       "                   True        780\n",
       "(harry, ron)       False        31\n",
       "                   True        781\n",
       "(hermione, ron)    False       623\n",
       "                   True        181\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['pairing', 'is_canon']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style lexicon across is_canon classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true negatives: 1432\n",
      "Number of true positives: 2207\n",
      "Number of false positives: 703\n",
      "Number of false negatives: 524\n"
     ]
    }
   ],
   "source": [
    "# Load training set predictions\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_pickle('/usr2/mamille2/fanfiction-project/output/emnlp2020_predictions/relationship_prediction_sample5400_train.pkl')\n",
    "train.shape\n",
    "\n",
    "# Confusion matrix\n",
    "\n",
    "true_negatives = train[(train['best_pred_canon']==False) & (train['is_canon']==False)]\n",
    "true_positives = train[(train['best_pred_canon']==True) & (train['is_canon']==True)]\n",
    "false_positives = train[(train['best_pred_canon']==True) & (train['is_canon']==False)]\n",
    "false_negatives = train[(train['best_pred_canon']==False) & (train['is_canon']==True)]\n",
    "\n",
    "print(f'Number of true negatives: {len(true_negatives)}')\n",
    "print(f'Number of true positives: {len(true_positives)}')\n",
    "print(f'Number of false positives: {len(false_positives)}')\n",
    "print(f'Number of false negatives: {len(false_negatives)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aaaaaaah': {'valence': 0.479,\n",
       "  'arousal': 0.606,\n",
       "  'dominance': 0.29100000000000004},\n",
       " 'aaaah': {'valence': 0.52, 'arousal': 0.636, 'dominance': 0.282},\n",
       " 'aardvark': {'valence': 0.42700000000000005,\n",
       "  'arousal': 0.49,\n",
       "  'dominance': 0.43700000000000006},\n",
       " 'aback': {'valence': 0.385,\n",
       "  'arousal': 0.40700000000000003,\n",
       "  'dominance': 0.28800000000000003},\n",
       " 'abacus': {'valence': 0.51, 'arousal': 0.276, 'dominance': 0.485},\n",
       " 'abalone': {'valence': 0.5,\n",
       "  'arousal': 0.48,\n",
       "  'dominance': 0.41200000000000003},\n",
       " 'abandon': {'valence': 0.052000000000000005,\n",
       "  'arousal': 0.519,\n",
       "  'dominance': 0.245},\n",
       " 'abandoned': {'valence': 0.046,\n",
       "  'arousal': 0.48100000000000004,\n",
       "  'dominance': 0.13},\n",
       " 'abandonment': {'valence': 0.128,\n",
       "  'arousal': 0.43,\n",
       "  'dominance': 0.20199999999999999},\n",
       " 'abashed': {'valence': 0.177, 'arousal': 0.644, 'dominance': 0.307},\n",
       " 'abate': {'valence': 0.255, 'arousal': 0.696, 'dominance': 0.604},\n",
       " 'abatement': {'valence': 0.38799999999999996,\n",
       "  'arousal': 0.33799999999999997,\n",
       "  'dominance': 0.336},\n",
       " 'abba': {'valence': 0.562, 'arousal': 0.5, 'dominance': 0.48},\n",
       " 'abbey': {'valence': 0.58,\n",
       "  'arousal': 0.36700000000000005,\n",
       "  'dominance': 0.444},\n",
       " 'abbot': {'valence': 0.42700000000000005,\n",
       "  'arousal': 0.321,\n",
       "  'dominance': 0.483},\n",
       " 'abbreviate': {'valence': 0.531, 'arousal': 0.375, 'dominance': 0.33},\n",
       " 'abbreviation': {'valence': 0.469, 'arousal': 0.306, 'dominance': 0.345},\n",
       " 'abdomen': {'valence': 0.469,\n",
       "  'arousal': 0.462,\n",
       "  'dominance': 0.47100000000000003},\n",
       " 'abdominal': {'valence': 0.49, 'arousal': 0.456, 'dominance': 0.445},\n",
       " 'abduct': {'valence': 0.17300000000000001,\n",
       "  'arousal': 0.72,\n",
       "  'dominance': 0.615},\n",
       " 'abduction': {'valence': 0.062,\n",
       "  'arousal': 0.99,\n",
       "  'dominance': 0.6729999999999999},\n",
       " 'aberrant': {'valence': 0.146, 'arousal': 0.765, 'dominance': 0.431},\n",
       " 'aberration': {'valence': 0.125,\n",
       "  'arousal': 0.816,\n",
       "  'dominance': 0.41700000000000004},\n",
       " 'abeyance': {'valence': 0.33, 'arousal': 0.51, 'dominance': 0.292},\n",
       " 'abhor': {'valence': 0.125, 'arousal': 0.602, 'dominance': 0.349},\n",
       " 'abhorrence': {'valence': 0.16699999999999998,\n",
       "  'arousal': 0.684,\n",
       "  'dominance': 0.42},\n",
       " 'abhorrent': {'valence': 0.22899999999999998,\n",
       "  'arousal': 0.75,\n",
       "  'dominance': 0.474},\n",
       " 'abide': {'valence': 0.635, 'arousal': 0.354, 'dominance': 0.705},\n",
       " 'abiding': {'valence': 0.7959999999999999,\n",
       "  'arousal': 0.327,\n",
       "  'dominance': 0.75},\n",
       " 'ability': {'valence': 0.875, 'arousal': 0.51, 'dominance': 0.816},\n",
       " 'abject': {'valence': 0.354,\n",
       "  'arousal': 0.59,\n",
       "  'dominance': 0.41700000000000004},\n",
       " 'ablation': {'valence': 0.418, 'arousal': 0.5, 'dominance': 0.5},\n",
       " 'ablaze': {'valence': 0.24, 'arousal': 0.847, 'dominance': 0.525},\n",
       " 'able': {'valence': 0.7859999999999999, 'arousal': 0.5, 'dominance': 0.81},\n",
       " 'abnormal': {'valence': 0.13699999999999998,\n",
       "  'arousal': 0.604,\n",
       "  'dominance': 0.309},\n",
       " 'abnormality': {'valence': 0.092,\n",
       "  'arousal': 0.655,\n",
       "  'dominance': 0.38299999999999995},\n",
       " 'aboard': {'valence': 0.698,\n",
       "  'arousal': 0.284,\n",
       "  'dominance': 0.48100000000000004},\n",
       " 'abode': {'valence': 0.62, 'arousal': 0.302, 'dominance': 0.5},\n",
       " 'abolish': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.615,\n",
       "  'dominance': 0.529},\n",
       " 'abolition': {'valence': 0.32299999999999995,\n",
       "  'arousal': 0.69,\n",
       "  'dominance': 0.529},\n",
       " 'abominable': {'valence': 0.12,\n",
       "  'arousal': 0.731,\n",
       "  'dominance': 0.48200000000000004},\n",
       " 'abominate': {'valence': 0.198,\n",
       "  'arousal': 0.7879999999999999,\n",
       "  'dominance': 0.366},\n",
       " 'abomination': {'valence': 0.078, 'arousal': 0.755, 'dominance': 0.518},\n",
       " 'aboriginal': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.42700000000000005,\n",
       "  'dominance': 0.542},\n",
       " 'abort': {'valence': 0.153,\n",
       "  'arousal': 0.6859999999999999,\n",
       "  'dominance': 0.429},\n",
       " 'abortion': {'valence': 0.08199999999999999,\n",
       "  'arousal': 0.77,\n",
       "  'dominance': 0.28300000000000003},\n",
       " 'abortive': {'valence': 0.09,\n",
       "  'arousal': 0.7759999999999999,\n",
       "  'dominance': 0.28},\n",
       " 'abound': {'valence': 0.7040000000000001,\n",
       "  'arousal': 0.49,\n",
       "  'dominance': 0.6809999999999999},\n",
       " 'abovementioned': {'valence': 0.541, 'arousal': 0.298, 'dominance': 0.509},\n",
       " 'abracadabra': {'valence': 0.6729999999999999,\n",
       "  'arousal': 0.632,\n",
       "  'dominance': 0.434},\n",
       " 'abrasion': {'valence': 0.406,\n",
       "  'arousal': 0.5920000000000001,\n",
       "  'dominance': 0.441},\n",
       " 'abrasive': {'valence': 0.392, 'arousal': 0.61, 'dominance': 0.593},\n",
       " 'abreast': {'valence': 0.635, 'arousal': 0.38, 'dominance': 0.519},\n",
       " 'abroad': {'valence': 0.677, 'arousal': 0.596, 'dominance': 0.561},\n",
       " 'abrogate': {'valence': 0.327, 'arousal': 0.51, 'dominance': 0.594},\n",
       " 'abrupt': {'valence': 0.271,\n",
       "  'arousal': 0.8190000000000001,\n",
       "  'dominance': 0.545},\n",
       " 'abruptly': {'valence': 0.25,\n",
       "  'arousal': 0.8079999999999999,\n",
       "  'dominance': 0.556},\n",
       " 'abscess': {'valence': 0.154, 'arousal': 0.451, 'dominance': 0.349},\n",
       " 'absence': {'valence': 0.153, 'arousal': 0.235, 'dominance': 0.266},\n",
       " 'absent': {'valence': 0.177,\n",
       "  'arousal': 0.221,\n",
       "  'dominance': 0.11599999999999999},\n",
       " 'absentee': {'valence': 0.235,\n",
       "  'arousal': 0.33,\n",
       "  'dominance': 0.27899999999999997},\n",
       " 'absenteeism': {'valence': 0.40399999999999997,\n",
       "  'arousal': 0.273,\n",
       "  'dominance': 0.35700000000000004},\n",
       " 'absinthe': {'valence': 0.48100000000000004,\n",
       "  'arousal': 0.51,\n",
       "  'dominance': 0.462},\n",
       " 'absolute': {'valence': 0.526,\n",
       "  'arousal': 0.51,\n",
       "  'dominance': 0.8270000000000001},\n",
       " 'absolution': {'valence': 0.715, 'arousal': 0.5, 'dominance': 0.664},\n",
       " 'absolve': {'valence': 0.684, 'arousal': 0.449, 'dominance': 0.66},\n",
       " 'absorb': {'valence': 0.469,\n",
       "  'arousal': 0.5579999999999999,\n",
       "  'dominance': 0.67},\n",
       " 'absorbed': {'valence': 0.49,\n",
       "  'arousal': 0.47100000000000003,\n",
       "  'dominance': 0.519},\n",
       " 'absorbent': {'valence': 0.552,\n",
       "  'arousal': 0.39399999999999996,\n",
       "  'dominance': 0.718},\n",
       " 'absorbing': {'valence': 0.49, 'arousal': 0.49, 'dominance': 0.578},\n",
       " 'absorption': {'valence': 0.609,\n",
       "  'arousal': 0.42200000000000004,\n",
       "  'dominance': 0.446},\n",
       " 'abstain': {'valence': 0.385,\n",
       "  'arousal': 0.385,\n",
       "  'dominance': 0.42700000000000005},\n",
       " 'abstention': {'valence': 0.271, 'arousal': 0.264, 'dominance': 0.509},\n",
       " 'abstinence': {'valence': 0.26, 'arousal': 0.392, 'dominance': 0.429},\n",
       " 'abstract': {'valence': 0.43799999999999994,\n",
       "  'arousal': 0.292,\n",
       "  'dominance': 0.444},\n",
       " 'abstraction': {'valence': 0.469, 'arousal': 0.439, 'dominance': 0.525},\n",
       " 'absurd': {'valence': 0.188,\n",
       "  'arousal': 0.6559999999999999,\n",
       "  'dominance': 0.284},\n",
       " 'absurdity': {'valence': 0.115,\n",
       "  'arousal': 0.528,\n",
       "  'dominance': 0.22699999999999998},\n",
       " 'abundance': {'valence': 0.812, 'arousal': 0.69, 'dominance': 0.852},\n",
       " 'abundant': {'valence': 0.958, 'arousal': 0.59, 'dominance': 0.76},\n",
       " 'abuse': {'valence': 0.071, 'arousal': 0.873, 'dominance': 0.469},\n",
       " 'abused': {'valence': 0.021,\n",
       "  'arousal': 0.8740000000000001,\n",
       "  'dominance': 0.235},\n",
       " 'abusive': {'valence': 0.125,\n",
       "  'arousal': 0.903,\n",
       "  'dominance': 0.5670000000000001},\n",
       " 'abutment': {'valence': 0.5, 'arousal': 0.265, 'dominance': 0.616},\n",
       " 'aby': {'valence': 0.385, 'arousal': 0.452, 'dominance': 0.368},\n",
       " 'abysmal': {'valence': 0.25, 'arousal': 0.71, 'dominance': 0.598},\n",
       " 'abyss': {'valence': 0.353,\n",
       "  'arousal': 0.725,\n",
       "  'dominance': 0.29600000000000004},\n",
       " 'academic': {'valence': 0.7809999999999999,\n",
       "  'arousal': 0.42,\n",
       "  'dominance': 0.812},\n",
       " 'academy': {'valence': 0.7040000000000001,\n",
       "  'arousal': 0.473,\n",
       "  'dominance': 0.792},\n",
       " 'accede': {'valence': 0.698, 'arousal': 0.51, 'dominance': 0.537},\n",
       " 'accelerant': {'valence': 0.643,\n",
       "  'arousal': 0.8440000000000001,\n",
       "  'dominance': 0.802},\n",
       " 'accelerate': {'valence': 0.615, 'arousal': 0.902, 'dominance': 0.759},\n",
       " 'accelerated': {'valence': 0.61, 'arousal': 0.812, 'dominance': 0.682},\n",
       " 'acceleration': {'valence': 0.7040000000000001,\n",
       "  'arousal': 0.905,\n",
       "  'dominance': 0.843},\n",
       " 'accelerator': {'valence': 0.593, 'arousal': 0.83, 'dominance': 0.812},\n",
       " 'accent': {'valence': 0.598,\n",
       "  'arousal': 0.35700000000000004,\n",
       "  'dominance': 0.509},\n",
       " 'accentuate': {'valence': 0.6729999999999999,\n",
       "  'arousal': 0.556,\n",
       "  'dominance': 0.667},\n",
       " 'accept': {'valence': 0.847,\n",
       "  'arousal': 0.28600000000000003,\n",
       "  'dominance': 0.565},\n",
       " 'acceptable': {'valence': 0.812,\n",
       "  'arousal': 0.28600000000000003,\n",
       "  'dominance': 0.583},\n",
       " 'acceptance': {'valence': 0.833, 'arousal': 0.287, 'dominance': 0.755},\n",
       " 'acceptances': {'valence': 0.847, 'arousal': 0.413, 'dominance': 0.648},\n",
       " 'access': {'valence': 0.7140000000000001,\n",
       "  'arousal': 0.47200000000000003,\n",
       "  'dominance': 0.5670000000000001},\n",
       " 'accessible': {'valence': 0.7959999999999999,\n",
       "  'arousal': 0.41,\n",
       "  'dominance': 0.645},\n",
       " 'accession': {'valence': 0.612,\n",
       "  'arousal': 0.38299999999999995,\n",
       "  'dominance': 0.636},\n",
       " 'accessory': {'valence': 0.562, 'arousal': 0.292, 'dominance': 0.445},\n",
       " 'accident': {'valence': 0.125,\n",
       "  'arousal': 0.9079999999999999,\n",
       "  'dominance': 0.336},\n",
       " 'accidental': {'valence': 0.319, 'arousal': 0.784, 'dominance': 0.307},\n",
       " 'accidentally': {'valence': 0.33299999999999996,\n",
       "  'arousal': 0.741,\n",
       "  'dominance': 0.33299999999999996},\n",
       " 'acclaim': {'valence': 0.562, 'arousal': 0.809, 'dominance': 0.718},\n",
       " 'accolade': {'valence': 0.688, 'arousal': 0.591, 'dominance': 0.775},\n",
       " 'accommodate': {'valence': 0.8440000000000001,\n",
       "  'arousal': 0.375,\n",
       "  'dominance': 0.5660000000000001},\n",
       " 'accommodation': {'valence': 0.8170000000000001,\n",
       "  'arousal': 0.415,\n",
       "  'dominance': 0.5870000000000001},\n",
       " 'accompaniment': {'valence': 0.74, 'arousal': 0.479, 'dominance': 0.695},\n",
       " 'accompany': {'valence': 0.833, 'arousal': 0.406, 'dominance': 0.585},\n",
       " 'accompanying': {'valence': 0.787,\n",
       "  'arousal': 0.46,\n",
       "  'dominance': 0.5820000000000001},\n",
       " 'accomplice': {'valence': 0.408, 'arousal': 0.58, 'dominance': 0.51},\n",
       " 'accomplish': {'valence': 0.929,\n",
       "  'arousal': 0.6729999999999999,\n",
       "  'dominance': 0.816},\n",
       " 'accomplished': {'valence': 0.87,\n",
       "  'arousal': 0.52,\n",
       "  'dominance': 0.7979999999999999},\n",
       " 'accomplishment': {'valence': 0.917,\n",
       "  'arousal': 0.6940000000000001,\n",
       "  'dominance': 0.888},\n",
       " 'accord': {'valence': 0.898, 'arousal': 0.264, 'dominance': 0.382},\n",
       " 'accordance': {'valence': 0.659, 'arousal': 0.349, 'dominance': 0.6},\n",
       " 'accordion': {'valence': 0.604, 'arousal': 0.49, 'dominance': 0.361},\n",
       " 'account': {'valence': 0.531,\n",
       "  'arousal': 0.34700000000000003,\n",
       "  'dominance': 0.47200000000000003},\n",
       " 'accountability': {'valence': 0.755, 'arousal': 0.537, 'dominance': 0.833},\n",
       " 'accountable': {'valence': 0.7090000000000001,\n",
       "  'arousal': 0.282,\n",
       "  'dominance': 0.777},\n",
       " 'accountant': {'valence': 0.625, 'arousal': 0.45, 'dominance': 0.639},\n",
       " 'accounting': {'valence': 0.552, 'arousal': 0.39, 'dominance': 0.677},\n",
       " 'accounts': {'valence': 0.5920000000000001,\n",
       "  'arousal': 0.34,\n",
       "  'dominance': 0.47100000000000003},\n",
       " 'accredited': {'valence': 0.669, 'arousal': 0.479, 'dominance': 0.768},\n",
       " 'accretion': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.519,\n",
       "  'dominance': 0.672},\n",
       " 'accrue': {'valence': 0.52,\n",
       "  'arousal': 0.48100000000000004,\n",
       "  'dominance': 0.602},\n",
       " 'accueil': {'valence': 0.45, 'arousal': 0.451, 'dominance': 0.47},\n",
       " 'accumulate': {'valence': 0.573, 'arousal': 0.536, 'dominance': 0.607},\n",
       " 'accumulation': {'valence': 0.479, 'arousal': 0.527, 'dominance': 0.6},\n",
       " 'accuracy': {'valence': 0.604,\n",
       "  'arousal': 0.48100000000000004,\n",
       "  'dominance': 0.802},\n",
       " 'accurate': {'valence': 0.743, 'arousal': 0.36, 'dominance': 0.737},\n",
       " 'accursed': {'valence': 0.135, 'arousal': 0.745, 'dominance': 0.345},\n",
       " 'accusation': {'valence': 0.073, 'arousal': 0.718, 'dominance': 0.564},\n",
       " 'accusative': {'valence': 0.198,\n",
       "  'arousal': 0.755,\n",
       "  'dominance': 0.48200000000000004},\n",
       " 'accuse': {'valence': 0.133, 'arousal': 0.752, 'dominance': 0.5},\n",
       " 'accused': {'valence': 0.13, 'arousal': 0.67, 'dominance': 0.42},\n",
       " 'accuser': {'valence': 0.122, 'arousal': 0.779, 'dominance': 0.615},\n",
       " 'accusing': {'valence': 0.156, 'arousal': 0.745, 'dominance': 0.324},\n",
       " 'accustomed': {'valence': 0.542, 'arousal': 0.365, 'dominance': 0.441},\n",
       " 'ace': {'valence': 0.643, 'arousal': 0.48100000000000004, 'dominance': 0.546},\n",
       " 'acetic': {'valence': 0.33299999999999996,\n",
       "  'arousal': 0.42,\n",
       "  'dominance': 0.519},\n",
       " 'acetylene': {'valence': 0.306, 'arousal': 0.469, 'dominance': 0.509},\n",
       " 'ache': {'valence': 0.146, 'arousal': 0.76, 'dominance': 0.312},\n",
       " 'achieve': {'valence': 0.816, 'arousal': 0.545, 'dominance': 0.843},\n",
       " 'achieved': {'valence': 0.8959999999999999,\n",
       "  'arousal': 0.519,\n",
       "  'dominance': 0.775},\n",
       " 'achievement': {'valence': 0.8959999999999999,\n",
       "  'arousal': 0.8079999999999999,\n",
       "  'dominance': 0.759},\n",
       " 'aching': {'valence': 0.053, 'arousal': 0.88, 'dominance': 0.348},\n",
       " 'achy': {'valence': 0.16699999999999998, 'arousal': 0.84, 'dominance': 0.373},\n",
       " 'acid': {'valence': 0.265, 'arousal': 0.642, 'dominance': 0.5660000000000001},\n",
       " 'acidity': {'valence': 0.156,\n",
       "  'arousal': 0.6629999999999999,\n",
       "  'dominance': 0.36},\n",
       " 'acknowledge': {'valence': 0.7859999999999999,\n",
       "  'arousal': 0.37,\n",
       "  'dominance': 0.6609999999999999},\n",
       " 'acknowledged': {'valence': 0.7140000000000001,\n",
       "  'arousal': 0.44299999999999995,\n",
       "  'dominance': 0.765},\n",
       " 'acknowledgement': {'valence': 0.8190000000000001,\n",
       "  'arousal': 0.539,\n",
       "  'dominance': 0.83},\n",
       " 'acknowledgment': {'valence': 0.7959999999999999,\n",
       "  'arousal': 0.528,\n",
       "  'dominance': 0.777},\n",
       " 'acme': {'valence': 0.408, 'arousal': 0.435, 'dominance': 0.375},\n",
       " 'acne': {'valence': 0.16699999999999998,\n",
       "  'arousal': 0.474,\n",
       "  'dominance': 0.308},\n",
       " 'acorn': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.198,\n",
       "  'dominance': 0.192},\n",
       " 'acoustic': {'valence': 0.542, 'arousal': 0.462, 'dominance': 0.536},\n",
       " 'acoustics': {'valence': 0.611, 'arousal': 0.33, 'dominance': 0.509},\n",
       " 'acquaint': {'valence': 0.6459999999999999,\n",
       "  'arousal': 0.491,\n",
       "  'dominance': 0.639},\n",
       " 'acquaintance': {'valence': 0.6559999999999999,\n",
       "  'arousal': 0.29,\n",
       "  'dominance': 0.67},\n",
       " 'acquainted': {'valence': 0.9059999999999999,\n",
       "  'arousal': 0.358,\n",
       "  'dominance': 0.632},\n",
       " 'acquiescence': {'valence': 0.542,\n",
       "  'arousal': 0.48,\n",
       "  'dominance': 0.5539999999999999},\n",
       " 'acquire': {'valence': 0.833,\n",
       "  'arousal': 0.46799999999999997,\n",
       "  'dominance': 0.7},\n",
       " 'acquiring': {'valence': 0.735,\n",
       "  'arousal': 0.51,\n",
       "  'dominance': 0.8170000000000001},\n",
       " 'acquisition': {'valence': 0.698, 'arousal': 0.509, 'dominance': 0.736},\n",
       " 'acquisitions': {'valence': 0.773, 'arousal': 0.66, 'dominance': 0.79},\n",
       " 'acquit': {'valence': 0.583,\n",
       "  'arousal': 0.5710000000000001,\n",
       "  'dominance': 0.611},\n",
       " 'acquittal': {'valence': 0.76,\n",
       "  'arousal': 0.49700000000000005,\n",
       "  'dominance': 0.7},\n",
       " 'acre': {'valence': 0.583, 'arousal': 0.387, 'dominance': 0.423},\n",
       " 'acreage': {'valence': 0.741, 'arousal': 0.45, 'dominance': 0.528},\n",
       " 'acres': {'valence': 0.51, 'arousal': 0.363, 'dominance': 0.5},\n",
       " 'acrobat': {'valence': 0.708, 'arousal': 0.828, 'dominance': 0.602},\n",
       " 'acrylic': {'valence': 0.5820000000000001,\n",
       "  'arousal': 0.27899999999999997,\n",
       "  'dominance': 0.42},\n",
       " 'act': {'valence': 0.6559999999999999,\n",
       "  'arousal': 0.7040000000000001,\n",
       "  'dominance': 0.735},\n",
       " 'acting': {'valence': 0.698, 'arousal': 0.643, 'dominance': 0.5},\n",
       " 'action': {'valence': 0.76, 'arousal': 0.898, 'dominance': 0.802},\n",
       " 'action figure': {'valence': 0.615, 'arousal': 0.774, 'dominance': 0.611},\n",
       " 'actionable': {'valence': 0.6729999999999999,\n",
       "  'arousal': 0.7020000000000001,\n",
       "  'dominance': 0.613},\n",
       " 'activate': {'valence': 0.764,\n",
       "  'arousal': 0.65,\n",
       "  'dominance': 0.8059999999999999},\n",
       " 'activation': {'valence': 0.7809999999999999,\n",
       "  'arousal': 0.8,\n",
       "  'dominance': 0.754},\n",
       " 'active': {'valence': 0.847, 'arousal': 0.73, 'dominance': 0.731},\n",
       " 'activist': {'valence': 0.531, 'arousal': 0.653, 'dominance': 0.877},\n",
       " 'activity': {'valence': 0.701, 'arousal': 0.66, 'dominance': 0.807},\n",
       " 'actor': {'valence': 0.653, 'arousal': 0.561, 'dominance': 0.629},\n",
       " 'actress': {'valence': 0.633, 'arousal': 0.556, 'dominance': 0.596},\n",
       " 'actual': {'valence': 0.7290000000000001, 'arousal': 0.4, 'dominance': 0.716},\n",
       " 'actuality': {'valence': 0.75,\n",
       "  'arousal': 0.46399999999999997,\n",
       "  'dominance': 0.6},\n",
       " 'actuary': {'valence': 0.51,\n",
       "  'arousal': 0.40399999999999997,\n",
       "  'dominance': 0.491},\n",
       " 'acuity': {'valence': 0.469,\n",
       "  'arousal': 0.37799999999999995,\n",
       "  'dominance': 0.741},\n",
       " 'acumen': {'valence': 0.564, 'arousal': 0.66, 'dominance': 0.679},\n",
       " 'acupuncture': {'valence': 0.531,\n",
       "  'arousal': 0.324,\n",
       "  'dominance': 0.5489999999999999},\n",
       " 'acute': {'valence': 0.42700000000000005,\n",
       "  'arousal': 0.652,\n",
       "  'dominance': 0.534},\n",
       " 'acutely': {'valence': 0.41700000000000004,\n",
       "  'arousal': 0.5429999999999999,\n",
       "  'dominance': 0.491},\n",
       " 'ad': {'valence': 0.521, 'arousal': 0.705, 'dominance': 0.5579999999999999},\n",
       " 'adage': {'valence': 0.517,\n",
       "  'arousal': 0.415,\n",
       "  'dominance': 0.5660000000000001},\n",
       " 'adamant': {'valence': 0.344, 'arousal': 0.529, 'dominance': 0.575},\n",
       " 'adapt': {'valence': 0.74, 'arousal': 0.355, 'dominance': 0.551},\n",
       " 'adaptable': {'valence': 0.735,\n",
       "  'arousal': 0.423,\n",
       "  'dominance': 0.6409999999999999},\n",
       " 'adaptation': {'valence': 0.6629999999999999,\n",
       "  'arousal': 0.365,\n",
       "  'dominance': 0.609},\n",
       " 'add': {'valence': 0.728, 'arousal': 0.49, 'dominance': 0.5539999999999999},\n",
       " 'added': {'valence': 0.562, 'arousal': 0.405, 'dominance': 0.509},\n",
       " 'addendum': {'valence': 0.392, 'arousal': 0.37, 'dominance': 0.418},\n",
       " 'adder': {'valence': 0.38799999999999996,\n",
       "  'arousal': 0.461,\n",
       "  'dominance': 0.588},\n",
       " 'addict': {'valence': 0.075, 'arousal': 0.696, 'dominance': 0.327},\n",
       " 'addicted': {'valence': 0.156,\n",
       "  'arousal': 0.7120000000000001,\n",
       "  'dominance': 0.483},\n",
       " 'addiction': {'valence': 0.18,\n",
       "  'arousal': 0.8059999999999999,\n",
       "  'dominance': 0.42},\n",
       " 'addictive': {'valence': 0.302,\n",
       "  'arousal': 0.6829999999999999,\n",
       "  'dominance': 0.47200000000000003},\n",
       " 'addition': {'valence': 0.562,\n",
       "  'arousal': 0.373,\n",
       "  'dominance': 0.47100000000000003},\n",
       " 'additional': {'valence': 0.6729999999999999,\n",
       "  'arousal': 0.462,\n",
       "  'dominance': 0.526},\n",
       " 'additive': {'valence': 0.561, 'arousal': 0.633, 'dominance': 0.691},\n",
       " 'address': {'valence': 0.65,\n",
       "  'arousal': 0.327,\n",
       "  'dominance': 0.5670000000000001},\n",
       " 'addressee': {'valence': 0.622,\n",
       "  'arousal': 0.382,\n",
       "  'dominance': 0.5379999999999999},\n",
       " 'addresses': {'valence': 0.51, 'arousal': 0.354, 'dominance': 0.45},\n",
       " 'adept': {'valence': 0.594, 'arousal': 0.539, 'dominance': 0.789},\n",
       " 'adequacy': {'valence': 0.615,\n",
       "  'arousal': 0.435,\n",
       "  'dominance': 0.7020000000000001},\n",
       " 'adequate': {'valence': 0.8540000000000001,\n",
       "  'arousal': 0.264,\n",
       "  'dominance': 0.705},\n",
       " 'adhere': {'valence': 0.633,\n",
       "  'arousal': 0.33899999999999997,\n",
       "  'dominance': 0.5539999999999999},\n",
       " 'adherence': {'valence': 0.76, 'arousal': 0.307, 'dominance': 0.63},\n",
       " 'adherent': {'valence': 0.561, 'arousal': 0.385, 'dominance': 0.555},\n",
       " 'adhering': {'valence': 0.612, 'arousal': 0.561, 'dominance': 0.537},\n",
       " 'adhesion': {'valence': 0.521, 'arousal': 0.445, 'dominance': 0.586},\n",
       " 'adhesive': {'valence': 0.604, 'arousal': 0.35, 'dominance': 0.413},\n",
       " 'adieu': {'valence': 0.25,\n",
       "  'arousal': 0.47100000000000003,\n",
       "  'dominance': 0.342},\n",
       " 'adipose': {'valence': 0.33299999999999996,\n",
       "  'arousal': 0.35,\n",
       "  'dominance': 0.391},\n",
       " 'adjacency': {'valence': 0.365,\n",
       "  'arousal': 0.41700000000000004,\n",
       "  'dominance': 0.375},\n",
       " 'adjacent': {'valence': 0.645, 'arousal': 0.276, 'dominance': 0.536},\n",
       " 'adjective': {'valence': 0.57, 'arousal': 0.316, 'dominance': 0.569},\n",
       " 'adjoining': {'valence': 0.52,\n",
       "  'arousal': 0.4,\n",
       "  'dominance': 0.39299999999999996},\n",
       " 'adjourn': {'valence': 0.385, 'arousal': 0.456, 'dominance': 0.475},\n",
       " 'adjournment': {'valence': 0.43799999999999994,\n",
       "  'arousal': 0.51,\n",
       "  'dominance': 0.37},\n",
       " 'adjudicate': {'valence': 0.5589999999999999,\n",
       "  'arousal': 0.52,\n",
       "  'dominance': 0.6829999999999999},\n",
       " 'adjudication': {'valence': 0.551, 'arousal': 0.462, 'dominance': 0.691},\n",
       " 'adjunct': {'valence': 0.45899999999999996,\n",
       "  'arousal': 0.44,\n",
       "  'dominance': 0.426},\n",
       " 'adjust': {'valence': 0.647, 'arousal': 0.327, 'dominance': 0.638},\n",
       " 'adjuster': {'valence': 0.51, 'arousal': 0.54, 'dominance': 0.76},\n",
       " 'adjustment': {'valence': 0.59,\n",
       "  'arousal': 0.52,\n",
       "  'dominance': 0.6609999999999999},\n",
       " 'adjuvant': {'valence': 0.51, 'arousal': 0.5, 'dominance': 0.456},\n",
       " 'admin': {'valence': 0.688, 'arousal': 0.42, 'dominance': 0.8540000000000001},\n",
       " 'administer': {'valence': 0.635, 'arousal': 0.425, 'dominance': 0.86},\n",
       " 'administration': {'valence': 0.625,\n",
       "  'arousal': 0.40399999999999997,\n",
       "  'dominance': 0.7859999999999999},\n",
       " 'administrative': {'valence': 0.542, 'arousal': 0.415, 'dominance': 0.579},\n",
       " 'administrator': {'valence': 0.5379999999999999,\n",
       "  'arousal': 0.48,\n",
       "  'dominance': 0.902},\n",
       " 'admirable': {'valence': 0.929, 'arousal': 0.6, 'dominance': 0.87},\n",
       " 'admiral': {'valence': 0.8440000000000001,\n",
       "  'arousal': 0.49,\n",
       "  'dominance': 0.847},\n",
       " 'admiralty': {'valence': 0.594, 'arousal': 0.547, 'dominance': 0.733},\n",
       " 'admiration': {'valence': 0.9690000000000001,\n",
       "  'arousal': 0.583,\n",
       "  'dominance': 0.726},\n",
       " 'admire': {'valence': 0.867,\n",
       "  'arousal': 0.6920000000000001,\n",
       "  'dominance': 0.7040000000000001},\n",
       " 'admired': {'valence': 0.917, 'arousal': 0.56, 'dominance': 0.815},\n",
       " 'admirer': {'valence': 0.7959999999999999,\n",
       "  'arousal': 0.72,\n",
       "  'dominance': 0.65},\n",
       " 'admiring': {'valence': 0.867, 'arousal': 0.578, 'dominance': 0.629},\n",
       " 'admissibility': {'valence': 0.802, 'arousal': 0.58, 'dominance': 0.602},\n",
       " 'admissible': {'valence': 0.78, 'arousal': 0.528, 'dominance': 0.642},\n",
       " 'admission': {'valence': 0.802, 'arousal': 0.415, 'dominance': 0.732},\n",
       " 'admit': {'valence': 0.5379999999999999,\n",
       "  'arousal': 0.423,\n",
       "  'dominance': 0.667},\n",
       " 'admittance': {'valence': 0.69, 'arousal': 0.451, 'dominance': 0.598},\n",
       " 'admitted': {'valence': 0.72, 'arousal': 0.49, 'dominance': 0.767},\n",
       " 'admitting': {'valence': 0.62, 'arousal': 0.5, 'dominance': 0.546},\n",
       " 'admixture': {'valence': 0.45,\n",
       "  'arousal': 0.375,\n",
       "  'dominance': 0.43799999999999994},\n",
       " 'admonition': {'valence': 0.35700000000000004,\n",
       "  'arousal': 0.606,\n",
       "  'dominance': 0.455},\n",
       " 'ado': {'valence': 0.52, 'arousal': 0.423, 'dominance': 0.385},\n",
       " 'adobe': {'valence': 0.5, 'arousal': 0.319, 'dominance': 0.32799999999999996},\n",
       " 'adolescence': {'valence': 0.48700000000000004,\n",
       "  'arousal': 0.6940000000000001,\n",
       "  'dominance': 0.444},\n",
       " 'adolescent': {'valence': 0.7809999999999999,\n",
       "  'arousal': 0.68,\n",
       "  'dominance': 0.509},\n",
       " 'adopt': {'valence': 0.6940000000000001,\n",
       "  'arousal': 0.612,\n",
       "  'dominance': 0.701},\n",
       " 'adoption': {'valence': 0.625,\n",
       "  'arousal': 0.5660000000000001,\n",
       "  'dominance': 0.589},\n",
       " 'adoptive': {'valence': 0.531, 'arousal': 0.469, 'dominance': 0.52},\n",
       " 'adorable': {'valence': 0.9690000000000001,\n",
       "  'arousal': 0.519,\n",
       "  'dominance': 0.457},\n",
       " 'adoration': {'valence': 0.885,\n",
       "  'arousal': 0.6990000000000001,\n",
       "  'dominance': 0.708},\n",
       " 'adore': {'valence': 0.8540000000000001,\n",
       "  'arousal': 0.43799999999999994,\n",
       "  'dominance': 0.657},\n",
       " 'adoring': {'valence': 0.885,\n",
       "  'arousal': 0.62,\n",
       "  'dominance': 0.7170000000000001},\n",
       " 'adorn': {'valence': 0.91,\n",
       "  'arousal': 0.424,\n",
       "  'dominance': 0.48200000000000004},\n",
       " 'adornment': {'valence': 0.9179999999999999,\n",
       "  'arousal': 0.373,\n",
       "  'dominance': 0.377},\n",
       " 'adrenalin': {'valence': 0.865,\n",
       "  'arousal': 0.92,\n",
       "  'dominance': 0.7859999999999999},\n",
       " 'adrenaline': {'valence': 0.765, 'arousal': 0.965, 'dominance': 0.825},\n",
       " 'adrift': {'valence': 0.39799999999999996,\n",
       "  'arousal': 0.486,\n",
       "  'dominance': 0.23},\n",
       " 'adult': {'valence': 0.815, 'arousal': 0.491, 'dominance': 0.787},\n",
       " 'adulterated': {'valence': 0.188, 'arousal': 0.865, 'dominance': 0.37},\n",
       " 'adulterer': {'valence': 0.22899999999999998,\n",
       "  'arousal': 0.8140000000000001,\n",
       "  'dominance': 0.40700000000000003},\n",
       " 'adultery': {'valence': 0.12, 'arousal': 0.922, 'dominance': 0.51},\n",
       " 'adulthood': {'valence': 0.541,\n",
       "  'arousal': 0.45399999999999996,\n",
       "  'dominance': 0.652},\n",
       " 'advance': {'valence': 0.6729999999999999,\n",
       "  'arousal': 0.47200000000000003,\n",
       "  'dominance': 0.858},\n",
       " 'advanced': {'valence': 0.8440000000000001,\n",
       "  'arousal': 0.623,\n",
       "  'dominance': 0.797},\n",
       " 'advancement': {'valence': 0.7759999999999999,\n",
       "  'arousal': 0.65,\n",
       "  'dominance': 0.8390000000000001},\n",
       " 'advancing': {'valence': 0.929, 'arousal': 0.608, 'dominance': 0.812},\n",
       " 'advantage': {'valence': 0.917,\n",
       "  'arousal': 0.5479999999999999,\n",
       "  'dominance': 0.8590000000000001},\n",
       " 'advantageous': {'valence': 0.8370000000000001,\n",
       "  'arousal': 0.64,\n",
       "  'dominance': 0.789},\n",
       " 'advent': {'valence': 0.665, 'arousal': 0.56, 'dominance': 0.627},\n",
       " 'adventure': {'valence': 0.917, 'arousal': 0.857, 'dominance': 0.71},\n",
       " 'adventurer': {'valence': 0.7809999999999999,\n",
       "  'arousal': 0.8390000000000001,\n",
       "  'dominance': 0.868},\n",
       " 'adventures': {'valence': 0.812,\n",
       "  'arousal': 0.764,\n",
       "  'dominance': 0.7490000000000001},\n",
       " 'adventurous': {'valence': 0.9690000000000001,\n",
       "  'arousal': 0.898,\n",
       "  'dominance': 0.722},\n",
       " 'adversary': {'valence': 0.349, 'arousal': 0.777, 'dominance': 0.457},\n",
       " 'adverse': {'valence': 0.32299999999999995,\n",
       "  'arousal': 0.61,\n",
       "  'dominance': 0.385},\n",
       " 'adversity': {'valence': 0.276,\n",
       "  'arousal': 0.76,\n",
       "  'dominance': 0.5379999999999999},\n",
       " 'advertise': {'valence': 0.5, 'arousal': 0.529, 'dominance': 0.58},\n",
       " 'advertisement': {'valence': 0.6,\n",
       "  'arousal': 0.5660000000000001,\n",
       "  'dominance': 0.539},\n",
       " 'advertising': {'valence': 0.622, 'arousal': 0.608, 'dominance': 0.632},\n",
       " 'adverts': {'valence': 0.551, 'arousal': 0.5, 'dominance': 0.595},\n",
       " 'advice': {'valence': 0.698, 'arousal': 0.408, 'dominance': 0.688},\n",
       " 'advisable': {'valence': 0.867, 'arousal': 0.48, 'dominance': 0.51},\n",
       " 'advise': {'valence': 0.76,\n",
       "  'arousal': 0.39299999999999996,\n",
       "  'dominance': 0.705},\n",
       " 'advised': {'valence': 0.823, 'arousal': 0.33, 'dominance': 0.509},\n",
       " 'advisement': {'valence': 0.698, 'arousal': 0.235, 'dominance': 0.655},\n",
       " 'adviser': {'valence': 0.745,\n",
       "  'arousal': 0.36200000000000004,\n",
       "  'dominance': 0.705},\n",
       " 'advisor': {'valence': 0.6459999999999999,\n",
       "  'arousal': 0.35,\n",
       "  'dominance': 0.6890000000000001},\n",
       " 'advisory': {'valence': 0.6559999999999999,\n",
       "  'arousal': 0.429,\n",
       "  'dominance': 0.633},\n",
       " 'advocacy': {'valence': 0.5,\n",
       "  'arousal': 0.6459999999999999,\n",
       "  'dominance': 0.731},\n",
       " 'advocate': {'valence': 0.551, 'arousal': 0.53, 'dominance': 0.818},\n",
       " 'aegis': {'valence': 0.49, 'arousal': 0.439, 'dominance': 0.462},\n",
       " 'aeration': {'valence': 0.55, 'arousal': 0.5, 'dominance': 0.433},\n",
       " 'aerial': {'valence': 0.615,\n",
       "  'arousal': 0.461,\n",
       "  'dominance': 0.46299999999999997},\n",
       " 'aerobics': {'valence': 0.708,\n",
       "  'arousal': 0.7709999999999999,\n",
       "  'dominance': 0.627},\n",
       " 'aerodrome': {'valence': 0.541,\n",
       "  'arousal': 0.74,\n",
       "  'dominance': 0.6779999999999999},\n",
       " 'aerodynamic': {'valence': 0.561,\n",
       "  'arousal': 0.7240000000000001,\n",
       "  'dominance': 0.728},\n",
       " 'aerodynamics': {'valence': 0.59,\n",
       "  'arousal': 0.6629999999999999,\n",
       "  'dominance': 0.722},\n",
       " 'aeronautics': {'valence': 0.551, 'arousal': 0.633, 'dominance': 0.688},\n",
       " 'aeroplane': {'valence': 0.7140000000000001,\n",
       "  'arousal': 0.642,\n",
       "  'dominance': 0.644},\n",
       " 'aerospace': {'valence': 0.643, 'arousal': 0.52, 'dominance': 0.779},\n",
       " 'aesthetic': {'valence': 0.708, 'arousal': 0.442, 'dominance': 0.526},\n",
       " 'aesthetics': {'valence': 0.847,\n",
       "  'arousal': 0.327,\n",
       "  'dominance': 0.5489999999999999},\n",
       " 'aetiology': {'valence': 0.48,\n",
       "  'arousal': 0.39799999999999996,\n",
       "  'dominance': 0.615},\n",
       " 'afar': {'valence': 0.396, 'arousal': 0.373, 'dominance': 0.358},\n",
       " 'affable': {'valence': 0.7040000000000001,\n",
       "  'arousal': 0.38,\n",
       "  'dominance': 0.452},\n",
       " 'affair': {'valence': 0.52,\n",
       "  'arousal': 0.45899999999999996,\n",
       "  'dominance': 0.657},\n",
       " 'affect': {'valence': 0.45799999999999996,\n",
       "  'arousal': 0.569,\n",
       "  'dominance': 0.578},\n",
       " 'affecting': {'valence': 0.35,\n",
       "  'arousal': 0.574,\n",
       "  'dominance': 0.39399999999999996},\n",
       " 'affection': {'valence': 0.898,\n",
       "  'arousal': 0.5589999999999999,\n",
       "  'dominance': 0.696},\n",
       " 'affectionate': {'valence': 0.9490000000000001,\n",
       "  'arousal': 0.42200000000000004,\n",
       "  'dominance': 0.55},\n",
       " 'affections': {'valence': 0.76, 'arousal': 0.547, 'dominance': 0.655},\n",
       " 'affiche': {'valence': 0.479, 'arousal': 0.265, 'dominance': 0.402},\n",
       " 'affidavit': {'valence': 0.469, 'arousal': 0.584, 'dominance': 0.526},\n",
       " 'affiliated': {'valence': 0.6729999999999999,\n",
       "  'arousal': 0.519,\n",
       "  'dominance': 0.535},\n",
       " 'affiliation': {'valence': 0.615, 'arousal': 0.594, 'dominance': 0.5},\n",
       " 'affinity': {'valence': 0.8, 'arousal': 0.5, 'dominance': 0.537},\n",
       " 'affirm': {'valence': 0.745, 'arousal': 0.509, 'dominance': 0.731},\n",
       " 'affirmation': {'valence': 0.75,\n",
       "  'arousal': 0.5,\n",
       "  'dominance': 0.6890000000000001},\n",
       " 'affirmative': {'valence': 0.8540000000000001,\n",
       "  'arousal': 0.589,\n",
       "  'dominance': 0.816},\n",
       " 'affirmatively': {'valence': 0.9079999999999999,\n",
       "  'arousal': 0.5,\n",
       "  'dominance': 0.8109999999999999},\n",
       " 'affix': {'valence': 0.43799999999999994,\n",
       "  'arousal': 0.335,\n",
       "  'dominance': 0.41100000000000003},\n",
       " 'afflict': {'valence': 0.302, 'arousal': 0.555, 'dominance': 0.293},\n",
       " 'afflicted': {'valence': 0.271,\n",
       "  'arousal': 0.5,\n",
       "  'dominance': 0.16699999999999998},\n",
       " 'affliction': {'valence': 0.294, 'arousal': 0.635, 'dominance': 0.392},\n",
       " 'affluence': {'valence': 0.6629999999999999,\n",
       "  'arousal': 0.618,\n",
       "  'dominance': 0.722},\n",
       " 'affluent': {'valence': 0.7559999999999999,\n",
       "  'arousal': 0.38799999999999996,\n",
       "  'dominance': 0.47700000000000004},\n",
       " 'afford': {'valence': 0.5710000000000001,\n",
       "  'arousal': 0.58,\n",
       "  'dominance': 0.575},\n",
       " 'affordable': {'valence': 0.84,\n",
       "  'arousal': 0.39799999999999996,\n",
       "  'dominance': 0.493},\n",
       " 'affront': {'valence': 0.327, 'arousal': 0.74, 'dominance': 0.547},\n",
       " 'affronted': {'valence': 0.385, 'arousal': 0.75, 'dominance': 0.527},\n",
       " 'afield': {'valence': 0.594, 'arousal': 0.37, 'dominance': 0.373},\n",
       " 'afire': {'valence': 0.36700000000000005,\n",
       "  'arousal': 0.904,\n",
       "  'dominance': 0.675},\n",
       " 'afloat': {'valence': 0.602,\n",
       "  'arousal': 0.42700000000000005,\n",
       "  'dominance': 0.444},\n",
       " 'afore': {'valence': 0.5, 'arousal': 0.337, 'dominance': 0.382},\n",
       " 'aforementioned': {'valence': 0.49, 'arousal': 0.316, 'dominance': 0.408},\n",
       " 'aforesaid': {'valence': 0.531, 'arousal': 0.358, 'dominance': 0.478},\n",
       " 'afraid': {'valence': 0.01, 'arousal': 0.775, 'dominance': 0.245},\n",
       " 'afresh': {'valence': 0.643, 'arousal': 0.521, 'dominance': 0.48},\n",
       " 'african': {'valence': 0.49, 'arousal': 0.423, 'dominance': 0.555},\n",
       " 'aft': {'valence': 0.48, 'arousal': 0.41700000000000004, 'dominance': 0.518},\n",
       " 'afterlife': {'valence': 0.5710000000000001,\n",
       "  'arousal': 0.5670000000000001,\n",
       "  'dominance': 0.568},\n",
       " 'aftermath': {'valence': 0.312, 'arousal': 0.449, 'dominance': 0.444},\n",
       " 'afternoon': {'valence': 0.5329999999999999,\n",
       "  'arousal': 0.38799999999999996,\n",
       "  'dominance': 0.33899999999999997},\n",
       " 'aftershave': {'valence': 0.406, 'arousal': 0.384, 'dominance': 0.415},\n",
       " 'aftertaste': {'valence': 0.354,\n",
       "  'arousal': 0.36200000000000004,\n",
       "  'dominance': 0.455},\n",
       " 'afterthought': {'valence': 0.396, 'arousal': 0.392, 'dominance': 0.349},\n",
       " 'aga': {'valence': 0.542, 'arousal': 0.327, 'dominance': 0.39799999999999996},\n",
       " 'agape': {'valence': 0.612,\n",
       "  'arousal': 0.529,\n",
       "  'dominance': 0.46399999999999997},\n",
       " 'agate': {'valence': 0.54, 'arousal': 0.377, 'dominance': 0.483},\n",
       " 'age': {'valence': 0.561, 'arousal': 0.226, 'dominance': 0.498},\n",
       " 'aged': {'valence': 0.135,\n",
       "  'arousal': 0.365,\n",
       "  'dominance': 0.23600000000000002},\n",
       " 'agency': {'valence': 0.46,\n",
       "  'arousal': 0.29600000000000004,\n",
       "  'dominance': 0.583},\n",
       " 'agenda': {'valence': 0.531,\n",
       "  'arousal': 0.29600000000000004,\n",
       "  'dominance': 0.5529999999999999},\n",
       " 'agent': {'valence': 0.48, 'arousal': 0.439, 'dominance': 0.755},\n",
       " 'agglomeration': {'valence': 0.45, 'arousal': 0.765, 'dominance': 0.509},\n",
       " 'aggravate': {'valence': 0.22399999999999998,\n",
       "  'arousal': 0.77,\n",
       "  'dominance': 0.46399999999999997},\n",
       " 'aggravated': {'valence': 0.079, 'arousal': 0.76, 'dominance': 0.43},\n",
       " 'aggravates': {'valence': 0.10800000000000001,\n",
       "  'arousal': 0.778,\n",
       "  'dominance': 0.35700000000000004},\n",
       " 'aggravating': {'valence': 0.257, 'arousal': 0.794, 'dominance': 0.64},\n",
       " 'aggravation': {'valence': 0.071, 'arousal': 0.784, 'dominance': 0.613},\n",
       " 'aggregate': {'valence': 0.73,\n",
       "  'arousal': 0.37799999999999995,\n",
       "  'dominance': 0.556},\n",
       " 'aggregation': {'valence': 0.583,\n",
       "  'arousal': 0.517,\n",
       "  'dominance': 0.6940000000000001},\n",
       " 'aggresive': {'valence': 0.059000000000000004,\n",
       "  'arousal': 0.971,\n",
       "  'dominance': 0.639},\n",
       " 'aggression': {'valence': 0.094,\n",
       "  'arousal': 0.929,\n",
       "  'dominance': 0.5329999999999999},\n",
       " 'aggressive': {'valence': 0.125,\n",
       "  'arousal': 0.9490000000000001,\n",
       "  'dominance': 0.648},\n",
       " 'aggressively': {'valence': 0.25,\n",
       "  'arousal': 0.9259999999999999,\n",
       "  'dominance': 0.688},\n",
       " 'aggressiveness': {'valence': 0.077,\n",
       "  'arousal': 0.9129999999999999,\n",
       "  'dominance': 0.648},\n",
       " 'aggressor': {'valence': 0.146, 'arousal': 0.948, 'dominance': 0.823},\n",
       " 'agh': {'valence': 0.26, 'arousal': 0.5, 'dominance': 0.4},\n",
       " 'aghast': {'valence': 0.133,\n",
       "  'arousal': 0.865,\n",
       "  'dominance': 0.46399999999999997},\n",
       " 'aghhh': {'valence': 0.281, 'arousal': 0.635, 'dominance': 0.243},\n",
       " 'agile': {'valence': 0.8, 'arousal': 0.657, 'dominance': 0.775},\n",
       " 'agility': {'valence': 0.72,\n",
       "  'arousal': 0.7020000000000001,\n",
       "  'dominance': 0.815},\n",
       " 'aging': {'valence': 0.214, 'arousal': 0.255, 'dominance': 0.284},\n",
       " 'agitate': {'valence': 0.3,\n",
       "  'arousal': 0.7959999999999999,\n",
       "  'dominance': 0.593},\n",
       " 'agitated': {'valence': 0.444, 'arousal': 0.882, 'dominance': 0.491},\n",
       " 'agitation': {'valence': 0.24,\n",
       "  'arousal': 0.9309999999999999,\n",
       "  'dominance': 0.447},\n",
       " 'aglow': {'valence': 0.78, 'arousal': 0.51, 'dominance': 0.797},\n",
       " 'agnostic': {'valence': 0.306, 'arousal': 0.396, 'dominance': 0.574},\n",
       " 'ago': {'valence': 0.317, 'arousal': 0.28, 'dominance': 0.40399999999999997},\n",
       " 'agonizing': {'valence': 0.083, 'arousal': 0.8, 'dominance': 0.34},\n",
       " 'agony': {'valence': 0.083,\n",
       "  'arousal': 0.775,\n",
       "  'dominance': 0.39299999999999996},\n",
       " 'agoraphobia': {'valence': 0.127,\n",
       "  'arousal': 0.7120000000000001,\n",
       "  'dominance': 0.43799999999999994},\n",
       " 'agree': {'valence': 0.9059999999999999, 'arousal': 0.26, 'dominance': 0.545},\n",
       " 'agreeable': {'valence': 0.9059999999999999,\n",
       "  'arousal': 0.5,\n",
       "  'dominance': 0.696},\n",
       " 'agreed': {'valence': 0.797, 'arousal': 0.449, 'dominance': 0.574},\n",
       " 'agreeing': {'valence': 0.8540000000000001,\n",
       "  'arousal': 0.48,\n",
       "  'dominance': 0.557},\n",
       " 'agreement': {'valence': 0.76, 'arousal': 0.44, 'dominance': 0.736},\n",
       " 'agressive': {'valence': 0.083,\n",
       "  'arousal': 0.9179999999999999,\n",
       "  'dominance': 0.7509999999999999},\n",
       " 'agricultural': {'valence': 0.6859999999999999,\n",
       "  'arousal': 0.321,\n",
       "  'dominance': 0.473},\n",
       " 'agriculture': {'valence': 0.64,\n",
       "  'arousal': 0.35700000000000004,\n",
       "  'dominance': 0.465},\n",
       " 'aground': {'valence': 0.33299999999999996,\n",
       "  'arousal': 0.34,\n",
       "  'dominance': 0.445},\n",
       " 'agua': {'valence': 0.598, 'arousal': 0.18, 'dominance': 0.436},\n",
       " 'ahead': {'valence': 0.708, 'arousal': 0.52, 'dominance': 0.6729999999999999},\n",
       " 'ahhh': {'valence': 0.562,\n",
       "  'arousal': 0.517,\n",
       "  'dominance': 0.24100000000000002},\n",
       " 'ahhhhhhhh': {'valence': 0.552,\n",
       "  'arousal': 0.649,\n",
       "  'dominance': 0.28800000000000003},\n",
       " 'ahoy': {'valence': 0.5, 'arousal': 0.49700000000000005, 'dominance': 0.38},\n",
       " 'aid': {'valence': 0.7959999999999999, 'arousal': 0.491, 'dominance': 0.541},\n",
       " 'aide': {'valence': 0.7240000000000001, 'arousal': 0.342, 'dominance': 0.434},\n",
       " 'aiding': {'valence': 0.643,\n",
       "  'arousal': 0.5329999999999999,\n",
       "  'dominance': 0.569},\n",
       " 'aids': {'valence': 0.561, 'arousal': 0.48, 'dominance': 0.5},\n",
       " 'ail': {'valence': 0.375, 'arousal': 0.434, 'dominance': 0.385},\n",
       " 'ailing': {'valence': 0.094, 'arousal': 0.518, 'dominance': 0.153},\n",
       " 'ailment': {'valence': 0.146,\n",
       "  'arousal': 0.7340000000000001,\n",
       "  'dominance': 0.27699999999999997},\n",
       " 'aim': {'valence': 0.48100000000000004,\n",
       "  'arousal': 0.569,\n",
       "  'dominance': 0.5670000000000001},\n",
       " 'aimless': {'valence': 0.15, 'arousal': 0.267, 'dominance': 0.183},\n",
       " 'air': {'valence': 0.708, 'arousal': 0.163, 'dominance': 0.42700000000000005},\n",
       " 'airbag': {'valence': 0.51, 'arousal': 0.402, 'dominance': 0.433},\n",
       " 'airborne': {'valence': 0.542, 'arousal': 0.519, 'dominance': 0.385},\n",
       " 'aircraft': {'valence': 0.6459999999999999,\n",
       "  'arousal': 0.644,\n",
       "  'dominance': 0.691},\n",
       " 'aircraft carrier': {'valence': 0.49, 'arousal': 0.74, 'dominance': 0.727},\n",
       " 'airfield': {'valence': 0.601, 'arousal': 0.65, 'dominance': 0.645},\n",
       " 'airhead': {'valence': 0.271,\n",
       "  'arousal': 0.48100000000000004,\n",
       "  'dominance': 0.276},\n",
       " 'airlift': {'valence': 0.573, 'arousal': 0.622, 'dominance': 0.642},\n",
       " 'airline': {'valence': 0.65,\n",
       "  'arousal': 0.48200000000000004,\n",
       "  'dominance': 0.688},\n",
       " 'airliner': {'valence': 0.667, 'arousal': 0.777, 'dominance': 0.647},\n",
       " 'airlock': {'valence': 0.39799999999999996,\n",
       "  'arousal': 0.52,\n",
       "  'dominance': 0.447},\n",
       " 'airman': {'valence': 0.5870000000000001,\n",
       "  'arousal': 0.716,\n",
       "  'dominance': 0.721},\n",
       " 'airplane': {'valence': 0.7190000000000001,\n",
       "  'arousal': 0.7020000000000001,\n",
       "  'dominance': 0.708},\n",
       " 'airport': {'valence': 0.7290000000000001,\n",
       "  'arousal': 0.684,\n",
       "  'dominance': 0.682},\n",
       " 'airs': {'valence': 0.583, 'arousal': 0.196, 'dominance': 0.37},\n",
       " 'airship': {'valence': 0.542,\n",
       "  'arousal': 0.47200000000000003,\n",
       "  'dominance': 0.529},\n",
       " 'airspace': {'valence': 0.562, 'arousal': 0.51, 'dominance': 0.64},\n",
       " 'airspeed': {'valence': 0.583, 'arousal': 0.78, 'dominance': 0.544},\n",
       " 'airstrip': {'valence': 0.55, 'arousal': 0.69, 'dominance': 0.649},\n",
       " 'airtight': {'valence': 0.479, 'arousal': 0.381, 'dominance': 0.57},\n",
       " 'airway': {'valence': 0.638,\n",
       "  'arousal': 0.585,\n",
       "  'dominance': 0.48200000000000004},\n",
       " 'aisle': {'valence': 0.43799999999999994,\n",
       "  'arousal': 0.222,\n",
       "  'dominance': 0.28300000000000003},\n",
       " 'ait': {'valence': 0.385, 'arousal': 0.39, 'dominance': 0.402},\n",
       " 'ajar': {'valence': 0.46, 'arousal': 0.413, 'dominance': 0.446},\n",
       " 'aka': {'valence': 0.45899999999999996,\n",
       "  'arousal': 0.358,\n",
       "  'dominance': 0.35100000000000003},\n",
       " 'akin': {'valence': 0.639,\n",
       "  'arousal': 0.34299999999999997,\n",
       "  'dominance': 0.523},\n",
       " 'alabaster': {'valence': 0.542,\n",
       "  'arousal': 0.40399999999999997,\n",
       "  'dominance': 0.445},\n",
       " 'alarm': {'valence': 0.24100000000000002,\n",
       "  'arousal': 0.882,\n",
       "  'dominance': 0.698},\n",
       " 'alarm clock': {'valence': 0.542, 'arousal': 0.727, 'dominance': 0.642},\n",
       " 'alarmed': {'valence': 0.188,\n",
       "  'arousal': 0.8220000000000001,\n",
       "  'dominance': 0.49200000000000005},\n",
       " 'alarming': {'valence': 0.204, 'arousal': 0.89, 'dominance': 0.585},\n",
       " 'alas': {'valence': 0.5710000000000001,\n",
       "  'arousal': 0.31,\n",
       "  'dominance': 0.27899999999999997},\n",
       " 'alb': {'valence': 0.521, 'arousal': 0.38, 'dominance': 0.42700000000000005},\n",
       " 'albatross': {'valence': 0.5, 'arousal': 0.445, 'dominance': 0.527},\n",
       " 'albino': {'valence': 0.5, 'arousal': 0.24, 'dominance': 0.358},\n",
       " 'album': {'valence': 0.635,\n",
       "  'arousal': 0.349,\n",
       "  'dominance': 0.45299999999999996},\n",
       " 'alchemy': {'valence': 0.541, 'arousal': 0.583, 'dominance': 0.693},\n",
       " 'alcohol': {'valence': 0.32299999999999995,\n",
       "  'arousal': 0.667,\n",
       "  'dominance': 0.377},\n",
       " 'alcoholic': {'valence': 0.153, 'arousal': 0.688, 'dominance': 0.361},\n",
       " 'alcoholism': {'valence': 0.061,\n",
       "  'arousal': 0.779,\n",
       "  'dominance': 0.40700000000000003},\n",
       " 'alcove': {'valence': 0.49,\n",
       "  'arousal': 0.34,\n",
       "  'dominance': 0.35600000000000004},\n",
       " 'alderman': {'valence': 0.55,\n",
       "  'arousal': 0.45899999999999996,\n",
       "  'dominance': 0.691},\n",
       " 'ale': {'valence': 0.53, 'arousal': 0.45, 'dominance': 0.358},\n",
       " 'alert': {'valence': 0.479, 'arousal': 0.82, 'dominance': 0.648},\n",
       " 'alertness': {'valence': 0.375, 'arousal': 0.875, 'dominance': 0.75},\n",
       " 'alerts': {'valence': 0.337,\n",
       "  'arousal': 0.804,\n",
       "  'dominance': 0.6729999999999999},\n",
       " 'alfalfa': {'valence': 0.546, 'arousal': 0.25, 'dominance': 0.311},\n",
       " 'algebra': {'valence': 0.44, 'arousal': 0.34, 'dominance': 0.565},\n",
       " 'algebraic': {'valence': 0.531,\n",
       "  'arousal': 0.41200000000000003,\n",
       "  'dominance': 0.441},\n",
       " 'algorithm': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.39399999999999996,\n",
       "  'dominance': 0.5589999999999999},\n",
       " 'alias': {'valence': 0.541,\n",
       "  'arousal': 0.353,\n",
       "  'dominance': 0.33299999999999996},\n",
       " 'alibi': {'valence': 0.396, 'arousal': 0.528, 'dominance': 0.556},\n",
       " 'alien': {'valence': 0.41, 'arousal': 0.615, 'dominance': 0.491},\n",
       " 'alienate': {'valence': 0.247, 'arousal': 0.5, 'dominance': 0.523},\n",
       " 'alienated': {'valence': 0.41,\n",
       "  'arousal': 0.423,\n",
       "  'dominance': 0.5589999999999999},\n",
       " 'alienation': {'valence': 0.37799999999999995,\n",
       "  'arousal': 0.53,\n",
       "  'dominance': 0.462},\n",
       " 'alight': {'valence': 0.667, 'arousal': 0.657, 'dominance': 0.605},\n",
       " 'align': {'valence': 0.6559999999999999,\n",
       "  'arousal': 0.364,\n",
       "  'dominance': 0.627},\n",
       " 'aligned': {'valence': 0.583,\n",
       "  'arousal': 0.275,\n",
       "  'dominance': 0.5529999999999999},\n",
       " 'alignment': {'valence': 0.643,\n",
       "  'arousal': 0.41200000000000003,\n",
       "  'dominance': 0.6829999999999999},\n",
       " 'alike': {'valence': 0.653,\n",
       "  'arousal': 0.17300000000000001,\n",
       "  'dominance': 0.444},\n",
       " 'alimentation': {'valence': 0.7809999999999999,\n",
       "  'arousal': 0.551,\n",
       "  'dominance': 0.602},\n",
       " 'alimony': {'valence': 0.612,\n",
       "  'arousal': 0.47700000000000004,\n",
       "  'dominance': 0.46399999999999997},\n",
       " 'aliquot': {'valence': 0.44,\n",
       "  'arousal': 0.31,\n",
       "  'dominance': 0.40399999999999997},\n",
       " 'alive': {'valence': 0.816, 'arousal': 0.637, 'dominance': 0.731},\n",
       " 'alkali': {'valence': 0.49, 'arousal': 0.35, 'dominance': 0.408},\n",
       " 'alkaloids': {'valence': 0.433, 'arousal': 0.562, 'dominance': 0.402},\n",
       " 'allay': {'valence': 0.41700000000000004,\n",
       "  'arousal': 0.406,\n",
       "  'dominance': 0.39799999999999996},\n",
       " 'allegation': {'valence': 0.578, 'arousal': 0.578, 'dominance': 0.608},\n",
       " 'allege': {'valence': 0.418,\n",
       "  'arousal': 0.48200000000000004,\n",
       "  'dominance': 0.5870000000000001},\n",
       " 'alleged': {'valence': 0.365, 'arousal': 0.522, 'dominance': 0.52},\n",
       " 'allegiance': {'valence': 0.917,\n",
       "  'arousal': 0.39799999999999996,\n",
       "  'dominance': 0.75},\n",
       " 'allegorical': {'valence': 0.517,\n",
       "  'arousal': 0.5579999999999999,\n",
       "  'dominance': 0.598},\n",
       " 'allegory': {'valence': 0.615, 'arousal': 0.58, 'dominance': 0.509},\n",
       " 'allegro': {'valence': 0.635,\n",
       "  'arousal': 0.627,\n",
       "  'dominance': 0.45299999999999996},\n",
       " 'allergic': {'valence': 0.135,\n",
       "  'arousal': 0.5489999999999999,\n",
       "  'dominance': 0.273},\n",
       " 'allergy': {'valence': 0.29600000000000004,\n",
       "  'arousal': 0.606,\n",
       "  'dominance': 0.389},\n",
       " 'alleviate': {'valence': 0.8690000000000001,\n",
       "  'arousal': 0.27,\n",
       "  'dominance': 0.528},\n",
       " 'alleviation': {'valence': 0.735, 'arousal': 0.2, 'dominance': 0.491},\n",
       " 'alley': {'valence': 0.34700000000000003, 'arousal': 0.5, 'dominance': 0.355},\n",
       " 'alleyway': {'valence': 0.35700000000000004,\n",
       "  'arousal': 0.47100000000000003,\n",
       "  'dominance': 0.382},\n",
       " 'alliance': {'valence': 0.696, 'arousal': 0.473, 'dominance': 0.769},\n",
       " 'allied': {'valence': 0.7140000000000001,\n",
       "  'arousal': 0.245,\n",
       "  'dominance': 0.642},\n",
       " 'alligator': {'valence': 0.354,\n",
       "  'arousal': 0.7040000000000001,\n",
       "  'dominance': 0.645},\n",
       " 'allocate': {'valence': 0.6729999999999999,\n",
       "  'arousal': 0.462,\n",
       "  'dominance': 0.672},\n",
       " 'allocation': {'valence': 0.604,\n",
       "  'arousal': 0.38799999999999996,\n",
       "  'dominance': 0.679},\n",
       " 'allot': {'valence': 0.622,\n",
       "  'arousal': 0.48100000000000004,\n",
       "  'dominance': 0.616},\n",
       " 'allotment': {'valence': 0.6, 'arousal': 0.39, 'dominance': 0.64},\n",
       " 'allow': {'valence': 0.698,\n",
       "  'arousal': 0.429,\n",
       "  'dominance': 0.5379999999999999},\n",
       " 'allowable': {'valence': 0.698, 'arousal': 0.5, 'dominance': 0.561},\n",
       " 'allowance': {'valence': 0.6729999999999999,\n",
       "  'arousal': 0.382,\n",
       "  'dominance': 0.591},\n",
       " 'allowed': {'valence': 0.73, 'arousal': 0.36, 'dominance': 0.655},\n",
       " 'alloy': {'valence': 0.583,\n",
       "  'arousal': 0.44299999999999995,\n",
       "  'dominance': 0.593},\n",
       " 'allsmiles': {'valence': 0.7859999999999999,\n",
       "  'arousal': 0.528,\n",
       "  'dominance': 0.43},\n",
       " 'allure': {'valence': 0.804,\n",
       "  'arousal': 0.585,\n",
       "  'dominance': 0.6859999999999999},\n",
       " 'alluring': {'valence': 0.8370000000000001,\n",
       "  'arousal': 0.745,\n",
       "  'dominance': 0.843},\n",
       " 'allusion': {'valence': 0.44, 'arousal': 0.308, 'dominance': 0.462},\n",
       " 'alluvial': {'valence': 0.32299999999999995,\n",
       "  'arousal': 0.49,\n",
       "  'dominance': 0.491},\n",
       " 'ally': {'valence': 0.792, 'arousal': 0.32, 'dominance': 0.688},\n",
       " 'almanac': {'valence': 0.688,\n",
       "  'arousal': 0.19,\n",
       "  'dominance': 0.41200000000000003},\n",
       " 'almighty': {'valence': 0.938,\n",
       "  'arousal': 0.8740000000000001,\n",
       "  'dominance': 0.958},\n",
       " 'almond': {'valence': 0.698, 'arousal': 0.183, 'dominance': 0.314},\n",
       " 'aloft': {'valence': 0.7709999999999999, 'arousal': 0.373, 'dominance': 0.7},\n",
       " 'aloha': {'valence': 0.698, 'arousal': 0.44, 'dominance': 0.441},\n",
       " 'alone': {'valence': 0.33299999999999996,\n",
       "  'arousal': 0.16699999999999998,\n",
       "  'dominance': 0.21600000000000003},\n",
       " 'alongside': {'valence': 0.45799999999999996,\n",
       "  'arousal': 0.33299999999999996,\n",
       "  'dominance': 0.34700000000000003},\n",
       " 'aloof': {'valence': 0.18899999999999997,\n",
       "  'arousal': 0.423,\n",
       "  'dominance': 0.302},\n",
       " 'aloud': {'valence': 0.45799999999999996,\n",
       "  'arousal': 0.713,\n",
       "  'dominance': 0.75},\n",
       " 'alpha': {'valence': 0.708, 'arousal': 0.34, 'dominance': 0.755},\n",
       " 'alphabet': {'valence': 0.562, 'arousal': 0.204, 'dominance': 0.672},\n",
       " 'alphabetical': {'valence': 0.537,\n",
       "  'arousal': 0.29600000000000004,\n",
       "  'dominance': 0.535},\n",
       " 'alpine': {'valence': 0.594, 'arousal': 0.337, 'dominance': 0.474},\n",
       " 'alreadyyyyy': {'valence': 0.5920000000000001,\n",
       "  'arousal': 0.7170000000000001,\n",
       "  'dominance': 0.35100000000000003},\n",
       " 'altar': {'valence': 0.7240000000000001,\n",
       "  'arousal': 0.387,\n",
       "  'dominance': 0.635},\n",
       " 'altar boy': {'valence': 0.434,\n",
       "  'arousal': 0.20600000000000002,\n",
       "  'dominance': 0.35},\n",
       " 'alter': {'valence': 0.33299999999999996,\n",
       "  'arousal': 0.6940000000000001,\n",
       "  'dominance': 0.654},\n",
       " 'alteration': {'valence': 0.16699999999999998,\n",
       "  'arousal': 0.7979999999999999,\n",
       "  'dominance': 0.609},\n",
       " 'altercation': {'valence': 0.17,\n",
       "  'arousal': 0.8059999999999999,\n",
       "  'dominance': 0.5},\n",
       " 'altered': {'valence': 0.255, 'arousal': 0.765, 'dominance': 0.5},\n",
       " 'alternate': {'valence': 0.625, 'arousal': 0.363, 'dominance': 0.589},\n",
       " 'alternating': {'valence': 0.48, 'arousal': 0.494, 'dominance': 0.542},\n",
       " 'alternative': {'valence': 0.628, 'arousal': 0.373, 'dominance': 0.631},\n",
       " 'altimeter': {'valence': 0.615, 'arousal': 0.51, 'dominance': 0.58},\n",
       " 'altitude': {'valence': 0.708,\n",
       "  'arousal': 0.48200000000000004,\n",
       "  'dominance': 0.736},\n",
       " 'alto': {'valence': 0.6559999999999999,\n",
       "  'arousal': 0.40399999999999997,\n",
       "  'dominance': 0.73},\n",
       " 'altogether': {'valence': 0.833, 'arousal': 0.324, 'dominance': 0.644},\n",
       " 'aluminum': {'valence': 0.449, 'arousal': 0.28, 'dominance': 0.434},\n",
       " 'alumnus': {'valence': 0.633,\n",
       "  'arousal': 0.368,\n",
       "  'dominance': 0.42200000000000004},\n",
       " 'alveolar': {'valence': 0.469,\n",
       "  'arousal': 0.48100000000000004,\n",
       "  'dominance': 0.36700000000000005},\n",
       " 'alzheimers': {'valence': 0.19399999999999998,\n",
       "  'arousal': 0.518,\n",
       "  'dominance': 0.319},\n",
       " 'amalgam': {'valence': 0.43799999999999994,\n",
       "  'arousal': 0.33299999999999996,\n",
       "  'dominance': 0.51},\n",
       " 'amalgamation': {'valence': 0.406, 'arousal': 0.47, 'dominance': 0.531},\n",
       " 'amaretto': {'valence': 0.5429999999999999,\n",
       "  'arousal': 0.551,\n",
       "  'dominance': 0.375},\n",
       " 'amass': {'valence': 0.552, 'arousal': 0.465, 'dominance': 0.465},\n",
       " 'amateur': {'valence': 0.469, 'arousal': 0.5, 'dominance': 0.409},\n",
       " 'amaze': {'valence': 0.8959999999999999,\n",
       "  'arousal': 0.843,\n",
       "  'dominance': 0.7829999999999999},\n",
       " 'amazed': {'valence': 0.7959999999999999,\n",
       "  'arousal': 0.779,\n",
       "  'dominance': 0.5329999999999999},\n",
       " 'amazedness': {'valence': 0.8270000000000001,\n",
       "  'arousal': 0.872,\n",
       "  'dominance': 0.51},\n",
       " 'amazement': {'valence': 0.75, 'arousal': 0.8, 'dominance': 0.639},\n",
       " 'amazing': {'valence': 0.9059999999999999,\n",
       "  'arousal': 0.8370000000000001,\n",
       "  'dominance': 0.8490000000000001},\n",
       " 'amazingly': {'valence': 0.9179999999999999,\n",
       "  'arousal': 0.765,\n",
       "  'dominance': 0.92},\n",
       " 'ambassador': {'valence': 0.6509999999999999,\n",
       "  'arousal': 0.529,\n",
       "  'dominance': 0.917},\n",
       " 'amber': {'valence': 0.635, 'arousal': 0.308, 'dominance': 0.369},\n",
       " 'ambience': {'valence': 0.735,\n",
       "  'arousal': 0.35600000000000004,\n",
       "  'dominance': 0.426},\n",
       " 'ambient': {'valence': 0.625,\n",
       "  'arousal': 0.36,\n",
       "  'dominance': 0.5820000000000001},\n",
       " 'ambiguity': {'valence': 0.16399999999999998,\n",
       "  'arousal': 0.46,\n",
       "  'dominance': 0.37},\n",
       " 'ambiguous': {'valence': 0.265, 'arousal': 0.462, 'dominance': 0.358},\n",
       " 'ambit': {'valence': 0.479, 'arousal': 0.38, 'dominance': 0.386},\n",
       " 'ambition': {'valence': 0.51,\n",
       "  'arousal': 0.804,\n",
       "  'dominance': 0.6609999999999999},\n",
       " 'ambitious': {'valence': 0.484,\n",
       "  'arousal': 0.821,\n",
       "  'dominance': 0.7170000000000001},\n",
       " 'ambivalent': {'valence': 0.51,\n",
       "  'arousal': 0.40399999999999997,\n",
       "  'dominance': 0.48200000000000004},\n",
       " 'ambrosia': {'valence': 0.5710000000000001,\n",
       "  'arousal': 0.452,\n",
       "  'dominance': 0.48},\n",
       " 'ambulance': {'valence': 0.5, 'arousal': 0.75, 'dominance': 0.609},\n",
       " 'ambush': {'valence': 0.281, 'arousal': 0.83, 'dominance': 0.5},\n",
       " 'ameliorate': {'valence': 0.77,\n",
       "  'arousal': 0.5479999999999999,\n",
       "  'dominance': 0.747},\n",
       " 'amen': {'valence': 0.7809999999999999, 'arousal': 0.182, 'dominance': 0.542},\n",
       " 'amenable': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.41,\n",
       "  'dominance': 0.406},\n",
       " 'amend': {'valence': 0.688,\n",
       "  'arousal': 0.406,\n",
       "  'dominance': 0.6579999999999999},\n",
       " 'amendment': {'valence': 0.531,\n",
       "  'arousal': 0.45899999999999996,\n",
       "  'dominance': 0.606},\n",
       " 'amends': {'valence': 0.64, 'arousal': 0.366, 'dominance': 0.517},\n",
       " 'amenity': {'valence': 0.75, 'arousal': 0.327, 'dominance': 0.574},\n",
       " 'amethyst': {'valence': 0.622, 'arousal': 0.406, 'dominance': 0.517},\n",
       " 'amiable': {'valence': 0.847, 'arousal': 0.29, 'dominance': 0.483},\n",
       " 'amicable': {'valence': 0.875, 'arousal': 0.33, 'dominance': 0.507},\n",
       " 'amid': {'valence': 0.51, 'arousal': 0.34, 'dominance': 0.256},\n",
       " 'amidst': {'valence': 0.48, 'arousal': 0.33, 'dominance': 0.316},\n",
       " 'amino': {'valence': 0.551, 'arousal': 0.402, 'dominance': 0.433},\n",
       " 'ammo': {'valence': 0.32299999999999995,\n",
       "  'arousal': 0.765,\n",
       "  'dominance': 0.621},\n",
       " 'ammonia': {'valence': 0.292,\n",
       "  'arousal': 0.5870000000000001,\n",
       "  'dominance': 0.409},\n",
       " 'ammonium': {'valence': 0.354, 'arousal': 0.396, 'dominance': 0.368},\n",
       " 'ammunition': {'valence': 0.33799999999999997,\n",
       "  'arousal': 0.635,\n",
       "  'dominance': 0.667},\n",
       " 'amnesia': {'valence': 0.29600000000000004,\n",
       "  'arousal': 0.33,\n",
       "  'dominance': 0.308},\n",
       " 'amnesty': {'valence': 0.551,\n",
       "  'arousal': 0.451,\n",
       "  'dominance': 0.8140000000000001},\n",
       " 'amorous': {'valence': 0.8440000000000001,\n",
       "  'arousal': 0.67,\n",
       "  'dominance': 0.636},\n",
       " 'amorphous': {'valence': 0.327, 'arousal': 0.402, 'dominance': 0.349},\n",
       " 'amortization': {'valence': 0.5920000000000001,\n",
       "  'arousal': 0.491,\n",
       "  'dominance': 0.522},\n",
       " 'amount': {'valence': 0.562,\n",
       "  'arousal': 0.42200000000000004,\n",
       "  'dominance': 0.649},\n",
       " 'amour': {'valence': 0.865, 'arousal': 0.48, 'dominance': 0.652},\n",
       " 'amp': {'valence': 0.439, 'arousal': 0.39299999999999996, 'dominance': 0.375},\n",
       " 'ampersand': {'valence': 0.48,\n",
       "  'arousal': 0.44799999999999995,\n",
       "  'dominance': 0.483},\n",
       " 'amphetamines': {'valence': 0.133, 'arousal': 0.667, 'dominance': 0.526},\n",
       " 'amphibian': {'valence': 0.42700000000000005,\n",
       "  'arousal': 0.35700000000000004,\n",
       "  'dominance': 0.474},\n",
       " 'amphibious': {'valence': 0.479,\n",
       "  'arousal': 0.34600000000000003,\n",
       "  'dominance': 0.445},\n",
       " 'amphitheater': {'valence': 0.653, 'arousal': 0.48, 'dominance': 0.545},\n",
       " 'ample': {'valence': 0.7440000000000001,\n",
       "  'arousal': 0.349,\n",
       "  'dominance': 0.7190000000000001},\n",
       " 'amplification': {'valence': 0.69, 'arousal': 0.677, 'dominance': 0.81},\n",
       " 'amplify': {'valence': 0.677,\n",
       "  'arousal': 0.735,\n",
       "  'dominance': 0.8270000000000001},\n",
       " 'amplitude': {'valence': 0.6940000000000001,\n",
       "  'arousal': 0.439,\n",
       "  'dominance': 0.6920000000000001},\n",
       " 'amply': {'valence': 0.7809999999999999,\n",
       "  'arousal': 0.431,\n",
       "  'dominance': 0.7659999999999999},\n",
       " 'amputate': {'valence': 0.092, 'arousal': 0.66, 'dominance': 0.509},\n",
       " 'amputation': {'valence': 0.1, 'arousal': 0.755, 'dominance': 0.483},\n",
       " 'amuck': {'valence': 0.385, 'arousal': 0.602, 'dominance': 0.321},\n",
       " 'amulet': {'valence': 0.7809999999999999, 'arousal': 0.26, 'dominance': 0.63},\n",
       " 'amuse': {'valence': 0.812, 'arousal': 0.684, 'dominance': 0.664},\n",
       " 'amused': {'valence': 0.9420000000000001,\n",
       "  'arousal': 0.847,\n",
       "  'dominance': 0.596},\n",
       " 'amusement': {'valence': 0.929,\n",
       "  'arousal': 0.8370000000000001,\n",
       "  'dominance': 0.8029999999999999},\n",
       " 'amusing': {'valence': 0.96,\n",
       "  'arousal': 0.8290000000000001,\n",
       "  'dominance': 0.632},\n",
       " 'ana': {'valence': 0.541, 'arousal': 0.3, 'dominance': 0.314},\n",
       " 'anaconda': {'valence': 0.146, 'arousal': 0.83, 'dominance': 0.54},\n",
       " 'anaesthesia': {'valence': 0.35, 'arousal': 0.217, 'dominance': 0.473},\n",
       " 'anaesthetic': {'valence': 0.449, 'arousal': 0.268, 'dominance': 0.509},\n",
       " 'anagram': {'valence': 0.552, 'arousal': 0.327, 'dominance': 0.449},\n",
       " 'anal': {'valence': 0.33299999999999996,\n",
       "  'arousal': 0.7979999999999999,\n",
       "  'dominance': 0.33399999999999996},\n",
       " 'analgesic': {'valence': 0.41700000000000004,\n",
       "  'arousal': 0.321,\n",
       "  'dominance': 0.441},\n",
       " 'analogous': {'valence': 0.531, 'arousal': 0.27, 'dominance': 0.5},\n",
       " 'analogue': {'valence': 0.57, 'arousal': 0.32, 'dominance': 0.446},\n",
       " 'analogy': {'valence': 0.51,\n",
       "  'arousal': 0.36700000000000005,\n",
       "  'dominance': 0.509},\n",
       " 'analysis': {'valence': 0.7290000000000001,\n",
       "  'arousal': 0.44799999999999995,\n",
       "  'dominance': 0.705},\n",
       " 'analyst': {'valence': 0.604, 'arousal': 0.415, 'dominance': 0.755},\n",
       " 'analytic': {'valence': 0.665, 'arousal': 0.521, 'dominance': 0.634},\n",
       " 'analytical': {'valence': 0.625, 'arousal': 0.324, 'dominance': 0.8},\n",
       " 'analyze': {'valence': 0.667, 'arousal': 0.462, 'dominance': 0.71},\n",
       " 'analyzer': {'valence': 0.625,\n",
       "  'arousal': 0.556,\n",
       "  'dominance': 0.8540000000000001},\n",
       " 'anaphylactic': {'valence': 0.37799999999999995,\n",
       "  'arousal': 0.588,\n",
       "  'dominance': 0.5},\n",
       " 'anarchism': {'valence': 0.125, 'arousal': 0.804, 'dominance': 0.623},\n",
       " 'anarchist': {'valence': 0.204, 'arousal': 0.7, 'dominance': 0.759},\n",
       " 'anarchy': {'valence': 0.146, 'arousal': 0.755, 'dominance': 0.62},\n",
       " 'anastomosis': {'valence': 0.375, 'arousal': 0.47, 'dominance': 0.49},\n",
       " 'anathema': {'valence': 0.28600000000000003,\n",
       "  'arousal': 0.49,\n",
       "  'dominance': 0.519},\n",
       " 'anatomic': {'valence': 0.562, 'arousal': 0.442, 'dominance': 0.546},\n",
       " 'anatomy': {'valence': 0.562,\n",
       "  'arousal': 0.39,\n",
       "  'dominance': 0.5710000000000001},\n",
       " 'ancestor': {'valence': 0.5920000000000001,\n",
       "  'arousal': 0.38799999999999996,\n",
       "  'dominance': 0.594},\n",
       " 'ancestral': {'valence': 0.64,\n",
       "  'arousal': 0.48100000000000004,\n",
       "  'dominance': 0.75},\n",
       " 'ancestry': {'valence': 0.708,\n",
       "  'arousal': 0.519,\n",
       "  'dominance': 0.7170000000000001},\n",
       " 'anchor': {'valence': 0.52, 'arousal': 0.284, 'dominance': 0.564},\n",
       " 'anchorage': {'valence': 0.5, 'arousal': 0.325, 'dominance': 0.639},\n",
       " 'ancient': {'valence': 0.42, 'arousal': 0.217, 'dominance': 0.439},\n",
       " 'ancillary': {'valence': 0.449, 'arousal': 0.442, 'dominance': 0.278},\n",
       " 'androgen': {'valence': 0.255, 'arousal': 0.523, 'dominance': 0.527},\n",
       " 'android': {'valence': 0.6629999999999999,\n",
       "  'arousal': 0.436,\n",
       "  'dominance': 0.5},\n",
       " 'anecdote': {'valence': 0.583, 'arousal': 0.529, 'dominance': 0.5},\n",
       " 'anemia': {'valence': 0.188, 'arousal': 0.327, 'dominance': 0.31},\n",
       " 'anemic': {'valence': 0.16699999999999998,\n",
       "  'arousal': 0.27899999999999997,\n",
       "  'dominance': 0.155},\n",
       " 'anemone': {'valence': 0.552,\n",
       "  'arousal': 0.5379999999999999,\n",
       "  'dominance': 0.327},\n",
       " 'anesthesia': {'valence': 0.365,\n",
       "  'arousal': 0.21600000000000003,\n",
       "  'dominance': 0.39399999999999996},\n",
       " 'anesthesiologist': {'valence': 0.419,\n",
       "  'arousal': 0.22399999999999998,\n",
       "  'dominance': 0.526},\n",
       " 'anesthetic': {'valence': 0.35,\n",
       "  'arousal': 0.264,\n",
       "  'dominance': 0.48200000000000004},\n",
       " 'aneurysm': {'valence': 0.115, 'arousal': 0.69, 'dominance': 0.536},\n",
       " 'anew': {'valence': 0.7709999999999999, 'arousal': 0.358, 'dominance': 0.385},\n",
       " 'angel': {'valence': 0.9059999999999999,\n",
       "  'arousal': 0.158,\n",
       "  'dominance': 0.7040000000000001},\n",
       " 'angelic': {'valence': 0.927,\n",
       "  'arousal': 0.298,\n",
       "  'dominance': 0.6679999999999999},\n",
       " 'anger': {'valence': 0.16699999999999998,\n",
       "  'arousal': 0.865,\n",
       "  'dominance': 0.657},\n",
       " 'angered': {'valence': 0.01, 'arousal': 0.86, 'dominance': 0.547},\n",
       " 'angermanagement': {'valence': 0.26,\n",
       "  'arousal': 0.632,\n",
       "  'dominance': 0.48200000000000004},\n",
       " 'angina': {'valence': 0.23,\n",
       "  'arousal': 0.63,\n",
       "  'dominance': 0.46399999999999997},\n",
       " 'angiogram': {'valence': 0.34700000000000003,\n",
       "  'arousal': 0.52,\n",
       "  'dominance': 0.465},\n",
       " 'angiography': {'valence': 0.37799999999999995,\n",
       "  'arousal': 0.536,\n",
       "  'dominance': 0.52},\n",
       " 'angle': {'valence': 0.541, 'arousal': 0.33, 'dominance': 0.455},\n",
       " 'angling': {'valence': 0.625, 'arousal': 0.408, 'dominance': 0.5},\n",
       " 'angora': {'valence': 0.529, 'arousal': 0.425, 'dominance': 0.405},\n",
       " 'angriest': {'valence': 0.094, 'arousal': 0.892, 'dominance': 0.43},\n",
       " 'angry': {'valence': 0.122, 'arousal': 0.83, 'dominance': 0.604},\n",
       " 'angrytweet': {'valence': 0.265,\n",
       "  'arousal': 0.644,\n",
       "  'dominance': 0.47100000000000003},\n",
       " 'angst': {'valence': 0.16699999999999998,\n",
       "  'arousal': 0.888,\n",
       "  'dominance': 0.33299999999999996},\n",
       " 'anguish': {'valence': 0.153, 'arousal': 0.792, 'dominance': 0.265},\n",
       " 'anguished': {'valence': 0.135, 'arousal': 0.72, 'dominance': 0.307},\n",
       " 'angular': {'valence': 0.449, 'arousal': 0.281, 'dominance': 0.444},\n",
       " 'anhydrous': {'valence': 0.456, 'arousal': 0.365, 'dominance': 0.355},\n",
       " 'animal': {'valence': 0.521, 'arousal': 0.51, 'dominance': 0.513},\n",
       " 'animate': {'valence': 0.8270000000000001,\n",
       "  'arousal': 0.755,\n",
       "  'dominance': 0.635},\n",
       " 'animated': {'valence': 0.823,\n",
       "  'arousal': 0.6759999999999999,\n",
       "  'dominance': 0.5379999999999999},\n",
       " 'animation': {'valence': 0.888,\n",
       "  'arousal': 0.75,\n",
       "  'dominance': 0.5489999999999999},\n",
       " 'animosity': {'valence': 0.51,\n",
       "  'arousal': 0.7240000000000001,\n",
       "  'dominance': 0.545},\n",
       " 'animus': {'valence': 0.698,\n",
       "  'arousal': 0.6759999999999999,\n",
       "  'dominance': 0.466},\n",
       " 'ankle': {'valence': 0.5,\n",
       "  'arousal': 0.27399999999999997,\n",
       "  'dominance': 0.23399999999999999},\n",
       " 'anklet': {'valence': 0.41, 'arousal': 0.276, 'dominance': 0.302},\n",
       " 'annals': {'valence': 0.42700000000000005,\n",
       "  'arousal': 0.61,\n",
       "  'dominance': 0.424},\n",
       " 'annex': {'valence': 0.594,\n",
       "  'arousal': 0.35,\n",
       "  'dominance': 0.45799999999999996},\n",
       " 'annexation': {'valence': 0.342, 'arousal': 0.5, 'dominance': 0.555},\n",
       " 'annexe': {'valence': 0.584, 'arousal': 0.35, 'dominance': 0.392},\n",
       " 'annihilate': {'valence': 0.115,\n",
       "  'arousal': 0.9179999999999999,\n",
       "  'dominance': 0.6809999999999999},\n",
       " 'annihilated': {'valence': 0.08, 'arousal': 0.76, 'dominance': 0.324},\n",
       " 'annihilation': {'valence': 0.040999999999999995,\n",
       "  'arousal': 0.8,\n",
       "  'dominance': 0.591},\n",
       " 'anniversary': {'valence': 0.88, 'arousal': 0.77, 'dominance': 0.723},\n",
       " 'annotate': {'valence': 0.5920000000000001,\n",
       "  'arousal': 0.469,\n",
       "  'dominance': 0.441},\n",
       " 'annotation': {'valence': 0.604, 'arousal': 0.47, 'dominance': 0.619},\n",
       " 'announce': {'valence': 0.6940000000000001,\n",
       "  'arousal': 0.618,\n",
       "  'dominance': 0.611},\n",
       " 'announcement': {'valence': 0.7290000000000001,\n",
       "  'arousal': 0.491,\n",
       "  'dominance': 0.48200000000000004},\n",
       " 'announcer': {'valence': 0.602, 'arousal': 0.57, 'dominance': 0.732},\n",
       " 'annoy': {'valence': 0.094,\n",
       "  'arousal': 0.765,\n",
       "  'dominance': 0.28600000000000003},\n",
       " 'annoyance': {'valence': 0.16699999999999998,\n",
       "  'arousal': 0.718,\n",
       "  'dominance': 0.342},\n",
       " 'annoyed': {'valence': 0.10400000000000001,\n",
       "  'arousal': 0.7829999999999999,\n",
       "  'dominance': 0.345},\n",
       " 'annoyin': {'valence': 0.26,\n",
       "  'arousal': 0.573,\n",
       "  'dominance': 0.35200000000000004},\n",
       " 'annoying': {'valence': 0.08199999999999999,\n",
       "  'arousal': 0.853,\n",
       "  'dominance': 0.348},\n",
       " 'annoys': {'valence': 0.146, 'arousal': 0.778, 'dominance': 0.435},\n",
       " 'annual': {'valence': 0.552,\n",
       "  'arousal': 0.23600000000000002,\n",
       "  'dominance': 0.5},\n",
       " 'annuity': {'valence': 0.521, 'arousal': 0.304, 'dominance': 0.527},\n",
       " 'annul': {'valence': 0.25,\n",
       "  'arousal': 0.44799999999999995,\n",
       "  'dominance': 0.364},\n",
       " 'annular': {'valence': 0.31,\n",
       "  'arousal': 0.385,\n",
       "  'dominance': 0.41200000000000003},\n",
       " 'annulment': {'valence': 0.153, 'arousal': 0.375, 'dominance': 0.447},\n",
       " 'annulus': {'valence': 0.45799999999999996,\n",
       "  'arousal': 0.38,\n",
       "  'dominance': 0.376},\n",
       " 'anointed': {'valence': 0.5, 'arousal': 0.368, 'dominance': 0.579},\n",
       " 'anointing': {'valence': 0.653, 'arousal': 0.35, 'dominance': 0.547},\n",
       " 'anomalous': {'valence': 0.281, 'arousal': 0.48, 'dominance': 0.423},\n",
       " 'anomaly': {'valence': 0.188,\n",
       "  'arousal': 0.5379999999999999,\n",
       "  'dominance': 0.40399999999999997},\n",
       " 'anon': {'valence': 0.479, 'arousal': 0.354, 'dominance': 0.298},\n",
       " 'anonymity': {'valence': 0.469, 'arousal': 0.255, 'dominance': 0.43},\n",
       " 'anonymous': {'valence': 0.396,\n",
       "  'arousal': 0.29100000000000004,\n",
       "  'dominance': 0.431},\n",
       " 'anorexic': {'valence': 0.16, 'arousal': 0.618, 'dominance': 0.245},\n",
       " 'answer': {'valence': 0.537,\n",
       "  'arousal': 0.373,\n",
       "  'dominance': 0.6609999999999999},\n",
       " 'answerable': {'valence': 0.708,\n",
       "  'arousal': 0.48100000000000004,\n",
       "  'dominance': 0.75},\n",
       " 'answering': {'valence': 0.684, 'arousal': 0.5, 'dominance': 0.607},\n",
       " 'ant': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.21600000000000003,\n",
       "  'dominance': 0.21600000000000003},\n",
       " 'antagonism': {'valence': 0.22399999999999998,\n",
       "  'arousal': 0.618,\n",
       "  'dominance': 0.524},\n",
       " 'antagonist': {'valence': 0.24, 'arousal': 0.615, 'dominance': 0.7},\n",
       " 'antagonistic': {'valence': 0.29600000000000004,\n",
       "  'arousal': 0.604,\n",
       "  'dominance': 0.565},\n",
       " 'antagonize': {'valence': 0.14300000000000002,\n",
       "  'arousal': 0.6629999999999999,\n",
       "  'dominance': 0.629},\n",
       " 'ante': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.32,\n",
       "  'dominance': 0.41700000000000004},\n",
       " 'antecedent': {'valence': 0.42700000000000005,\n",
       "  'arousal': 0.551,\n",
       "  'dominance': 0.5660000000000001},\n",
       " 'antelope': {'valence': 0.542, 'arousal': 0.51, 'dominance': 0.5},\n",
       " 'antenna': {'valence': 0.521, 'arousal': 0.327, 'dominance': 0.358},\n",
       " 'anterior': {'valence': 0.51,\n",
       "  'arousal': 0.245,\n",
       "  'dominance': 0.36200000000000004},\n",
       " 'anthem': {'valence': 0.78,\n",
       "  'arousal': 0.34299999999999997,\n",
       "  'dominance': 0.7290000000000001},\n",
       " 'anthill': {'valence': 0.327, 'arousal': 0.578, 'dominance': 0.377},\n",
       " 'anthology': {'valence': 0.33799999999999997,\n",
       "  'arousal': 0.406,\n",
       "  'dominance': 0.537},\n",
       " 'anthrax': {'valence': 0.188, 'arousal': 0.73, 'dominance': 0.5},\n",
       " 'anthropological': {'valence': 0.36700000000000005,\n",
       "  'arousal': 0.39,\n",
       "  'dominance': 0.49},\n",
       " 'anthropologist': {'valence': 0.551, 'arousal': 0.385, 'dominance': 0.725},\n",
       " 'anthropology': {'valence': 0.49,\n",
       "  'arousal': 0.36700000000000005,\n",
       "  'dominance': 0.5820000000000001},\n",
       " 'anti': {'valence': 0.365,\n",
       "  'arousal': 0.41200000000000003,\n",
       "  'dominance': 0.384},\n",
       " 'antiaircraft': {'valence': 0.33, 'arousal': 0.622, 'dominance': 0.629},\n",
       " 'antibiotic': {'valence': 0.51,\n",
       "  'arousal': 0.373,\n",
       "  'dominance': 0.6579999999999999},\n",
       " 'antibiotics': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.406,\n",
       "  'dominance': 0.557},\n",
       " 'antichrist': {'valence': 0.08199999999999999,\n",
       "  'arousal': 0.8370000000000001,\n",
       "  'dominance': 0.544},\n",
       " 'anticipate': {'valence': 0.622, 'arousal': 0.469, 'dominance': 0.667},\n",
       " 'anticipation': {'valence': 0.698, 'arousal': 0.539, 'dominance': 0.711},\n",
       " 'anticipatory': {'valence': 0.653, 'arousal': 0.551, 'dominance': 0.682},\n",
       " 'antics': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.74,\n",
       "  'dominance': 0.23600000000000002},\n",
       " 'antidote': {'valence': 0.541, 'arousal': 0.49, 'dominance': 0.629},\n",
       " 'antifungal': {'valence': 0.408,\n",
       "  'arousal': 0.41200000000000003,\n",
       "  'dominance': 0.441},\n",
       " 'antigravity': {'valence': 0.43,\n",
       "  'arousal': 0.7140000000000001,\n",
       "  'dominance': 0.6579999999999999},\n",
       " 'antimony': {'valence': 0.37799999999999995,\n",
       "  'arousal': 0.39799999999999996,\n",
       "  'dominance': 0.49},\n",
       " 'antipathy': {'valence': 0.198,\n",
       "  'arousal': 0.5489999999999999,\n",
       "  'dominance': 0.39299999999999996},\n",
       " 'antiquarian': {'valence': 0.5, 'arousal': 0.233, 'dominance': 0.426},\n",
       " 'antiquated': {'valence': 0.42,\n",
       "  'arousal': 0.392,\n",
       "  'dominance': 0.23600000000000002},\n",
       " 'antique': {'valence': 0.634, 'arousal': 0.29, 'dominance': 0.518},\n",
       " 'antiques': {'valence': 0.54, 'arousal': 0.37, 'dominance': 0.595},\n",
       " 'antiquity': {'valence': 0.385,\n",
       "  'arousal': 0.33299999999999996,\n",
       "  'dominance': 0.556},\n",
       " 'antiseptic': {'valence': 0.43799999999999994,\n",
       "  'arousal': 0.37,\n",
       "  'dominance': 0.623},\n",
       " 'antisocial': {'valence': 0.146,\n",
       "  'arousal': 0.6859999999999999,\n",
       "  'dominance': 0.391},\n",
       " 'antithesis': {'valence': 0.396,\n",
       "  'arousal': 0.41200000000000003,\n",
       "  'dominance': 0.536},\n",
       " 'antithetical': {'valence': 0.271, 'arousal': 0.509, 'dominance': 0.358},\n",
       " 'antiviral': {'valence': 0.45899999999999996,\n",
       "  'arousal': 0.47,\n",
       "  'dominance': 0.5489999999999999},\n",
       " 'antler': {'valence': 0.44799999999999995, 'arousal': 0.47, 'dominance': 0.5},\n",
       " 'antsy': {'valence': 0.449,\n",
       "  'arousal': 0.5579999999999999,\n",
       "  'dominance': 0.41700000000000004},\n",
       " 'anus': {'valence': 0.34700000000000003, 'arousal': 0.644, 'dominance': 0.35},\n",
       " 'anvil': {'valence': 0.38, 'arousal': 0.51, 'dominance': 0.604},\n",
       " 'anxiety': {'valence': 0.146, 'arousal': 0.865, 'dominance': 0.342},\n",
       " 'anxietyattack': {'valence': 0.15, 'arousal': 0.925, 'dominance': 0.446},\n",
       " 'anxious': {'valence': 0.281, 'arousal': 0.875, 'dominance': 0.434},\n",
       " 'anxiousness': {'valence': 0.235,\n",
       "  'arousal': 0.8140000000000001,\n",
       "  'dominance': 0.282},\n",
       " 'anytime': {'valence': 0.625, 'arousal': 0.461, 'dominance': 0.436},\n",
       " 'aorta': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.51,\n",
       "  'dominance': 0.542},\n",
       " 'aortic': {'valence': 0.436,\n",
       "  'arousal': 0.54,\n",
       "  'dominance': 0.43799999999999994},\n",
       " 'apace': {'valence': 0.536, 'arousal': 0.5, 'dominance': 0.536},\n",
       " 'apache': {'valence': 0.687, 'arousal': 0.469, 'dominance': 0.5},\n",
       " 'apartment': {'valence': 0.7190000000000001,\n",
       "  'arousal': 0.39299999999999996,\n",
       "  'dominance': 0.58},\n",
       " 'apartments': {'valence': 0.7040000000000001,\n",
       "  'arousal': 0.337,\n",
       "  'dominance': 0.44299999999999995},\n",
       " 'apathetic': {'valence': 0.188,\n",
       "  'arousal': 0.292,\n",
       "  'dominance': 0.33299999999999996},\n",
       " 'apathy': {'valence': 0.184, 'arousal': 0.212, 'dominance': 0.204},\n",
       " 'ape': {'valence': 0.5479999999999999, 'arousal': 0.389, 'dominance': 0.336},\n",
       " 'aperture': {'valence': 0.612, 'arousal': 0.45, 'dominance': 0.667},\n",
       " 'apex': {'valence': 0.57, 'arousal': 0.433, 'dominance': 0.418},\n",
       " 'aphid': {'valence': 0.38799999999999996,\n",
       "  'arousal': 0.473,\n",
       "  'dominance': 0.40700000000000003},\n",
       " 'aphrodisiac': {'valence': 0.75, 'arousal': 0.846, 'dominance': 0.667},\n",
       " 'apiece': {'valence': 0.439,\n",
       "  'arousal': 0.259,\n",
       "  'dominance': 0.38299999999999995},\n",
       " 'aplomb': {'valence': 0.5, 'arousal': 0.509, 'dominance': 0.5820000000000001},\n",
       " 'apocalypse': {'valence': 0.05, 'arousal': 0.867, 'dominance': 0.736},\n",
       " 'apocalyptic': {'valence': 0.17300000000000001,\n",
       "  'arousal': 0.88,\n",
       "  'dominance': 0.75},\n",
       " 'apologetic': {'valence': 0.479,\n",
       "  'arousal': 0.461,\n",
       "  'dominance': 0.5710000000000001},\n",
       " 'apologist': {'valence': 0.406, 'arousal': 0.429, 'dominance': 0.526},\n",
       " 'apologize': {'valence': 0.551,\n",
       "  'arousal': 0.37799999999999995,\n",
       "  'dominance': 0.389},\n",
       " 'apology': {'valence': 0.5710000000000001,\n",
       "  'arousal': 0.34600000000000003,\n",
       "  'dominance': 0.402},\n",
       " 'apostasy': {'valence': 0.38799999999999996,\n",
       "  'arousal': 0.52,\n",
       "  'dominance': 0.517},\n",
       " 'apostate': {'valence': 0.342, 'arousal': 0.5, 'dominance': 0.528},\n",
       " 'apostle': {'valence': 0.6459999999999999,\n",
       "  'arousal': 0.34700000000000003,\n",
       "  'dominance': 0.732},\n",
       " 'apostolic': {'valence': 0.5920000000000001,\n",
       "  'arousal': 0.3,\n",
       "  'dominance': 0.7170000000000001},\n",
       " 'apostrophe': {'valence': 0.469, 'arousal': 0.368, 'dominance': 0.537},\n",
       " 'apothecary': {'valence': 0.561,\n",
       "  'arousal': 0.32799999999999996,\n",
       "  'dominance': 0.529},\n",
       " 'appalled': {'valence': 0.19399999999999998,\n",
       "  'arousal': 0.792,\n",
       "  'dominance': 0.562},\n",
       " 'appalling': {'valence': 0.16,\n",
       "  'arousal': 0.8270000000000001,\n",
       "  'dominance': 0.415},\n",
       " 'apparatus': {'valence': 0.375, 'arousal': 0.353, 'dominance': 0.377},\n",
       " 'apparel': {'valence': 0.698,\n",
       "  'arousal': 0.435,\n",
       "  'dominance': 0.45299999999999996},\n",
       " 'apparent': {'valence': 0.473,\n",
       "  'arousal': 0.38299999999999995,\n",
       "  'dominance': 0.39799999999999996},\n",
       " 'apparently': {'valence': 0.531, 'arousal': 0.41, 'dominance': 0.426},\n",
       " 'apparition': {'valence': 0.406, 'arousal': 0.573, 'dominance': 0.636},\n",
       " 'appeal': {'valence': 0.6629999999999999,\n",
       "  'arousal': 0.598,\n",
       "  'dominance': 0.5579999999999999},\n",
       " 'appear': {'valence': 0.735,\n",
       "  'arousal': 0.506,\n",
       "  'dominance': 0.5670000000000001},\n",
       " 'appearance': {'valence': 0.669, 'arousal': 0.49, 'dominance': 0.534},\n",
       " 'appease': {'valence': 0.633, 'arousal': 0.278, 'dominance': 0.434},\n",
       " 'appellant': {'valence': 0.327, 'arousal': 0.588, 'dominance': 0.568},\n",
       " 'append': {'valence': 0.573,\n",
       "  'arousal': 0.46399999999999997,\n",
       "  'dominance': 0.45299999999999996},\n",
       " 'appendage': {'valence': 0.22899999999999998,\n",
       "  'arousal': 0.382,\n",
       "  'dominance': 0.43799999999999994},\n",
       " 'appendectomy': {'valence': 0.177,\n",
       "  'arousal': 0.67,\n",
       "  'dominance': 0.5539999999999999},\n",
       " 'appendicitis': {'valence': 0.031,\n",
       "  'arousal': 0.64,\n",
       "  'dominance': 0.34700000000000003},\n",
       " 'appendix': {'valence': 0.365, 'arousal': 0.387, 'dominance': 0.425},\n",
       " 'appetite': {'valence': 0.7040000000000001,\n",
       "  'arousal': 0.637,\n",
       "  'dominance': 0.581},\n",
       " 'appetizer': {'valence': 0.755, 'arousal': 0.56, 'dominance': 0.406},\n",
       " 'appetizing': {'valence': 0.8059999999999999,\n",
       "  'arousal': 0.657,\n",
       "  'dominance': 0.688},\n",
       " 'applaud': {'valence': 0.865,\n",
       "  'arousal': 0.8240000000000001,\n",
       "  'dominance': 0.46399999999999997},\n",
       " 'applause': {'valence': 0.953, 'arousal': 0.857, 'dominance': 0.621},\n",
       " 'apple': {'valence': 0.8109999999999999, 'arousal': 0.3, 'dominance': 0.264},\n",
       " 'apple juice': {'valence': 0.765, 'arousal': 0.204, 'dominance': 0.294},\n",
       " 'applejack': {'valence': 0.604, 'arousal': 0.431, 'dominance': 0.473},\n",
       " 'applesauce': {'valence': 0.75,\n",
       "  'arousal': 0.16699999999999998,\n",
       "  'dominance': 0.29100000000000004},\n",
       " 'appliance': {'valence': 0.5820000000000001,\n",
       "  'arousal': 0.45299999999999996,\n",
       "  'dominance': 0.5379999999999999},\n",
       " 'appliances': {'valence': 0.594,\n",
       "  'arousal': 0.39399999999999996,\n",
       "  'dominance': 0.5670000000000001},\n",
       " 'applicability': {'valence': 0.677, 'arousal': 0.49, 'dominance': 0.741},\n",
       " 'applicable': {'valence': 0.469, 'arousal': 0.43, 'dominance': 0.667},\n",
       " 'applicant': {'valence': 0.612,\n",
       "  'arousal': 0.5579999999999999,\n",
       "  'dominance': 0.688},\n",
       " 'application': {'valence': 0.6459999999999999,\n",
       "  'arousal': 0.445,\n",
       "  'dominance': 0.726},\n",
       " 'apply': {'valence': 0.612, 'arousal': 0.321, 'dominance': 0.667},\n",
       " 'appoint': {'valence': 0.565, 'arousal': 0.33, 'dominance': 0.509},\n",
       " 'appointment': {'valence': 0.688, 'arousal': 0.594, 'dominance': 0.547},\n",
       " 'appointments': {'valence': 0.745, 'arousal': 0.677, 'dominance': 0.625},\n",
       " 'apportion': {'valence': 0.677, 'arousal': 0.49, 'dominance': 0.638},\n",
       " 'apportionment': {'valence': 0.552,\n",
       "  'arousal': 0.48100000000000004,\n",
       "  'dominance': 0.45299999999999996},\n",
       " 'appraisal': {'valence': 0.41700000000000004,\n",
       "  'arousal': 0.667,\n",
       "  'dominance': 0.682},\n",
       " 'appraise': {'valence': 0.677, 'arousal': 0.49, 'dominance': 0.696},\n",
       " 'appreciable': {'valence': 0.873, 'arousal': 0.491, 'dominance': 0.778},\n",
       " 'appreciate': {'valence': 0.885,\n",
       "  'arousal': 0.42200000000000004,\n",
       "  'dominance': 0.741},\n",
       " 'appreciated': {'valence': 0.91, 'arousal': 0.434, 'dominance': 0.779},\n",
       " 'appreciates': {'valence': 0.765,\n",
       "  'arousal': 0.5,\n",
       "  'dominance': 0.6559999999999999},\n",
       " 'appreciation': {'valence': 0.917, 'arousal': 0.529, 'dominance': 0.588},\n",
       " 'appreciative': {'valence': 0.857, 'arousal': 0.38, 'dominance': 0.654},\n",
       " 'apprehend': {'valence': 0.521, 'arousal': 0.624, 'dominance': 0.696},\n",
       " 'apprehension': {'valence': 0.385,\n",
       "  'arousal': 0.72,\n",
       "  'dominance': 0.45399999999999996},\n",
       " 'apprehensive': {'valence': 0.406,\n",
       "  'arousal': 0.5920000000000001,\n",
       "  'dominance': 0.431},\n",
       " 'apprentice': {'valence': 0.615, 'arousal': 0.413, 'dominance': 0.452},\n",
       " 'apprenticeship': {'valence': 0.812,\n",
       "  'arousal': 0.48200000000000004,\n",
       "  'dominance': 0.643},\n",
       " 'approach': {'valence': 0.612, 'arousal': 0.392, 'dominance': 0.61},\n",
       " 'approaching': {'valence': 0.74, 'arousal': 0.557, 'dominance': 0.491},\n",
       " 'approbate': {'valence': 0.6459999999999999,\n",
       "  'arousal': 0.59,\n",
       "  'dominance': 0.86},\n",
       " 'approbation': {'valence': 0.792, 'arousal': 0.529, 'dominance': 0.774},\n",
       " 'appropriate': {'valence': 0.833, 'arousal': 0.368, 'dominance': 0.759},\n",
       " 'appropriation': {'valence': 0.51,\n",
       "  'arousal': 0.632,\n",
       "  'dominance': 0.7170000000000001},\n",
       " 'approval': {'valence': 0.8540000000000001,\n",
       "  'arousal': 0.46,\n",
       "  'dominance': 0.889},\n",
       " 'approve': {'valence': 0.875,\n",
       "  'arousal': 0.5479999999999999,\n",
       "  'dominance': 0.741},\n",
       " 'approved': {'valence': 0.833, 'arousal': 0.349, 'dominance': 0.698},\n",
       " 'approvement': {'valence': 0.88, 'arousal': 0.625, 'dominance': 0.78},\n",
       " 'approving': {'valence': 0.917, 'arousal': 0.583, 'dominance': 0.773},\n",
       " 'approximate': {'valence': 0.551, 'arousal': 0.56, 'dominance': 0.52},\n",
       " 'approximately': {'valence': 0.622,\n",
       "  'arousal': 0.396,\n",
       "  'dominance': 0.5379999999999999},\n",
       " 'approximating': {'valence': 0.583,\n",
       "  'arousal': 0.615,\n",
       "  'dominance': 0.47100000000000003},\n",
       " 'approximation': {'valence': 0.5820000000000001,\n",
       "  'arousal': 0.402,\n",
       "  'dominance': 0.593},\n",
       " 'appurtenances': {'valence': 0.573,\n",
       "  'arousal': 0.41200000000000003,\n",
       "  'dominance': 0.547},\n",
       " 'apricot': {'valence': 0.708, 'arousal': 0.32, 'dominance': 0.278},\n",
       " 'apron': {'valence': 0.5820000000000001,\n",
       "  'arousal': 0.20800000000000002,\n",
       "  'dominance': 0.245},\n",
       " 'apt': {'valence': 0.5820000000000001, 'arousal': 0.418, 'dominance': 0.382},\n",
       " 'aptitude': {'valence': 0.75,\n",
       "  'arousal': 0.47100000000000003,\n",
       "  'dominance': 0.746},\n",
       " 'aqua': {'valence': 0.6559999999999999, 'arousal': 0.292, 'dominance': 0.359},\n",
       " 'aquamarine': {'valence': 0.7290000000000001,\n",
       "  'arousal': 0.306,\n",
       "  'dominance': 0.413},\n",
       " 'aquarium': {'valence': 0.6629999999999999,\n",
       "  'arousal': 0.327,\n",
       "  'dominance': 0.39299999999999996},\n",
       " 'aquatic': {'valence': 0.677,\n",
       "  'arousal': 0.51,\n",
       "  'dominance': 0.46299999999999997},\n",
       " 'aqueduct': {'valence': 0.551,\n",
       "  'arousal': 0.41100000000000003,\n",
       "  'dominance': 0.534},\n",
       " 'aqueous': {'valence': 0.429, 'arousal': 0.27, 'dominance': 0.31},\n",
       " 'arable': {'valence': 0.51, 'arousal': 0.35, 'dominance': 0.465},\n",
       " 'arbiter': {'valence': 0.561,\n",
       "  'arousal': 0.537,\n",
       "  'dominance': 0.8140000000000001},\n",
       " 'arbitrary': {'valence': 0.281,\n",
       "  'arousal': 0.7020000000000001,\n",
       "  'dominance': 0.6859999999999999},\n",
       " 'arbitrate': {'valence': 0.47, 'arousal': 0.62, 'dominance': 0.682},\n",
       " 'arbitration': {'valence': 0.5870000000000001,\n",
       "  'arousal': 0.602,\n",
       "  'dominance': 0.67},\n",
       " 'arbitrator': {'valence': 0.385,\n",
       "  'arousal': 0.44799999999999995,\n",
       "  'dominance': 0.795},\n",
       " 'arbor': {'valence': 0.583, 'arousal': 0.49, 'dominance': 0.591},\n",
       " 'arc': {'valence': 0.552, 'arousal': 0.38799999999999996, 'dominance': 0.396},\n",
       " 'arcade': {'valence': 0.6759999999999999,\n",
       "  'arousal': 0.521,\n",
       "  'dominance': 0.502},\n",
       " 'arcane': {'valence': 0.5, 'arousal': 0.49, 'dominance': 0.637},\n",
       " 'arch': {'valence': 0.5, 'arousal': 0.354, 'dominance': 0.46799999999999997},\n",
       " 'archaeological': {'valence': 0.74, 'arousal': 0.441, 'dominance': 0.66},\n",
       " 'archaeologist': {'valence': 0.552, 'arousal': 0.451, 'dominance': 0.706},\n",
       " 'archaeology': {'valence': 0.596, 'arousal': 0.358, 'dominance': 0.691},\n",
       " 'archaic': {'valence': 0.271, 'arousal': 0.327, 'dominance': 0.332},\n",
       " 'archangel': {'valence': 0.8370000000000001,\n",
       "  'arousal': 0.5,\n",
       "  'dominance': 0.708},\n",
       " 'archbishop': {'valence': 0.622,\n",
       "  'arousal': 0.28,\n",
       "  'dominance': 0.7759999999999999},\n",
       " 'archdiocese': {'valence': 0.4,\n",
       "  'arousal': 0.321,\n",
       "  'dominance': 0.7040000000000001},\n",
       " 'archduke': {'valence': 0.45799999999999996,\n",
       "  'arousal': 0.413,\n",
       "  'dominance': 0.634},\n",
       " 'arched': {'valence': 0.5820000000000001,\n",
       "  'arousal': 0.40299999999999997,\n",
       "  'dominance': 0.39799999999999996},\n",
       " 'archer': {'valence': 0.573,\n",
       "  'arousal': 0.622,\n",
       "  'dominance': 0.6609999999999999},\n",
       " 'archery': {'valence': 0.594, 'arousal': 0.604, 'dominance': 0.589},\n",
       " 'archetype': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.52,\n",
       "  'dominance': 0.569},\n",
       " 'archipelago': {'valence': 0.745,\n",
       "  'arousal': 0.37,\n",
       "  'dominance': 0.5920000000000001},\n",
       " 'architect': {'valence': 0.7759999999999999,\n",
       "  'arousal': 0.442,\n",
       "  'dominance': 0.836},\n",
       " 'architectural': {'valence': 0.7290000000000001,\n",
       "  'arousal': 0.39,\n",
       "  'dominance': 0.67},\n",
       " 'architecture': {'valence': 0.82,\n",
       "  'arousal': 0.39,\n",
       "  'dominance': 0.6940000000000001},\n",
       " 'archive': {'valence': 0.43799999999999994,\n",
       "  'arousal': 0.294,\n",
       "  'dominance': 0.527},\n",
       " 'arctic': {'valence': 0.615,\n",
       "  'arousal': 0.35200000000000004,\n",
       "  'dominance': 0.546},\n",
       " 'ardent': {'valence': 0.6940000000000001,\n",
       "  'arousal': 0.873,\n",
       "  'dominance': 0.722},\n",
       " 'ardor': {'valence': 0.5, 'arousal': 0.78, 'dominance': 0.5379999999999999},\n",
       " 'arduous': {'valence': 0.344,\n",
       "  'arousal': 0.7829999999999999,\n",
       "  'dominance': 0.605},\n",
       " 'area': {'valence': 0.49, 'arousal': 0.306, 'dominance': 0.46399999999999997},\n",
       " 'arena': {'valence': 0.51,\n",
       "  'arousal': 0.235,\n",
       "  'dominance': 0.40399999999999997},\n",
       " 'areola': {'valence': 0.41700000000000004,\n",
       "  'arousal': 0.396,\n",
       "  'dominance': 0.381},\n",
       " 'areyoukidding': {'valence': 0.429, 'arousal': 0.633, 'dominance': 0.4},\n",
       " 'areyoukiddingme': {'valence': 0.365, 'arousal': 0.635, 'dominance': 0.375},\n",
       " 'argent': {'valence': 0.594,\n",
       "  'arousal': 0.418,\n",
       "  'dominance': 0.47200000000000003},\n",
       " 'argh': {'valence': 0.26,\n",
       "  'arousal': 0.5379999999999999,\n",
       "  'dominance': 0.32799999999999996},\n",
       " 'arghh': {'valence': 0.292, 'arousal': 0.536, 'dominance': 0.397},\n",
       " 'arghhhh': {'valence': 0.25, 'arousal': 0.618, 'dominance': 0.324},\n",
       " 'argue': {'valence': 0.09300000000000001,\n",
       "  'arousal': 0.7979999999999999,\n",
       "  'dominance': 0.525},\n",
       " 'argument': {'valence': 0.51,\n",
       "  'arousal': 0.46399999999999997,\n",
       "  'dominance': 0.698},\n",
       " 'argumentation': {'valence': 0.479,\n",
       "  'arousal': 0.5489999999999999,\n",
       "  'dominance': 0.76},\n",
       " 'argumentative': {'valence': 0.45, 'arousal': 0.531, 'dominance': 0.679},\n",
       " 'arguments': {'valence': 0.541, 'arousal': 0.602, 'dominance': 0.657},\n",
       " 'arid': {'valence': 0.32299999999999995,\n",
       "  'arousal': 0.33299999999999996,\n",
       "  'dominance': 0.379},\n",
       " 'arise': {'valence': 0.75, 'arousal': 0.5820000000000001, 'dominance': 0.725},\n",
       " 'aristocracy': {'valence': 0.688,\n",
       "  'arousal': 0.5489999999999999,\n",
       "  'dominance': 0.8420000000000001},\n",
       " 'aristocrat': {'valence': 0.583,\n",
       "  'arousal': 0.413,\n",
       "  'dominance': 0.8109999999999999},\n",
       " 'aristocratic': {'valence': 0.449,\n",
       "  'arousal': 0.519,\n",
       "  'dominance': 0.6759999999999999},\n",
       " 'arithmetic': {'valence': 0.45299999999999996,\n",
       "  'arousal': 0.46,\n",
       "  'dominance': 0.634},\n",
       " 'ark': {'valence': 0.396,\n",
       "  'arousal': 0.42700000000000005,\n",
       "  'dominance': 0.5429999999999999},\n",
       " 'arm': {'valence': 0.552, 'arousal': 0.285, 'dominance': 0.469},\n",
       " 'armada': {'valence': 0.408, 'arousal': 0.74, 'dominance': 0.868},\n",
       " 'armament': {'valence': 0.198, 'arousal': 0.764, 'dominance': 0.81},\n",
       " 'armaments': {'valence': 0.192,\n",
       "  'arousal': 0.8390000000000001,\n",
       "  'dominance': 0.83},\n",
       " 'armature': {'valence': 0.51,\n",
       "  'arousal': 0.5579999999999999,\n",
       "  'dominance': 0.755},\n",
       " 'armchair': {'valence': 0.6459999999999999,\n",
       "  'arousal': 0.16399999999999998,\n",
       "  'dominance': 0.33899999999999997},\n",
       " 'armed': {'valence': 0.188, 'arousal': 0.75, 'dominance': 0.8079999999999999},\n",
       " 'armor': {'valence': 0.469, 'arousal': 0.625, 'dominance': 0.784},\n",
       " 'armored': {'valence': 0.469, 'arousal': 0.509, 'dominance': 0.861},\n",
       " 'armory': {'valence': 0.44799999999999995,\n",
       "  'arousal': 0.6629999999999999,\n",
       "  'dominance': 0.8},\n",
       " 'armpit': {'valence': 0.28300000000000003,\n",
       "  'arousal': 0.439,\n",
       "  'dominance': 0.25},\n",
       " 'arms': {'valence': 0.46399999999999997,\n",
       "  'arousal': 0.395,\n",
       "  'dominance': 0.483},\n",
       " 'army': {'valence': 0.41700000000000004,\n",
       "  'arousal': 0.759,\n",
       "  'dominance': 0.902},\n",
       " 'aroma': {'valence': 0.823, 'arousal': 0.235, 'dominance': 0.442},\n",
       " 'aromatherapy': {'valence': 0.847, 'arousal': 0.22, 'dominance': 0.473},\n",
       " 'arousal': {'valence': 0.7909999999999999,\n",
       "  'arousal': 0.943,\n",
       "  'dominance': 0.731},\n",
       " 'arouse': {'valence': 0.74, 'arousal': 0.491, 'dominance': 0.58},\n",
       " 'aroused': {'valence': 0.708,\n",
       "  'arousal': 0.9520000000000001,\n",
       "  'dominance': 0.667},\n",
       " 'arraignment': {'valence': 0.406,\n",
       "  'arousal': 0.8370000000000001,\n",
       "  'dominance': 0.534},\n",
       " 'arrange': {'valence': 0.74,\n",
       "  'arousal': 0.49,\n",
       "  'dominance': 0.5710000000000001},\n",
       " 'arranged': {'valence': 0.698, 'arousal': 0.531, 'dominance': 0.728},\n",
       " 'arrangement': {'valence': 0.625,\n",
       "  'arousal': 0.382,\n",
       "  'dominance': 0.6829999999999999},\n",
       " 'array': {'valence': 0.521, 'arousal': 0.396, 'dominance': 0.568},\n",
       " 'arrears': {'valence': 0.28600000000000003,\n",
       "  'arousal': 0.485,\n",
       "  'dominance': 0.302},\n",
       " 'arrest': {'valence': 0.146, 'arousal': 0.951, 'dominance': 0.5},\n",
       " 'arrhythmia': {'valence': 0.265,\n",
       "  'arousal': 0.706,\n",
       "  'dominance': 0.35600000000000004},\n",
       " 'arrival': {'valence': 0.6779999999999999,\n",
       "  'arousal': 0.51,\n",
       "  'dominance': 0.474},\n",
       " 'arrive': {'valence': 0.8370000000000001,\n",
       "  'arousal': 0.406,\n",
       "  'dominance': 0.585},\n",
       " 'arrogance': {'valence': 0.14300000000000002,\n",
       "  'arousal': 0.75,\n",
       "  'dominance': 0.62},\n",
       " 'arrogant': {'valence': 0.115, 'arousal': 0.755, 'dominance': 0.58},\n",
       " 'arrow': {'valence': 0.439,\n",
       "  'arousal': 0.39,\n",
       "  'dominance': 0.45399999999999996},\n",
       " 'arsehole': {'valence': 0.276, 'arousal': 0.598, 'dominance': 0.433},\n",
       " 'arseholes': {'valence': 0.188,\n",
       "  'arousal': 0.545,\n",
       "  'dominance': 0.35100000000000003},\n",
       " 'arsenal': {'valence': 0.365, 'arousal': 0.741, 'dominance': 0.752},\n",
       " 'arsenic': {'valence': 0.281,\n",
       "  'arousal': 0.47200000000000003,\n",
       "  'dominance': 0.447},\n",
       " 'arson': {'valence': 0.133,\n",
       "  'arousal': 0.904,\n",
       "  'dominance': 0.5670000000000001},\n",
       " 'arsonist': {'valence': 0.348, 'arousal': 0.84, 'dominance': 0.5},\n",
       " 'art': {'valence': 0.812, 'arousal': 0.36, 'dominance': 0.603},\n",
       " 'arterial': {'valence': 0.396, 'arousal': 0.51, 'dominance': 0.583},\n",
       " 'artery': {'valence': 0.396, 'arousal': 0.58, 'dominance': 0.537},\n",
       " 'artful': {'valence': 0.7709999999999999,\n",
       "  'arousal': 0.608,\n",
       "  'dominance': 0.778},\n",
       " 'arthritis': {'valence': 0.11, 'arousal': 0.518, 'dominance': 0.345},\n",
       " 'arthropod': {'valence': 0.344,\n",
       "  'arousal': 0.46399999999999997,\n",
       "  'dominance': 0.434},\n",
       " 'artichoke': {'valence': 0.583, 'arousal': 0.218, 'dominance': 0.287},\n",
       " 'article': {'valence': 0.594,\n",
       "  'arousal': 0.28,\n",
       "  'dominance': 0.48100000000000004},\n",
       " 'articles': {'valence': 0.552, 'arousal': 0.324, 'dominance': 0.565},\n",
       " 'articulate': {'valence': 0.677, 'arousal': 0.462, 'dominance': 0.618},\n",
       " 'articulation': {'valence': 0.479, 'arousal': 0.48, 'dominance': 0.591},\n",
       " 'artifact': {'valence': 0.51,\n",
       "  'arousal': 0.5,\n",
       "  'dominance': 0.5660000000000001},\n",
       " 'artifice': {'valence': 0.316,\n",
       "  'arousal': 0.696,\n",
       "  'dominance': 0.48200000000000004},\n",
       " 'artificial': {'valence': 0.306,\n",
       "  'arousal': 0.385,\n",
       "  'dominance': 0.35100000000000003},\n",
       " 'artillery': {'valence': 0.35, 'arousal': 0.912, 'dominance': 0.794},\n",
       " 'artisan': {'valence': 0.7809999999999999,\n",
       "  'arousal': 0.33,\n",
       "  'dominance': 0.41100000000000003},\n",
       " 'artist': {'valence': 0.802, 'arousal': 0.442, 'dominance': 0.732},\n",
       " 'artiste': {'valence': 0.8440000000000001,\n",
       "  'arousal': 0.512,\n",
       "  'dominance': 0.565},\n",
       " 'artistic': {'valence': 0.802,\n",
       "  'arousal': 0.6459999999999999,\n",
       "  'dominance': 0.632},\n",
       " 'artistry': {'valence': 0.823,\n",
       "  'arousal': 0.34600000000000003,\n",
       "  'dominance': 0.769},\n",
       " 'artists': {'valence': 0.7959999999999999,\n",
       "  'arousal': 0.667,\n",
       "  'dominance': 0.741},\n",
       " 'artwork': {'valence': 0.8959999999999999,\n",
       "  'arousal': 0.368,\n",
       "  'dominance': 0.679},\n",
       " 'arty': {'valence': 0.49,\n",
       "  'arousal': 0.42200000000000004,\n",
       "  'dominance': 0.38799999999999996},\n",
       " 'asap': {'valence': 0.5710000000000001, 'arousal': 0.5, 'dominance': 0.552},\n",
       " ...}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load style lexicon\n",
    "\n",
    "# lexicon_fpath = '/projects/quarantine_impacts/lexicons/combined_lexicon.csv'\n",
    "# lexicon_data = pd.read_csv(lexicon_fpath)\n",
    "# lexicon = lexicon_data.set_index('word').to_dict(orient='index')\n",
    "\n",
    "lexicon_fpath = '/projects/quarantine_impacts/lexicons/NRC-VAD-Lexicon.txt'\n",
    "lexicon_data = pd.read_csv(lexicon_fpath, sep='\\t')\n",
    "lexicon_data.columns = [col.lower() for col in lexicon_data.columns]\n",
    "lexicon = lexicon_data.set_index('word').to_dict(orient='index')\n",
    "\n",
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d7bb98a20140018fbab0303ac6b44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fic_id</th>\n",
       "      <th>pairing</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>concreteness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001573</td>\n",
       "      <td>(hermione, ron)</td>\n",
       "      <td>0.174962</td>\n",
       "      <td>0.123308</td>\n",
       "      <td>0.126557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10040978</td>\n",
       "      <td>(hermione, ron)</td>\n",
       "      <td>0.128520</td>\n",
       "      <td>0.097067</td>\n",
       "      <td>0.107550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10050407</td>\n",
       "      <td>(hermione, ron)</td>\n",
       "      <td>0.148854</td>\n",
       "      <td>0.102437</td>\n",
       "      <td>0.118846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10050761</td>\n",
       "      <td>(hermione, ron)</td>\n",
       "      <td>0.150165</td>\n",
       "      <td>0.108002</td>\n",
       "      <td>0.123809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10052243</td>\n",
       "      <td>(hermione, ron)</td>\n",
       "      <td>0.133889</td>\n",
       "      <td>0.102045</td>\n",
       "      <td>0.115608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>9884660</td>\n",
       "      <td>(ginny, harry)</td>\n",
       "      <td>0.133975</td>\n",
       "      <td>0.100190</td>\n",
       "      <td>0.113507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>9893540</td>\n",
       "      <td>(ginny, harry)</td>\n",
       "      <td>0.134738</td>\n",
       "      <td>0.118648</td>\n",
       "      <td>0.125928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>9893891</td>\n",
       "      <td>(ginny, harry)</td>\n",
       "      <td>0.152122</td>\n",
       "      <td>0.095622</td>\n",
       "      <td>0.124970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>9894032</td>\n",
       "      <td>(ginny, harry)</td>\n",
       "      <td>0.152954</td>\n",
       "      <td>0.106079</td>\n",
       "      <td>0.123699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>9896951</td>\n",
       "      <td>(ginny, harry)</td>\n",
       "      <td>0.136102</td>\n",
       "      <td>0.106934</td>\n",
       "      <td>0.114563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4840 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fic_id          pairing   valence   arousal  dominance  concreteness\n",
       "0      1001573  (hermione, ron)  0.174962  0.123308   0.126557             0\n",
       "1     10040978  (hermione, ron)  0.128520  0.097067   0.107550             0\n",
       "2     10050407  (hermione, ron)  0.148854  0.102437   0.118846             0\n",
       "3     10050761  (hermione, ron)  0.150165  0.108002   0.123809             0\n",
       "4     10052243  (hermione, ron)  0.133889  0.102045   0.115608             0\n",
       "...        ...              ...       ...       ...        ...           ...\n",
       "4835   9884660   (ginny, harry)  0.133975  0.100190   0.113507             0\n",
       "4836   9893540   (ginny, harry)  0.134738  0.118648   0.125928             0\n",
       "4837   9893891   (ginny, harry)  0.152122  0.095622   0.124970             0\n",
       "4838   9894032   (ginny, harry)  0.152954  0.106079   0.123699             0\n",
       "4839   9896951   (ginny, harry)  0.136102  0.106934   0.114563             0\n",
       "\n",
       "[4840 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get style lexicon scores for every fic\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def lexicon_scores(text):\n",
    "#     text_values = {key: 0 for key in ['valence', 'arousal', 'dominance', 'concreteness']}      \n",
    "    text_values = Counter({key: 0 for key in ['valence', 'arousal', 'dominance', 'concreteness']})\n",
    "    for tok in text.split():\n",
    "        if tok in lexicon:\n",
    "            text_values = Counter(lexicon[tok]) + text_values\n",
    "            \n",
    "    return {key: val/len(text.split()) for key, val in text_values.items()}\n",
    "\n",
    "import re\n",
    "\n",
    "def pairing_present(text, pairing):\n",
    "     if re.search(r'\\b{}\\b'.format(pairing[0]), text) and re.search(r'\\b{}\\b'.format(pairing[1]), text):\n",
    "        return True\n",
    "     else:\n",
    "        return False\n",
    "\n",
    "# Join with story texts, find paragraphs with both characters\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import pdb\n",
    "\n",
    "story_dirpath = '/data/fanfiction_ao3/harrypotter/preprocessed_paras/'\n",
    "# story_dirpath = '/usr2/mamille2/fanfiction-project/data/ao3/harrypotter/fics_paras'\n",
    "lexicon_outlines = []\n",
    "\n",
    "for fic_id, pairing in tqdm(list(zip(train['fic_id'], train['pairing']))):\n",
    "    fic_fpath = os.path.join(story_dirpath, f'{fic_id}.txt')\n",
    "    fic_lexicon_totals = Counter({key: 0 for key in ['valence', 'arousal', 'dominance', 'concreteness']})\n",
    "    with open(fic_fpath) as f:\n",
    "        paras = [p for p in f.read().splitlines()]\n",
    "        paras_present = [para for para in paras if pairing_present(para, pairing)]\n",
    "#         if len(paras_present) < 5:\n",
    "#             print(len(paras_present))\n",
    "        if len(paras_present)==0:\n",
    "            continue\n",
    "        for para in paras_present:\n",
    "            fic_lexicon_totals += Counter(lexicon_scores(para))\n",
    "    fic_lexicon_scores = {key: total/len(paras_present) for key, total in fic_lexicon_totals.items()}\n",
    "    lexicon_outlines.append([fic_id, pairing] + [fic_lexicon_scores.get(key, 0) for key in ['valence', 'arousal', 'dominance', 'concreteness']])\n",
    "    \n",
    "lexicon_df = pd.DataFrame(lexicon_outlines, columns=['fic_id', 'pairing', 'valence', 'arousal', 'dominance', 'concreteness'])\n",
    "lexicon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4840"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join in information about predicted in_canon\n",
    "\n",
    "merged = pd.merge(lexicon_df, train, on=['fic_id', 'pairing'])\n",
    "len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>concreteness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_pred_canon</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.142285</td>\n",
       "      <td>0.105267</td>\n",
       "      <td>0.118089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.138997</td>\n",
       "      <td>0.102485</td>\n",
       "      <td>0.116032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  valence   arousal  dominance  concreteness\n",
       "best_pred_canon                                             \n",
       "False            0.142285  0.105267   0.118089             0\n",
       "True             0.138997  0.102485   0.116032             0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average lexicon values\n",
    "pred_groups = merged.groupby(['best_pred_canon']).agg({'valence': 'mean', 'arousal': 'mean', 'dominance': 'mean', 'concreteness': 'mean'})\n",
    "pred_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>concreteness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_canon</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.140345</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.116738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.140293</td>\n",
       "      <td>0.103367</td>\n",
       "      <td>0.116950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           valence   arousal  dominance  concreteness\n",
       "is_canon                                             \n",
       "False     0.140345  0.103900   0.116738             0\n",
       "True      0.140293  0.103367   0.116950             0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average lexicon values\n",
    "actual_groups = merged.groupby(['is_canon']).agg({'valence': 'mean', 'arousal': 'mean', 'dominance': 'mean', 'concreteness': 'mean'})\n",
    "actual_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valence: Ttest_indResult(statistic=-4.538698299246469, pvalue=5.797474585475383e-06)\n",
      "arousal: Ttest_indResult(statistic=-5.323166987671603, pvalue=1.0658550481184181e-07)\n",
      "dominance: Ttest_indResult(statistic=-3.4469067534508784, pvalue=0.000571872529139558)\n",
      "concreteness: Ttest_indResult(statistic=nan, pvalue=nan)\n"
     ]
    }
   ],
   "source": [
    "# Significance testing for predictions\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "lexicon_groups = ['valence', 'arousal', 'dominance', 'concreteness']\n",
    "canon_split = {True: {}, False: {}}\n",
    "for pred in [True, False]:\n",
    "    for col in lexicon_groups:\n",
    "        canon_split[pred][col] = merged.loc[merged['best_pred_canon']==pred, col]\n",
    "        \n",
    "for col in lexicon_groups:\n",
    "    print(f'{col}: {ttest_ind(canon_split[True][col], canon_split[False][col])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valence: Ttest_indResult(statistic=-0.07172567198334423, pvalue=0.9428231902435041)\n",
      "arousal: Ttest_indResult(statistic=-1.028785243757927, pvalue=0.3036320324286657)\n",
      "dominance: Ttest_indResult(statistic=0.36001113278777724, pvalue=0.718854522777072)\n",
      "concreteness: Ttest_indResult(statistic=nan, pvalue=nan)\n"
     ]
    }
   ],
   "source": [
    "# Significance testing for actual\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "lexicon_groups = ['valence', 'arousal', 'dominance', 'concreteness']\n",
    "canon_split = {True: {}, False: {}}\n",
    "for pred in [True, False]:\n",
    "    for col in lexicon_groups:\n",
    "        canon_split[pred][col] = merged.loc[merged['is_canon']==pred, col]\n",
    "        \n",
    "for col in lexicon_groups:\n",
    "    print(f'{col}: {ttest_ind(canon_split[True][col], canon_split[False][col])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate data issue with pairings have fewer than 5 paragraphs\n",
    "Ended up being from quotes where the characters replied to each other or spoke to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('draco', 'harry'), ('hermione', 'ron'), ('ginny', 'harry'), ('draco', 'hermione'), ('harry', 'hermione'), ('harry', 'ron')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load character context embeddings saved from character_context_embeddings_paragraphs.py\n",
    "import pickle\n",
    "\n",
    "# context_emb_fpath = '/usr2/mamille2/fanfiction-project/temp/char_contexts_local.pkl'\n",
    "# context_emb_fpath = '/usr2/mamille2/fanfiction-project/embeddings/char_vecs_quote_all_context_only_combined.pkl'\n",
    "context_emb_fpath = '/usr2/mamille2/fanfiction-project/embeddings/char_vecs_assertion_local_context_only_combined.pkl'\n",
    "\n",
    "with open(context_emb_fpath, 'rb') as f:\n",
    "    context_embs = pickle.load(f)\n",
    "    \n",
    "context_embs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1053822 in context_embs[('hermione', 'ron')].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([10028441, 10027832, 1001573, 1001234, 10018181, 10018874, 10018988, 10017002, 10032896, 10034954, 10033436, 10041509, 10039166, 10050407, 10040978, 10050566, 10050686, 10050905, 10050917, 10051442, 10052243, 10051322, 10056305, 10054547, 10055381, 10057505, 10048754, 10058249, 10060568, 10062521, 10060850, 10062236, 10062335, 10062533, 100570, 1006327, 10063145, 10063613, 10064330, 10064054, 10065515, 10065662, 1006472, 10066193, 10073099, 10075517, 10064744, 1007270, 10075892, 1007650, 10075814, 10076873, 10076903, 10076906, 10077248, 10076291, 10093271, 10095068, 100802, 10097252, 10097576, 10097900, 1012240, 101305, 10140872, 1014300, 10139189, 10154996, 10136480, 10160687, 10158134, 10160948, 10161113, 10161275, 10161008, 10161515, 10136669, 10161368, 10160993, 10160984, 10162064, 10162226, 10161203, 10162457, 10162694, 10162769, 10173377, 10176230, 10177064, 10176701, 10179023, 10185869, 10180412, 10183436, 10184693, 10180007, 10181825, 1019907, 10209461, 10191158, 1017683, 1024382, 10216640, 10235255, 10223171, 1026371, 1023084, 1029747, 10256096, 1030211, 10316117, 10329731, 10348914, 103642, 10367520, 10369206, 10384770, 10396374, 1042335, 10425510, 10431840, 1044657, 10480935, 10491378, 1035664, 1045628, 1049966, 10488876, 10506069, 1051688, 10466280, 10505304, 10531302, 1050767, 10532211, 10536099, 10513749, 1053822, 10557220, 10562475, 10581726, 10600566, 10613580, 10628166, 10622376, 10626450, 10558854, 10625715, 10631397, 1060212, 1063896, 1064078, 105837, 1064483, 10665024, 1067375, 10683810, 10688925, 10681473, 10720404, 10690701, 10734054, 1071854, 10742163, 10747464, 1076442, 10768398, 10787007, 10786740, 10787325, 10782378, 10787592, 10787856, 10788408, 10788576, 10782444, 10790163, 10790172, 10798992, 10799043, 10806402, 10805256, 10807092, 10807941, 10807596, 10807779, 10809444, 10805811, 10811340, 10810446, 10811790, 10811562, 10811793, 10812642, 10811319, 10811799, 10814334, 1081759, 10814880, 10822239, 10835823, 10820733, 10824855, 1085383, 1085412, 10853601, 1085400, 108390, 108295, 1088440, 10877226, 1087424, 10876983, 10878207, 10890840, 1086116, 10893915, 10902018, 1090258, 10892742, 10901745, 10896369, 1091358, 10915503, 1092128, 10951398, 10954152, 10957704, 109323, 10958781, 10957410, 10962963, 10973082, 10977633, 1096708, 10972461, 10990731, 1097906, 11005281, 1101127, 11032785, 11019591, 11016093, 11055042, 11064306, 11076615, 1106871, 11087223, 11088207, 11091009, 11093481, 11111202, 1112811, 1111318, 11142945, 1114937, 1116529, 1117155, 1115479, 11190588, 11186103, 11180595, 11197383, 111988, 11241741, 11259051, 11255775, 11261388, 11259225, 11282619, 11264781, 11301171, 1129360, 1130557, 1131860, 11331654, 1132164, 1133370, 11329809, 1134485, 11352768, 1130086, 11372385, 11373930, 1137958, 11367462, 11402892, 11383992, 11415702, 1141764, 11403900, 11432331, 11414484, 11433555, 1142812, 11444802, 1144655, 11454996, 114469, 11459325, 11479098, 11479992, 11470650, 1149081, 11472648, 11504679, 11508717, 11503584, 11468256, 11528028, 11544942, 11543934, 11544978, 11545935, 11554362, 11560575, 1156393, 11571501, 11572512, 11570559, 115796, 11586360, 11580693, 11599248, 11594643, 1158977, 1160694, 1162835, 1164899, 11640861, 1162945, 11618682, 11642883, 11654454, 1162854, 1165679, 11661363, 11659725, 11663391, 11666229, 11681685, 11695554, 1169793, 11696538, 11682267, 11698353, 11713563, 1171599, 11744421, 11737404, 11748006, 117471, 11755689, 11767326, 1176892, 11779419, 11779836, 11770086, 11790435, 11801043, 11803947, 11814516, 11819712, 11827911, 11833041, 11841741, 11852010, 11836593, 11853636, 11873763, 11878326, 11870469, 11885214, 11872554, 11892765, 11899452, 11913426, 1188480, 11923254, 119, 11945850, 1191969, 11954241, 11940930, 11956635, 11970324, 119664, 11974053, 11962530, 119739, 12036420, 11973765, 12040341, 12052398, 12056346, 120599, 12049515, 12045300, 12061215, 1203946, 12060855, 12065601, 120873, 12110064, 1209373, 12127065, 12136980, 12139677, 1213852, 12118800, 12183867, 1216054, 12173748, 12171654, 12209349, 1221511, 12214314, 12213495, 12216330, 12237192, 12230142, 12232407, 12207756, 12250638, 12275142, 12272349, 12272961, 12303831, 12302310, 1231963, 12312420, 12330075, 123205, 1236073, 12317121, 1234885, 12391923, 12381339, 12401370, 12404916, 12401193, 12408018, 12408612, 12409329, 12404862, 12411687, 12410031, 12415233, 12415899, 1246486, 1244647, 12478232, 12475684, 12492696, 12461961, 1252552, 12543616, 12535816, 12518572, 12543520, 1247959, 12565220, 12576364, 12581956, 12595804, 12600316, 1259122, 12629805, 1261, 12639780, 12647160, 12649992, 12669576, 12667272, 12680400, 1270558, 12682629, 1271065, 12724605, 12707139, 12738957, 126694, 12733728, 12742470, 1260, 12705891, 12756270, 12754311, 12768927, 12826416, 1280734, 12778137, 12845394, 12854127, 12877161, 12880134, 12877770, 12870804, 12880170, 12847242, 12895404, 12894321, 12900627, 1290319, 12909726, 12915420, 12918870, 12922311, 1290880, 12937602, 12924507, 129663, 1293346, 12978267, 1294120, 12962658, 13006662, 12933738, 13006941, 13027698, 13034526, 13043466, 13085109, 130975, 13098783, 13090485, 13082262, 13107957, 13119561, 13123500, 13125288, 13136007, 13161618, 13160727, 13142754, 13169814, 13176606, 13176000, 13163763, 13178007, 13110369, 13191747, 13182756, 131736, 13207710, 13188915, 13217727, 13227255, 13229529, 13230066, 1324669, 1324768, 13262220, 13233807, 13276101, 13277118, 1329025, 1325137, 13295898, 13295901, 1330054, 13288386, 13307583, 13309227, 13314174, 13315155, 13299207, 13309929, 13339218, 13327311, 13326270, 1325104, 13384635, 13386231, 13379955, 13396641, 13395078, 13403454, 13404696, 13407195, 13419717, 13428783, 13449813, 13423638, 13461978, 13468788, 13446828, 13491660, 13478451, 13513191, 13505940, 13476363, 13516635, 13521588, 1353502, 13543143, 1352455, 1343047, 13546410, 13558755, 13573113, 13570830, 13576098, 13461141, 13580730, 13560489, 13601283, 13559415, 13589577, 13576575, 13618944, 13596042, 13620555, 13643946, 136524, 13659363, 13647501, 13690860, 13682826, 13633332, 1369285, 13655562, 1346185, 13730067, 13720854, 13741794, 13744227, 13740837, 13744608, 13749840, 13747875, 13736532, 13772244, 13787226, 13788162, 13784763, 13749426, 13805274, 13813623, 1384306, 13851786, 1385779, 138661, 13868547, 1388674, 13904637, 13930281, 13929294, 13881393, 1390552, 13932975, 13907388, 13955721, 13943694, 1401226, 14002215, 14015364, 13976862, 14056131, 1406926, 14057193, 14075556, 14076777, 14072127, 13867242, 14118129, 14077758, 14104605, 14056179, 1407952, 1403215, 14061186, 14127630, 14139801, 14166432, 14174607, 14176824, 14182713, 14203407, 14236047, 14246466, 14252262, 14251476, 14272077, 14247480, 14262144, 14294757, 14308131, 14309673, 14307762, 14318862, 14301243, 14315961, 14305905, 14326323, 14330403, 1434142, 14342685, 14339253, 14344890, 14357424, 14358156, 14364543, 14367660, 14370402, 14359368, 14376423, 1436935, 14374101, 14389857, 14370498, 14440419, 144407, 14454174, 14463684, 14475159, 14446683, 14485896, 14470482, 14539947, 14542653, 14553159, 145552, 14578353, 14586183, 14611239, 14569368, 14633412, 14633649, 14667834, 14663046, 1448944, 14568753, 14600361, 14688342, 14670297, 14689173, 14689527, 14696144, 1472281, 14728316, 147281, 14735057, 14747219, 14727594, 14736429, 14771282, 14759186, 1465963, 14772854, 14794172, 14759268, 14828672, 14831015, 14831186, 1483858, 14840931, 14839643, 14843699, 14823162, 14845793, 14852573, 14886539, 14890245, 14887616, 14897922, 14905766, 14916353, 14909120, 14920538, 14921576, 14923646, 1492582, 14925680, 14940131, 14925668, 14966282, 14957171, 14958828, 14959107, 14940398, 14980517, 14985608, 14961243, 15016946, 15024440, 15026618, 15009803, 15038066, 15049505, 15044549, 15066806, 15015365, 15068714, 14991197, 15074012, 15055727, 15067544, 15127514, 15156536, 1511975, 15167102, 15181496, 15205457, 15275916, 15331215, 15327051, 15346497, 1534019, 15350592, 1536209, 15380604, 15380469, 15384810, 15380832, 15410469, 1536485, 15417792, 15407934, 15465387, 15461673, 15390153, 15468783, 15479469, 15499818, 15506670, 15494943, 1550378, 15531291, 15542922, 15542394, 15537897, 1556516, 15582621, 15563223, 15549540, 15522078, 15654432, 15663219, 15642432, 15675297, 15678519, 15686154, 15686880, 1569212, 15689913, 15682923, 15708120, 157413, 15727476, 15676293, 15712026, 15699489, 157414, 157412, 15745509, 15749427, 15814320, 15754899, 15853071, 16017251, 15994781, 16022672, 160802, 16017770, 1609865, 16123502, 15995570, 16182, 16177967, 16204133, 16209365, 16274741, 162984, 16224497, 16301492, 16305062, 16340429, 163716, 163051, 16319195, 16411577, 16429844, 16441577, 16464656, 16444763, 16496399, 1647041, 16486205, 16481699, 1680950, 1673261, 1684070, 1693445, 1695377, 169574, 1704410, 1706720, 171151, 1709096, 1731362, 1738535, 1747328, 1758483, 1760345, 1719926, 1760523, 176926, 1774231, 1758837, 1780927, 1793110, 1789219, 1745879, 1735595, 180806, 1813657, 1819165, 1821946, 1813519, 1830433, 1821964, 184827, 1848016, 1838962, 1817452, 1879740, 1863450, 1845664, 188817, 185653, 1899732, 1905588, 1900509, 1908255, 1905252, 19129, 1927641, 1927878, 1926747, 1929432, 192815, 1941810, 1948506, 1953717, 1967307, 1975314, 196484, 197997, 1980966, 196508, 2007897, 202416, 2025777, 2020551, 2039787, 2023461, 203238, 2054430, 202149, 2061960, 192356, 2011647, 204873, 2062350, 201997, 2069913, 2114478, 2119842, 2124831, 2126703, 2135769, 2158587, 21214, 2158413, 2145951, 2159475, 2159121, 2177055, 2175390, 2214318, 2211948, 221508, 2234118, 221202, 2253663, 2242650, 2221383, 2266659, 2256654, 227477, 227411, 2278077, 215150, 2277018, 224810, 2326445, 2326607, 2304488, 233384, 233435, 233566, 2346161, 23539, 23387, 239144, 240801, 2415386, 23828, 240753, 2431439, 243084, 23837, 2436329, 2446655, 2445923, 2450642, 244716, 2451800, 242918, 246188, 246326, 2465690, 245007, 244403, 246675, 2444648, 2469779, 237892, 2471711, 2479346, 2483486, 2485286, 2494610, 249396, 248634, 24884, 247402, 250976, 251058, 246759, 251553, 2516510, 2507042, 2535413, 2507117, 2552888, 2562383, 2566382, 2568890, 257063, 246733, 2563856, 257338, 25656, 2576393, 2574014, 2556383, 2580821, 246418, 257701, 261823, 2590928, 263939, 2625638, 26342, 2637458, 2667911, 267488, 2659871, 2682983, 2684012, 266096, 267864, 2685569, 2682410, 2687837, 2674, 2694818, 2708663, 268870, 2715926, 2727356, 274158, 27600, 276517, 2723783, 275238, 279196, 2794931, 2774954, 279474, 2822549, 2805470, 2711060, 287619, 284310, 2853059, 293195, 2912090, 298446, 300701, 284392, 304284, 306412, 305155, 301125, 3066578, 3072080, 307173, 309180, 3101099, 310445, 288742, 3103358, 3106862, 3113789, 309252, 309693, 313189, 3159926, 3165443, 3171864, 3172856, 3170786, 3192611, 317571, 3139046, 3199109, 317957, 3175186, 3215123, 323237, 3217646, 324523, 324514, 3264584, 3269597, 324649, 3266726, 327164, 3293474, 328987, 3302333, 3310853, 328919, 3223727, 3318311, 331240, 332829, 332824, 330163, 331638, 332838, 333775, 333432, 3378833, 3403982, 339276, 3412346, 3427175, 3435932, 3466958, 3452204, 3487364, 346849, 3461795, 3496775, 349307, 347648, 3462581, 3506471, 3525602, 3530978, 3535181, 3534131, 3536612, 3548876, 3504665, 3530774, 358051, 358122, 358559, 358120, 358357, 3607650, 359198, 3636027, 3630327, 3637383, 3660357, 3686949, 3664839, 366169, 3668844, 3626724, 358789, 3688317, 3690171, 3661812, 3697694, 3696941, 3708777, 3712579, 372283, 373281, 3717433, 3757066, 376056, 3759676, 3764659, 376888, 377471, 3770935, 376928, 373711, 378746, 379548, 379606, 3816001, 380026, 3816481, 3823012, 3848911, 381123, 385305, 383504, 3866092, 3871744, 3836032, 3879790, 3880195, 3893437, 389453, 3895723, 3911608, 3871411, 389217, 3915142, 3919741, 392253, 3933208, 393269, 393000, 393753, 394544, 3920059, 396770, 3976099, 394502, 397675, 3987526, 400507, 400517, 400934, 404032, 4022782, 4038868, 4005484, 403453, 401208, 401152, 4041706, 405334, 4050871, 4069309, 4069336, 4075366, 4060012, 4076008, 4080991, 4101937, 408950, 4087114, 4103302, 409285, 41101, 4117936, 4066699, 4123167, 4128690, 4130415, 41103, 413284, 4149024, 414887, 415941, 4163049, 408565, 4180857, 4145394, 417879, 4184532, 4170693, 417864, 420177, 421326, 4223940, 420583, 4267035, 423064, 4267422, 422957, 4279203, 42210, 4242003, 4213656, 4235001, 423124, 4241040, 4202763, 4289172, 430530, 4309479, 4309689, 4300026, 431114, 4283343, 4313301, 431858, 4335932, 4342358, 4330836, 434498, 4347425, 4348331, 43502, 4362470, 4370078, 4384094, 4372229, 4365272, 4394258, 4399196, 439865, 4400789, 435452, 4400630, 4421360, 4433987, 4430987, 4445954, 445263, 4422662, 4458650, 4469153, 446920, 4474835, 4493235, 4501068, 4506837, 449976, 450221, 450088, 4515828, 4523133, 444457, 444805, 4528002, 451371, 4528551, 451172, 452208, 4533360, 453246, 453891, 4551402, 454741, 4549929, 456381, 456611, 45703, 458381, 459530, 459418, 454186, 4600548, 459051, 4611291, 462532, 4600923, 4617447, 4632522, 4647696, 4647030, 466612, 466950, 4686389, 4679093, 4707371, 4699043, 4714292, 4723928, 4701869, 470767, 4694096, 4729979, 4732727, 4744052, 4741934, 476104, 4738223, 4744967, 4755359, 4733003, 4739090, 4766939, 4749806, 4773077, 4775714, 4783076, 4788908, 4731860, 479236, 4792814, 4794710, 480428, 47964, 4798334, 4811051, 4799546, 483344, 4846931, 4841291, 4807733, 482179, 48334, 483488, 4844438, 48302, 484380, 4865405, 4812263, 4859444, 4886587, 4879876, 487818, 4920445, 4927045, 4902346, 493385, 4932703, 491077, 4946923, 4906606, 4940047, 495191, 4953556, 495574, 4962886, 4999573, 5018443, 502969, 5054074, 506701, 5076088, 507281, 4974925, 498328, 5093033, 5060446, 510921, 5109329, 511013, 5123276, 5137685, 5146706, 501521, 5163386, 5172275, 516308, 5130740, 5175446, 5189666, 518895, 5189759, 5206886, 51293, 5215688, 5230388, 522906, 5224073, 5223, 5240207, 525119, 5264216, 5243489, 5285558, 5225171, 533504, 5271320, 5315414, 5340077, 5350367, 5363165, 535608, 5374946, 5343182, 539001, 5380268, 5380535, 539875, 5403848, 536398, 54229, 545835, 5434277, 546992, 54835, 5440955, 5495552, 5460773, 5439374, 5518499, 549234, 5547815, 550545, 557270, 560498, 5600455, 5607295, 5613928, 5579962, 552828, 556365, 5651875, 562655, 5649868, 566627, 5690182, 5676193, 568093, 571260, 5688301, 5698750, 571347, 571303, 5696176, 572322, 5720908, 572901, 5717689, 5733448, 573679, 57034, 574759, 5750365, 5758723, 573057, 576861, 5771029, 5786701, 579358, 5802097, 5787289, 576865, 5804749, 5783425, 5814976, 5815162, 579791, 582850, 5849695, 5837776, 5881576, 5874244, 5876728, 585988, 5924326, 5924476, 5951437, 5952646, 5942016, 5930779, 603381, 60367, 6034903, 6039967, 608957, 6111073, 6105904, 606289, 6110023, 6116710, 6138097, 6148987, 6160852, 6141595, 615628, 61770, 6137263, 6200260, 622344, 6218920, 6225709, 6222289, 6212878, 6225547, 623674, 624638, 6239806, 6248830, 616631, 6252448, 625437, 6265345, 6276226, 6256129, 6300883, 62949, 631519, 632151, 6322057, 6363172, 6357958, 6371380, 638104, 630355, 633896, 6405661, 6410569, 6412096, 6423226, 641367, 642004, 640509, 642847, 644142, 6446107, 6453157, 64607, 6453097, 6468994, 6466174, 648555, 6476650, 6490861, 6508633, 6525703, 6528064, 6529837, 65476, 658047, 658380, 6562291, 6605641, 660883, 6607183, 6611041, 6637171, 6663766, 6660799, 6661693, 659627, 670913, 670252, 670403, 6708151, 6700021, 672085, 6723334, 6736627, 673586, 6744622, 6746287, 675566, 675953, 6756835, 6782863, 675089, 679229, 6799963, 679415, 6824914, 6838789, 689669, 6902275, 686597, 690803, 689295, 6916057, 692658, 69451, 6910396, 6819424, 6947116, 69363, 698316, 69889, 7017232, 701778, 7024936, 70318, 701722, 7012426, 7024750, 7076824, 71126, 712975, 7135787, 7126246, 715134, 7162523, 715459, 7176818, 7024042, 719965, 718619, 723082, 723311, 7214983, 72356, 7237309, 7254334, 721616, 7271434, 7274626, 7274515, 727144, 7292242, 725823, 731847, 7293067, 7342744, 727980, 734930, 7350, 732798, 7358083, 7368784, 7370389, 7220197, 736180, 7357633, 738697, 7382500, 7404709, 74058, 7434507, 7440637, 7437817, 7450840, 7456444, 7465509, 7469469, 74050, 7473867, 7423918, 7490400, 7510021, 7474536, 7507792, 7519358, 7490784, 7538848, 753424, 7545993, 74892, 7536217, 754708, 755115, 7554319, 7557004, 756177, 7562548, 7570039, 7570351, 7592434, 7613224, 7626220, 762726, 7635253, 7647544, 7630993, 7650451, 7656985, 7658860, 763367, 7675132, 7682230, 7683601, 7683628, 7684972, 7695913, 769967, 7729069, 7734100, 7714615, 7742044, 777037, 7755385, 771495, 7778932, 7774936, 780161, 7799941, 778766, 7798267, 7803673, 7814287, 7819735, 7816183, 7776190, 785207, 783424, 7876597, 7723327, 78824, 7897702, 7903294, 790488, 7900501, 791048, 7901914, 7934794, 791619, 7958683, 7973728, 7972714, 7975732, 7974481, 7989682, 8003494, 800959, 8013418, 802479, 8037256, 801004, 8060137, 8059654, 8073604, 8075020, 8072578, 8047918, 8081986, 80843, 8091997, 8057680, 8106136, 801580, 8116399, 8120701, 8102803, 811360, 812357, 8117122, 8131279, 8138828, 8127470, 8140631, 813986, 8154, 8161336, 8156495, 8131408, 81769, 8174591, 8180936, 8176255, 8158447, 8186122, 8186131, 8185901, 8186482, 8188636, 8190118, 8184311, 8194186, 8197696, 8197651, 8187556, 8199244, 8198188, 8199295, 8201032, 8201381, 8204390, 8205730, 8205571, 8205829, 8205832, 8205959, 8209082, 8209156, 8209180, 8209469, 8210311, 8210611, 8209499, 8210822, 8211880, 8211949, 8211967, 8212192, 8213404, 8214638, 8214733, 8215883, 8215858, 8214703, 8215966, 8217802, 821513, 8217808, 8218127, 8216653, 8218735, 8218628, 8218741, 8216731, 8218132, 8229586, 821928, 8233867, 8242024, 823633, 824668, 826710, 8277938, 8261828, 827386, 825875, 8329894, 825477, 8284075, 8305918, 8340370, 833384, 8343019, 8308696, 8278178, 836915, 8369683, 8371630, 833733, 8374294, 8334520, 8376214, 8393869, 8396008, 8397796, 837746, 8424007, 8431420, 8432554, 8451523, 8437525, 8466583, 8466955, 847006, 847529, 847542, 8476018, 846707, 8475505, 8514763, 847873, 8507344, 8517286, 8493628, 849859, 8536510, 852702, 8536339, 8541115, 8546431, 8538220, 855381, 855004, 8559340, 8566789, 8556859, 8573494, 8572360, 8640808, 8646739, 8648779, 862741, 8673031, 8640832, 865793, 8664997, 8696833, 8710264, 8568577, 8722162, 861968, 8729986, 8727586, 8732080, 8740669, 874213, 8759551, 876635, 876286, 8784751, 8797756, 878422, 878998, 8799919, 880454, 880452, 880461, 8819086, 8805172, 8801308, 888826, 887890, 8820499, 892674, 897200, 8982121, 900479, 902237, 896640, 9044975, 9057739, 906090, 9094222, 9065263, 909617, 914329, 910554, 9150688, 908503, 922767, 921944, 9236039, 9267623, 928727, 930618, 9275651, 9324497, 933394, 936659, 938004, 9411356, 94518, 93221, 950531, 951036, 951044, 951739, 923683, 9543539, 959095, 960358, 959735, 965089, 967126, 963496, 96744, 976083, 972386, 975164, 96429, 969751, 980612, 984353, 9849800, 9884660, 9893411, 9893537, 9896828, 9897428, 9896951, 9898055, 990164, 983727, 9911075, 9898094, 9914225, 989537, 9963857, 992265, 9938102])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embs[('hermione', 'ron')].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10050767 in context_embs[('hermione', 'ron')].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/mamille2/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c322c33a964f4d8daa001b52255df4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 597: expected 4 fields, saw 1519\\n'\n",
      "b'Skipping line 34: expected 4 fields, saw 1264\\n'\n",
      "b'Skipping line 94: expected 4 fields, saw 1306\\n'\n",
      "b'Skipping line 145: expected 4 fields, saw 21247\\n'\n",
      "b'Skipping line 86: expected 4 fields, saw 244\\n'\n",
      "b'Skipping line 146: expected 4 fields, saw 2734\\n'\n",
      "b'Skipping line 11: expected 4 fields, saw 34\\n'\n",
      "b'Skipping line 72: expected 4 fields, saw 6292\\n'\n",
      "b'Skipping line 65: expected 4 fields, saw 5605\\n'\n",
      "b'Skipping line 198: expected 4 fields, saw 16156\\n'\n",
      "b'Skipping line 49: expected 4 fields, saw 3397\\n'\n",
      "b'Skipping line 211: expected 4 fields, saw 2023\\n'\n",
      "b'Skipping line 207: expected 4 fields, saw 13078\\n'\n",
      "b'Skipping line 92: expected 4 fields, saw 658\\n'\n",
      "b'Skipping line 40: expected 4 fields, saw 442\\n'\n",
      "b'Skipping line 136: expected 4 fields, saw 5233\\n'\n",
      "b'Skipping line 70: expected 4 fields, saw 652\\n'\n",
      "b'Skipping line 79: expected 4 fields, saw 2098\\n'\n",
      "b'Skipping line 241: expected 4 fields, saw 3346\\n'\n",
      "b'Skipping line 348: expected 4 fields, saw 946\\n'\n",
      "b'Skipping line 329: expected 4 fields, saw 691\\n'\n",
      "b'Skipping line 84: expected 4 fields, saw 1108\\n'\n",
      "b'Skipping line 141: expected 4 fields, saw 1720\\n'\n",
      "b'Skipping line 25: expected 4 fields, saw 2587\\n'\n",
      "b'Skipping line 158: expected 4 fields, saw 1525\\n'\n",
      "b'Skipping line 174: expected 4 fields, saw 4087\\n'\n",
      "b'Skipping line 19: expected 4 fields, saw 2413\\n'\n",
      "b'Skipping line 193: expected 4 fields, saw 9409\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-6-08662d0588f1>(21)<module>()\n",
      "-> pairing_present['lexicon_scores'] = pairing_present['text'].map(lexicon_scores)\n",
      "(Pdb) p fic_id\n",
      "1053822\n",
      "(Pdb) p pairing\n",
      "('hermione', 'ron')\n",
      "(Pdb) q\n",
      "\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-08662d0588f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairing_present\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mpairing_present\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lexicon_scores'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairing_present\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairing_present\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lexicon_scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairing_present\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lexicon_scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfic_lexicon_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'arousal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dominance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'concreteness'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-08662d0588f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairing_present\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mpairing_present\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lexicon_scores'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairing_present\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairing_present\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lexicon_scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairing_present\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lexicon_scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfic_lexicon_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'arousal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dominance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'concreteness'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OLD WAY FROM CSVs\n",
    "# Join with story texts, find paragraphs with both characters\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pdb\n",
    "\n",
    "def pairing_in_text(pairing, text):\n",
    "    return (pairing[0] in text.lower()) and (pairing[1] in text.lower())\n",
    "\n",
    "# story_dirpath = '/usr2/mamille2/fanfiction-project/data/ao3/harrypotter/emnlp_dataset_6k/fics'\n",
    "story_dirpath = '/data/fanfiction_ao3/harrypotter/preprocessed_paras/\n",
    "lexicon_outlines = []\n",
    "\n",
    "for fic_id, pairing in tqdm(list(zip(train['fic_id'], train['pairing']))):\n",
    "#     fic_fpath = os.path.join(story_dirpath, f'{fic_id}.csv')\n",
    "    fic_fpath = os.path.join(story_dirpath, f'{fic_id}.txt')\n",
    "#     fic = pd.read_csv(fic_fpath, error_bad_lines=False)\n",
    "    with open(os.path.join(fics_fpath, fname)) as f:\n",
    "        paras = [p.split() for p in f.read().splitlines()]\n",
    "        paras_present = []\n",
    "    pairing_present = fic.loc[pairing_present_mask, ['text']]\n",
    "    if len(pairing_present) == 0:\n",
    "        pdb.set_trace()\n",
    "    pairing_present['lexicon_scores'] = pairing_present['text'].map(lexicon_scores)\n",
    "    merged = pd.concat([pairing_present.drop(columns='lexicon_scores'), pairing_present['lexicon_scores'].apply(pd.Series)], axis=1)\n",
    "    fic_lexicon_scores = merged.loc[:,['valence', 'arousal', 'dominance', 'concreteness']].mean()\n",
    "    lexicon_outlines.append([fic_id, pairing, fic_lexicon_scores.tolist()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
